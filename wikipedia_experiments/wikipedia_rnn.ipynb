{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDJctDhhEDTD"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z2xZnxncD2Ep"
      },
      "outputs": [],
      "source": [
        "# Selecting Tensorflow version v2 (the command is relevant for Colab only).\n",
        "%tensorflow_version  2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpueB6zADYgE",
        "outputId": "6dfff30d-d2db-4977-b470-753036581299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.7.13\n",
            "Tensorflow version: 2.8.0\n",
            "Keras version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform\n",
        "import time\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "print('Python version:', platform.python_version())\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('Keras version:', tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciI_JnnNEGCw"
      },
      "source": [
        "## Download the dataset\n",
        "\n",
        "[Wikipedia](https://www.tensorflow.org/datasets/catalog/wikipedia) dataset contains cleaned articles of all languages. The datasets are built from the [Wikipedia dump](https://dumps.wikimedia.org/) with one split per language. Each example contains the content of one full Wikipedia article with cleaning to strip markdown and unwanted sections (references, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3PDebo50-Le",
        "outputId": "c8a00136-c1cf-439c-93c2-7309cbd3f7d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abstract_reasoning',\n",
              " 'accentdb',\n",
              " 'aeslc',\n",
              " 'aflw2k3d',\n",
              " 'ag_news_subset',\n",
              " 'ai2_arc',\n",
              " 'ai2_arc_with_ir',\n",
              " 'amazon_us_reviews',\n",
              " 'anli',\n",
              " 'arc',\n",
              " 'bair_robot_pushing_small',\n",
              " 'bccd',\n",
              " 'beans',\n",
              " 'big_patent',\n",
              " 'bigearthnet',\n",
              " 'billsum',\n",
              " 'binarized_mnist',\n",
              " 'binary_alpha_digits',\n",
              " 'blimp',\n",
              " 'bool_q',\n",
              " 'c4',\n",
              " 'caltech101',\n",
              " 'caltech_birds2010',\n",
              " 'caltech_birds2011',\n",
              " 'cars196',\n",
              " 'cassava',\n",
              " 'cats_vs_dogs',\n",
              " 'celeb_a',\n",
              " 'celeb_a_hq',\n",
              " 'cfq',\n",
              " 'chexpert',\n",
              " 'cifar10',\n",
              " 'cifar100',\n",
              " 'cifar10_1',\n",
              " 'cifar10_corrupted',\n",
              " 'citrus_leaves',\n",
              " 'cityscapes',\n",
              " 'civil_comments',\n",
              " 'clevr',\n",
              " 'clic',\n",
              " 'clinc_oos',\n",
              " 'cmaterdb',\n",
              " 'cnn_dailymail',\n",
              " 'coco',\n",
              " 'coco_captions',\n",
              " 'coil100',\n",
              " 'colorectal_histology',\n",
              " 'colorectal_histology_large',\n",
              " 'common_voice',\n",
              " 'coqa',\n",
              " 'cos_e',\n",
              " 'cosmos_qa',\n",
              " 'covid19sum',\n",
              " 'crema_d',\n",
              " 'curated_breast_imaging_ddsm',\n",
              " 'cycle_gan',\n",
              " 'deep_weeds',\n",
              " 'definite_pronoun_resolution',\n",
              " 'dementiabank',\n",
              " 'diabetic_retinopathy_detection',\n",
              " 'div2k',\n",
              " 'dmlab',\n",
              " 'downsampled_imagenet',\n",
              " 'dsprites',\n",
              " 'dtd',\n",
              " 'duke_ultrasound',\n",
              " 'emnist',\n",
              " 'eraser_multi_rc',\n",
              " 'esnli',\n",
              " 'eurosat',\n",
              " 'fashion_mnist',\n",
              " 'flic',\n",
              " 'flores',\n",
              " 'food101',\n",
              " 'forest_fires',\n",
              " 'fuss',\n",
              " 'gap',\n",
              " 'geirhos_conflict_stimuli',\n",
              " 'genomics_ood',\n",
              " 'german_credit_numeric',\n",
              " 'gigaword',\n",
              " 'glue',\n",
              " 'goemotions',\n",
              " 'gpt3',\n",
              " 'groove',\n",
              " 'gtzan',\n",
              " 'gtzan_music_speech',\n",
              " 'hellaswag',\n",
              " 'higgs',\n",
              " 'horses_or_humans',\n",
              " 'i_naturalist2017',\n",
              " 'imagenet2012',\n",
              " 'imagenet2012_corrupted',\n",
              " 'imagenet2012_real',\n",
              " 'imagenet2012_subset',\n",
              " 'imagenet_a',\n",
              " 'imagenet_r',\n",
              " 'imagenet_resized',\n",
              " 'imagenet_v2',\n",
              " 'imagenette',\n",
              " 'imagewang',\n",
              " 'imdb_reviews',\n",
              " 'irc_disentanglement',\n",
              " 'iris',\n",
              " 'kitti',\n",
              " 'kmnist',\n",
              " 'lfw',\n",
              " 'librispeech',\n",
              " 'librispeech_lm',\n",
              " 'libritts',\n",
              " 'ljspeech',\n",
              " 'lm1b',\n",
              " 'lost_and_found',\n",
              " 'lsun',\n",
              " 'malaria',\n",
              " 'math_dataset',\n",
              " 'mctaco',\n",
              " 'mnist',\n",
              " 'mnist_corrupted',\n",
              " 'movie_lens',\n",
              " 'movie_rationales',\n",
              " 'movielens',\n",
              " 'moving_mnist',\n",
              " 'multi_news',\n",
              " 'multi_nli',\n",
              " 'multi_nli_mismatch',\n",
              " 'natural_questions',\n",
              " 'natural_questions_open',\n",
              " 'newsroom',\n",
              " 'nsynth',\n",
              " 'nyu_depth_v2',\n",
              " 'omniglot',\n",
              " 'open_images_challenge2019_detection',\n",
              " 'open_images_v4',\n",
              " 'openbookqa',\n",
              " 'opinion_abstracts',\n",
              " 'opinosis',\n",
              " 'opus',\n",
              " 'oxford_flowers102',\n",
              " 'oxford_iiit_pet',\n",
              " 'para_crawl',\n",
              " 'patch_camelyon',\n",
              " 'paws_wiki',\n",
              " 'paws_x_wiki',\n",
              " 'pet_finder',\n",
              " 'pg19',\n",
              " 'places365_small',\n",
              " 'plant_leaves',\n",
              " 'plant_village',\n",
              " 'plantae_k',\n",
              " 'qa4mre',\n",
              " 'qasc',\n",
              " 'quickdraw_bitmap',\n",
              " 'radon',\n",
              " 'reddit',\n",
              " 'reddit_disentanglement',\n",
              " 'reddit_tifu',\n",
              " 'resisc45',\n",
              " 'robonet',\n",
              " 'rock_paper_scissors',\n",
              " 'rock_you',\n",
              " 'salient_span_wikipedia',\n",
              " 'samsum',\n",
              " 'savee',\n",
              " 'scan',\n",
              " 'scene_parse150',\n",
              " 'scicite',\n",
              " 'scientific_papers',\n",
              " 'sentiment140',\n",
              " 'shapes3d',\n",
              " 'smallnorb',\n",
              " 'snli',\n",
              " 'so2sat',\n",
              " 'speech_commands',\n",
              " 'spoken_digit',\n",
              " 'squad',\n",
              " 'stanford_dogs',\n",
              " 'stanford_online_products',\n",
              " 'starcraft_video',\n",
              " 'stl10',\n",
              " 'sun397',\n",
              " 'super_glue',\n",
              " 'svhn_cropped',\n",
              " 'ted_hrlr_translate',\n",
              " 'ted_multi_translate',\n",
              " 'tedlium',\n",
              " 'tf_flowers',\n",
              " 'the300w_lp',\n",
              " 'tiny_shakespeare',\n",
              " 'titanic',\n",
              " 'trec',\n",
              " 'trivia_qa',\n",
              " 'tydi_qa',\n",
              " 'uc_merced',\n",
              " 'ucf101',\n",
              " 'vctk',\n",
              " 'vgg_face2',\n",
              " 'visual_domain_decathlon',\n",
              " 'voc',\n",
              " 'voxceleb',\n",
              " 'voxforge',\n",
              " 'waymo_open_dataset',\n",
              " 'web_questions',\n",
              " 'wider_face',\n",
              " 'wiki40b',\n",
              " 'wikihow',\n",
              " 'wikipedia',\n",
              " 'wikipedia_toxicity_subtypes',\n",
              " 'wine_quality',\n",
              " 'winogrande',\n",
              " 'wmt14_translate',\n",
              " 'wmt15_translate',\n",
              " 'wmt16_translate',\n",
              " 'wmt17_translate',\n",
              " 'wmt18_translate',\n",
              " 'wmt19_translate',\n",
              " 'wmt_t2t_translate',\n",
              " 'wmt_translate',\n",
              " 'wordnet',\n",
              " 'xnli',\n",
              " 'xquad',\n",
              " 'xsum',\n",
              " 'yelp_polarity_reviews',\n",
              " 'yes_no']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# List all available datasets to see how the wikipedia dataset is called.\n",
        "tfds.list_builders()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gsqkLYgZ0-Lj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "54eecfe79eb94c5c99da114100bcc773",
            "ba9c35ae1b2d4d319c49e3e082ebd6a0",
            "d92aa3c2a711465d9231404fdb1b7d7c",
            "37081c453e7c4311aaf25248568da59f",
            "beac80ee20824617b033b3e46ca1c924",
            "7b24fba6a52049cf811bc7149ced948a",
            "768533de65524f5d9437f84d4ef7b78d",
            "78f5e7a5c7bc42c2aba4afd3ed3faa0c",
            "6b34d165ff304e9282c8e86dc83e23ff",
            "3dcccf36369a431b9ce8ba503c23d5a0",
            "71b63b483b2d407f8d1d5a686e4870c9"
          ]
        },
        "outputId": "a510073d-9606-4594-d6f8-56295177dba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset wikipedia/20190301.en/1.0.0 (download: 15.72 GiB, generated: Unknown size, total: 15.72 GiB) to tmp/wikipedia/20190301.en/1.0.0...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset wikipedia is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/258 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54eecfe79eb94c5c99da114100bcc773"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mDataset wikipedia downloaded and prepared to tmp/wikipedia/20190301.en/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Loading the wikipedia dataset.\n",
        "DATASET_NAME = 'wikipedia/20190301.en'\n",
        "# DATASET_NAME = 'wikipedia/20190301.uk'\n",
        "\n",
        "dataset, dataset_info = tfds.load(\n",
        "    name=DATASET_NAME,\n",
        "    data_dir='tmp',\n",
        "    with_info=True,\n",
        "    split=tfds.Split.TRAIN,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5nkTrRZ0-Ln",
        "outputId": "6855be56-c69f-4309-8727-07900af1b731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='wikipedia',\n",
            "    version=1.0.0,\n",
            "    description='Wikipedia dataset containing cleaned articles of all languages.\n",
            "The datasets are built from the Wikipedia dump\n",
            "(https://dumps.wikimedia.org/) with one split per language. Each example\n",
            "contains the content of one full Wikipedia article with cleaning to strip\n",
            "markdown and unwanted sections (references, etc.).',\n",
            "    homepage='https://dumps.wikimedia.org',\n",
            "    features=FeaturesDict({\n",
            "        'text': Text(shape=(), dtype=tf.string),\n",
            "        'title': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=5824596,\n",
            "    splits={\n",
            "        'train': 5824596,\n",
            "    },\n",
            "    supervised_keys=None,\n",
            "    citation=\"\"\"@ONLINE {wikidump,\n",
            "        author = \"Wikimedia Foundation\",\n",
            "        title  = \"Wikimedia Downloads\",\n",
            "        url    = \"https://dumps.wikimedia.org\"\n",
            "    }\"\"\",\n",
            "    redistribution_info=license: \"This work is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License. To view a copy of this license, visit http://creativecommons.org/licenses/by-sa/3.0/ or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\",\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(dataset_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A11MeAt0-Lr",
        "outputId": "146a2344-7541-4f66-d3f5-7b6b30f79c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec={'text': TensorSpec(shape=(), dtype=tf.string, name=None), 'title': TensorSpec(shape=(), dtype=tf.string, name=None)}>\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKTy6YS5Gx-g"
      },
      "source": [
        "## Analyze the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldLeTmcM0-Lu",
        "outputId": "22e670ec-9dbb-4961-fa95-2b621a48aad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of articles:  5824596\n"
          ]
        }
      ],
      "source": [
        "TRAIN_NUM_EXAMPLES = dataset_info.splits['train'].num_examples\n",
        "print('Total number of articles: ', TRAIN_NUM_EXAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHkz0ZHA0-Lz",
        "outputId": "4e9a6bb4-7dcf-4b87-cfa5-02f9974373ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First article \n",
            "======\n",
            "\n",
            "Title: \n",
            "------\n",
            "Joseph Greenberg\n",
            "\n",
            "Text: \n",
            "------\n",
            "Joseph Harold Greenberg (May 28, 1915 – May 7, 2001) was an American linguist, known mainly for his work concerning linguistic typology and the genetic classification of languages.\n",
            "\n",
            "Life\n",
            "\n",
            "Early life and education \n",
            "(Main source: Croft 2003)\n",
            "\n",
            "Joseph Greenberg was born on May 28, 1915 to Jewish parents in Brooklyn, New York. His first great interest was music. At the age of 14, he gave a piano concert in Steinway Hall. He continued to play the piano frequently throughout his life.\n",
            "\n",
            "After finishing high school, he decided to pursue a scholarly career rather than a musical one. He enrolled at Columbia University in New York. During his senior year, he attended a class taught by Franz Boas concerning American Indian languages. With references from Boas and Ruth Benedict, he was accepted as a graduate student by Melville J. Herskovits at Northwestern University in Chicago. During the course of his graduate studies, Greenberg did fieldwork among the Hausa people of Nigeria, where he learned the Hausa language. The subject of his doctoral dissertation was the influence of Islam on a Hausa group that, unlike most others, had not converted to it.\n",
            "\n",
            "During 1940, he began postdoctoral studies at Yale University. These were interrupted by service in the U.S. Army Signal Corps during World War II, for which he worked as a codebreaker and participated with the landing at Casablanca. Before leaving for Europe during 1943, Greenberg married Selma Berkowitz, whom he had met during his first year at Columbia University.\n",
            "\n",
            "Career\n",
            "After the war, Greenberg taught at the University of Minnesota before returning to Columbia University during 1948 as a teacher of anthropology. While in New York, he became acquainted with Roman Jakobson and André Martinet. They introduced him to the Prague school of structuralism, which influenced his work.\n",
            "\n",
            "During 1962, Greenberg relocated to the anthropology department of Stanford University in California, where he continued to work for the rest of his life. During 1965 Greenberg served as president of the African Studies Association. He received during 1996 the highest award for a scholar in Linguistics, the Gold Medal of Philology (http://insop.org/index.php?p=1_8_Ancient-Medal-Winners.).\n",
            "\n",
            "Contributions to linguistics\n",
            "\n",
            "Linguistic typology \n",
            "\n",
            "Greenberg's reputation rests partly on his contributions to synchronic linguistics and the quest to identify linguistic universals. During the late 1950s, Greenberg began to examine languages covering a wide geographic and genetic distribution. He located a number of interesting potential universals as well as many strong cross-linguistic tendencies.\n",
            "\n",
            "In particular, Greenberg conceptualized the idea of \"implicational universal\", which has the form, \"if a language has structure X, then it must also have structure Y.\" For example, X might be \"mid front rounded vowels\" and Y \"high front rounded vowels\" (for terminology see phonetics). Many scholars adopted this kind of research following Greenberg's example and it remains important in synchronic linguistics.\n",
            "\n",
            "Like Noam Chomsky, Greenberg sought to discover the universal structures on which human language is based. Unlike Chomsky, Greenberg's method was functionalist, rather than formalist. An argument to reconcile the Greenbergian and Chomskyan methods can be found in Linguistic Universals (2006), edited by Ricardo Mairal and Juana Gil .\n",
            "\n",
            "Many who are strongly opposed to Greenberg's methods of language classification (see below) acknowledge the importance of his typological work. During 1963 he published an article that was extremely influential: \"Some universals of grammar with particular reference to the order of meaningful elements\".\n",
            "\n",
            "Mass comparison \n",
            "\n",
            "Greenberg rejected the opinion, prevalent among linguists since the mid-20th century, that comparative reconstruction was the only method to discover relationships between languages. He argued that genetic classification is methodologically prior to comparative reconstruction, or the first stage of it: you cannot engage in the comparative reconstruction of languages until you know which languages to compare (1957:44).\n",
            "\n",
            "He also criticized the prevalent opinion that comprehensive comparisons of two languages at a time (which commonly take years to perform) could establish language families of any size. He argued that, even for 8 languages, there are already 4,140 ways to classify them into distinct families, while for 25 languages there are 4,749,027,089,305,918,018 ways (1957:44). For comparison, the Niger–Congo family is said to have some 1,500 languages. He thought language families of any size needed to be established by some scholastic means other than bilateral comparison. The theory of mass comparison is an attempt to demonstrate such means.\n",
            "\n",
            "Greenberg argued for the virtues of breadth over depth. He advocated restricting the amount of material to be compared (to basic vocabulary, morphology, and known paths of sound change) and increasing the number of languages to be compared to all the languages in a given area. This would make it possible to compare numerous languages reliably. At the same time, the process would provide a check on accidental resemblances through the sheer number of languages under review. The mathematical probability that resemblances are accidental decreases strongly with the number of languages concerned (1957:39).\n",
            "\n",
            "Greenberg used the premise that mass \"borrowing\" of basic vocabulary is unknown. He argued that borrowing, when it occurs, is concentrated in cultural vocabulary and clusters \"in certain semantic areas\", making it easy to detect (1957:39). With the goal of determining broad patterns of relationship, the idea was not to get every word right but to detect patterns. From the beginning with his theory of mass comparison, Greenberg addressed why chance resemblance and borrowing were not obstacles to its being useful. Despite that, critics consider those phenomena caused difficulties for his theory.\n",
            "\n",
            "Greenberg first termed his method \"mass comparison\" in an article of 1954 (reprinted in Greenberg 1955). As of 1987, he replaced the term \"mass comparison\" with \"multilateral comparison\", to emphasize its contrast with the bilateral comparisons recommended by linguistics textbooks. He believed that multilateral comparison was not in any way opposed to the comparative method, but is, on the contrary, its necessary first step (Greenberg, 1957:44). According to him, comparative reconstruction should have the status of an explanatory theory for facts already established by language classification (Greenberg, 1957:45).\n",
            "\n",
            "Most historical linguists (Campbell 2001:45) reject the use of mass comparison as a method for establishing genealogical relationships between languages. Among the most outspoken critics of mass comparison have been Lyle Campbell, Donald Ringe, William Poser, and the late R. Larry Trask.\n",
            "\n",
            "Genetic classification of languages\n",
            "\n",
            "The languages of Africa \n",
            "\n",
            "Greenberg is known widely for his development of a classification system for the languages of Africa, which he published as a series of articles in the Southwestern Journal of Anthropology from 1949 to 1954 (reprinted together as a book during 1955). He revised the book and published it again during 1963, followed by a nearly identical edition of 1966 (reprinted without change during 1970). A few more changes of the classification were made by Greenberg in an article during 1981.\n",
            "\n",
            "Greenberg grouped the hundreds of African languages into four families, which he dubbed Afroasiatic, Nilo-Saharan, Niger–Congo, and Khoisan. During the course of his work, Greenberg invented the term \"Afroasiatic\" to replace the earlier term \"Hamito-Semitic\", after showing that the Hamitic group, accepted widely since the 19th century, is not a valid language family. Another major feature of his work was to establish the classification of the Bantu languages, which occupy much of sub-Saharan Africa, as a part of the Niger–Congo language family, rather than as an independent family as many Bantuists had maintained.\n",
            "\n",
            "Greenberg's classification rested largely in evaluating competing earlier classifications. For a time, his classification was considered bold and speculative, especially the proposal of a Nilo-Saharan language family. Now, apart from Khoisan, it is generally accepted by African specialists and has been used as a basis for further work by other scholars.\n",
            "\n",
            "Greenberg's work on African languages has been criticised by Lyle Campbell and Donald Ringe, who do not believe that his classification is justified by his data; they request a reexamination of his macro-phyla by \"reliable methods\" (Ringe 1993:104). Harold Fleming and Lionel Bender, who are sympathetic to Greenberg's classification, acknowledge that at least some of his macrofamilies (particularly Nilo-Saharan and Khoisan) are not accepted completely by most linguists and may need to be divided (Campbell 1997). Their objection is methodological: if mass comparison is not a valid method, it cannot be expected to have brought order successfully out of the confusion of African languages.\n",
            "\n",
            "By contrast, some linguists have sought to combine Greenberg's four African families into larger units. In particular, Edgar Gregersen (1972) proposed joining Niger–Congo and Nilo-Saharan into a larger family, which he termed Kongo-Saharan. Roger Blench (1995) suggests Niger–Congo is a subfamily of Nilo-Saharan.\n",
            "\n",
            "The languages of New Guinea, Tasmania, and the Andaman Islands\n",
            "\n",
            "During 1971 Greenberg proposed the Indo-Pacific macrofamily, which groups together the Papuan languages (a large number of language families of New Guinea and nearby islands) with the native languages of the Andaman Islands and Tasmania but excludes the Australian Aboriginal languages. Its principal feature was to reduce the manifold language families of New Guinea to a single genetic unit. This excludes the Austronesian languages, which have been established as associated with a more recent migration of people.\n",
            "\n",
            "Greenberg's subgrouping of these languages has not been accepted by the few specialists who have worked on the classification of these languages. However, the work of Stephen Wurm (1982) and Malcolm Ross (2005) has provided considerable evidence for his once-radical idea that these languages form a single genetic unit. Wurm stated that the lexical similarities between Great Andamanese and the West Papuan and Timor–Alor families \"are quite striking and amount to virtual formal identity [...] in a number of instances.\" He believes this to be due to a linguistic substratum.\n",
            "\n",
            "The languages of the Americas\n",
            "\n",
            "Most linguists concerned with the native languages of the Americas classify them into 150 to 180 independent language families. Some believe that two language families, Eskimo–Aleut and Na-Dené, were distinct, perhaps the results of later migrations into the New World.\n",
            "\n",
            "Early on, Greenberg (1957:41, 1960) became convinced that many of the language groups considered unrelated could be classified into larger groupings. In his 1987 book Language in the Americas, while agreeing that the Eskimo–Aleut and Na-Dené groupings as distinct, he proposed that all the other Native American languages belong to a single language macro-family, which he termed Amerind.\n",
            "\n",
            "Language in the Americas has generated lively debate, but has been criticized strongly; it is rejected by most specialists of indigenous languages of the Americas and also by most historical linguists. Specialists of the individual language families have found extensive inaccuracies and errors in Greenberg's data, such as including data from non-existent languages, erroneous transcriptions of the forms compared, misinterpretations of the meanings of words used for comparison, and entirely spurious forms.\n",
            "\n",
            "Historical linguists also reject the validity of the method of multilateral (or mass) comparison upon which the classification is based. They argue that he has not provided a convincing case that the similarities presented as evidence are due to inheritance from an earlier common ancestor rather than being explained by a combination of errors, accidental similarity, excessive semantic latitude in comparisons, borrowings, onomatopoeia, etc.\n",
            "\n",
            "The languages of northern Eurasia \n",
            "\n",
            "Later in his life, Greenberg proposed that nearly all of the language families of northern Eurasia belong to a single higher-order family, which he termed Eurasiatic. The only exception was Yeniseian, which has been related to a wider Dené–Caucasian grouping, also including Sino-Tibetan.  During 2008 Edward Vajda related Yeniseian to the Na-Dené languages of North America as a Dené–Yeniseian family.\n",
            "\n",
            "The Eurasiatic grouping resembles the older Nostratic groupings of Holger Pedersen and Vladislav Illich-Svitych by including Indo-European, Uralic, and Altaic. It differs by including Nivkh, Japonic, Korean, and Ainu (which the Nostraticists had excluded from comparison because they are single languages rather than language families) and in excluding Afroasiatic. At about this time, Russian Nostraticists, notably Sergei Starostin, constructed a revised version of Nostratic. It was slightly larger than Greenberg's grouping but it also excluded Afroasiatic.\n",
            "\n",
            "Recently, a consensus has been emerging among proponents of the Nostratic hypothesis. Greenberg basically agreed with the Nostratic concept, though he stressed a deep internal division between its northern 'tier' (his Eurasiatic) and a southern 'tier' (principally Afroasiatic and Dravidian).\n",
            "\n",
            "The American Nostraticist Allan Bomhard considers Eurasiatic a branch of Nostratic, alongside other branches: Afroasiatic, Elamo-Dravidian, and Kartvelian. Similarly, Georgiy Starostin (2002) arrives at a tripartite overall grouping: he considers Afroasiatic, Nostratic and Elamite to be roughly equidistant and more closely related to each other than to any other language family. Sergei Starostin's school has now included Afroasiatic in a broadly defined Nostratic. They reserve the term Eurasiatic to designate the narrower subgrouping, which comprises the rest of the macrofamily. Recent proposals thus differ mainly on the precise inclusion of Dravidian and Kartvelian.\n",
            "\n",
            "Greenberg continued to work on this project after he was diagnosed with incurable pancreatic cancer and until he died during May 2001. His colleague and former student Merritt Ruhlen ensured the publication of the final volume of his Eurasiatic work (2002) after his death.\n",
            "\n",
            "Selected works by Joseph H. Greenberg\n",
            "\n",
            "Books \n",
            "  (Photo-offset reprint of the SJA articles with minor corrections.)\n",
            " \n",
            "  (Heavily revised version of Greenberg 1955. From the same publisher: second, revised edition, 1966; third edition, 1970. All three editions simultaneously published at The Hague by Mouton & Co.)\n",
            "  (Reprinted 1980 and, with a foreword by Martin Haspelmath, 2005.)\n",
            "\n",
            "Books (editor) \n",
            "  (Second edition 1966.)\n",
            "\n",
            "Articles, reviews, etc. \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  (Reprinted in Genetic Linguistics, 2005.)\n",
            " \n",
            "  (In second edition of Universals of Language, 1966: pp. 73–113.)\n",
            " \n",
            " \n",
            "  (Reprinted in Genetic Linguistics, 2005.)\n",
            "\n",
            "Bibliography\n",
            "\n",
            "Blench, Roger. 1995. \"Is Niger–Congo simply a branch of Nilo-Saharan?\" In Fifth Nilo-Saharan Linguistics Colloquium, Nice, 24–29 August 1992: Proceedings, edited by Robert Nicolaï and Franz Rottland. Cologne: Köppe Verlag, pp. 36–49.\n",
            "\n",
            "Campbell, Lyle. 1997. American Indian Languages: The Historical Linguistics of Native America. New York: Oxford University Press. .\n",
            "Campbell, Lyle. 2001. \"Beyond the comparative method.\" In Historical Linguistics 2001: Selected Papers from the 15th International Conference on Historical Linguistics, Melbourne, 13–17 August 2001, edited by Barry J. Blake, Kate Burridge, and Jo Taylor.\n",
            "Diamond, Jared. 1997. Guns, Germs and Steel: The Fates of Human Societies. New York: Norton. .\n",
            "\n",
            "Mairal, Ricardo and Juana Gil. 2006. Linguistic Universals. Cambridge–NY: Cambridge University Press. .\n",
            "\n",
            "Ross, Malcolm. 2005. \"Pronouns as a preliminary diagnostic for grouping Papuan languages.\" In Papuan Pasts: Cultural, Linguistic and Biological Histories of Papuan-speaking Peoples, edited by Andrew Pawley, Robert Attenborough, Robin Hide, and Jack Golson. Canberra: Pacific Linguistics, pp. 15–66.\n",
            "Wurm, Stephen A. 1982. The Papuan Languages of Oceania. Tübingen: Gunter Narr.\n",
            "\n",
            "See also\n",
            "\n",
            "Linguistic universal\n",
            "Monogenesis (linguistics)\n",
            "Nostratic languages\n",
            "\n",
            "References\n",
            "\n",
            "External links\n",
            "Joseph Greenberg at work; a portrait of himself\n",
            "\"What we all spoke when the world was young\" by Nicholas Wade, New York Times (February 1, 2000)\n",
            "Obituary from Stanford Report\n",
            "Memorial Resolution\n",
            "\"Joseph Harold Greenberg\" by William Croft (2003) (also: )\n",
            "\"Complete bibliography of the publications of Joseph H. Greenberg\" by William Croft (2003)\n",
            "\n",
            "Category:1915 births\n",
            "Category:2001 deaths\n",
            "Category:Linguists from the United States\n",
            "Category:American Africanists\n",
            "Category:American Jews in the military\n",
            "Category:Paleolinguists\n",
            "Category:Columbia University faculty\n",
            "Category:Stanford University Department of Anthropology faculty\n",
            "Category:Fellows of the American Academy of Arts and Sciences\n",
            "Category:Members of the United States National Academy of Sciences\n",
            "Category:United States Army personnel\n",
            "Category:American army personnel of World War II\n",
            "Category:Guggenheim Fellows\n",
            "Category:American expatriates in Nigeria\n",
            "Category:People from Brooklyn\n",
            "Category:Linguists of Na-Dene languages\n",
            "Category:Linguists of Eskimo–Aleut languages\n",
            "Category:Linguists of Hokan languages\n",
            "Category:Jewish scientists\n",
            "Category:Linguists of Papuan languages\n",
            "Category:Linguists of Amerind languages\n",
            "Category:Linguists of Andamanese languages\n",
            "Category:Linguists of Tasmanian languages\n",
            "Category:Linguists of Niger–Congo languages\n",
            "Category:Linguists of Afroasiatic languages\n",
            "Category:Linguistic Society of America presidents\n"
          ]
        }
      ],
      "source": [
        "print('First article','\\n======\\n')\n",
        "for example in dataset.take(1):\n",
        "    print('Title:','\\n------')\n",
        "    print(example['title'].numpy().decode('utf-8'))\n",
        "    print()\n",
        "\n",
        "    print('Text:', '\\n------')\n",
        "    print(example['text'].numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqpuKh9HMNnf"
      },
      "source": [
        "## Process the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK_FFy7P0-L3"
      },
      "source": [
        "### Flatten the dataset\n",
        "\n",
        "Converting the dataset from the set of articles into the set of characters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AC6MHFC0-L3",
        "outputId": "3714cc7f-27b2-4c1a-8585-0a2dd9f342fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'J' b'o' b's' ... b'n' b't' b's']\n",
            "\n",
            "\n",
            "[b'P' b'a' b'u' ... b'e' b'r' b's']\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def article_to_text(text):\n",
        "    return np.array([char for char in text.numpy().decode('utf-8')])\n",
        "\n",
        "# Converting each dataset item to a string ('text') instead of a dictionary ({'text', 'title'}).\n",
        "dataset_text = dataset.map(\n",
        "    lambda article: tf.py_function(func=article_to_text, inp=[article['text']], Tout=tf.string)\n",
        ")\n",
        "\n",
        "for text in dataset_text.take(2):\n",
        "    print(text.numpy())\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSsSbJbX0-L8",
        "outputId": "d58f6525-0c88-4900-a6a5-8a08f5570b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J\n",
            "o\n",
            "s\n",
            "e\n",
            "p\n",
            "h\n",
            " \n",
            "H\n",
            "a\n",
            "r\n",
            "o\n",
            "l\n",
            "d\n",
            " \n",
            "G\n",
            "r\n",
            "e\n",
            "e\n",
            "n\n",
            "b\n"
          ]
        }
      ],
      "source": [
        "# Unbatch the text dataset into a more granular char dataset.\n",
        "# Now each dataset item is one character instead of a big piece of text.\n",
        "dataset_chars = dataset_text.unbatch()\n",
        "\n",
        "for char in dataset_chars.take(20):\n",
        "    print(char.numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHNkkXGz0-L_"
      },
      "source": [
        "### Generating vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7rnYLeU0-MA",
        "outputId": "19acd58b-8ce4-4ec5-e8f3-a490f58fe11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique characters: 621\n",
            "vocab:\n",
            "['\\t', '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\xa0', '£', '§', '«', '®', '°', '±', '²', '·', '»', '¼', '½', '¿', 'Á', 'Å', 'Æ', 'Ç', 'É', 'Ë', 'Í', 'Î', 'Ó', 'Ö', '×', 'Ø', 'Ü', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ú', 'û', 'ü', 'ý', 'ā', 'ă', 'ą', 'Ć', 'ć', 'Č', 'č', 'đ', 'ė', 'ę', 'ě', 'ğ', 'ġ', 'Ħ', 'ī', 'İ', 'ı', 'ļ', 'Ł', 'ł', 'ń', 'ň', 'Ō', 'ō', 'ő', 'ř', 'Ś', 'ś', 'Ş', 'ş', 'Š', 'š', 'ţ', 'ū', 'ź', 'ż', 'Ž', 'ž', 'ơ', 'ư', 'ǔ', 'ș', 'ț', 'ɔ', 'ə', 'ɛ', 'ʷ', 'ʼ', 'ʿ', '˚', 'Ι', 'Π', 'α', 'β', 'ε', 'η', 'ι', 'κ', 'μ', 'ο', 'ρ', 'ς', 'τ', 'υ', 'χ', 'ψ', 'ό', 'Б', 'В', 'Д', 'Ж', 'З', 'И', 'К', 'Л', 'М', 'Н', 'О', 'П', 'С', 'У', 'Ф', 'Х', 'а', 'б', 'в', 'г', 'д', 'е', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'ю', 'я', 'і', 'ј', 'ћ', 'ּ', 'א', 'ב', 'ג', 'ו', 'ט', 'י', 'ך', 'ל', 'מ', 'נ', 'ס', 'ע', 'פ', 'ץ', 'צ', 'ק', 'ר', 'ת', 'װ', '،', 'أ', 'إ', 'ا', 'ب', 'ة', 'ت', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'س', 'ش', 'ص', 'ط', 'ع', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ي', 'پ', 'ک', 'அ', 'ஆ', 'இ', 'க', 'ச', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ா', 'ி', 'ு', 'ே', 'ை', 'ொ', '்', 'ಡ', 'ಮ', 'ರ', 'ಲ', 'ಸ', 'ಿ', 'ก', 'ข', 'ค', 'ง', 'จ', 'ช', 'ฒ', 'ณ', 'ด', 'ต', 'ท', 'ธ', 'น', 'บ', 'ป', 'ผ', 'พ', 'ภ', 'ม', 'ย', 'ร', 'ฤ', 'ล', 'ว', 'ศ', 'ส', 'ห', 'อ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ื', 'ุ', 'ู', 'เ', 'แ', 'โ', 'ไ', '่', '้', '์', 'ზ', 'უ', 'ფ', 'ḩ', 'ḻ', 'ṟ', 'ṣ', 'ṭ', 'ạ', 'ễ', 'ệ', 'ὶ', '\\u200e', '–', '—', '‘', '’', '“', '”', '†', '‡', '•', '…', '′', '″', '₨', '€', '₱', '℃', 'ℓ', '№', '™', '→', '−', '≠', '♠', '♦', '➔', '\\u3000', 'り', 'ア', 'イ', 'ウ', 'カ', 'ク', 'コ', 'シ', 'ズ', 'ゼ', 'ソ', 'タ', 'チ', 'ッ', 'ツ', 'パ', 'ボ', 'マ', 'ム', 'ャ', 'ョ', 'リ', 'レ', 'ン', 'ー', '一', '三', '上', '下', '东', '中', '主', '义', '九', '乡', '事', '介', '伐', '会', '依', '俳', '僧', '光', '児', '全', '六', '兴', '其', '典', '况', '前', '加', '勇', '務', '化', '华', '単', '卡', '厂', '双', '句', '史', '号', '吉', '吹', '哈', '哪', '国', '國', '地', '坝', '坪', '堡', '大', '姚', '子', '孤', '安', '宗', '家', '寄', '寨', '射', '局', '屋', '岩', '島', '左', '巴', '師', '店', '庙', '延', '建', '得', '心', '怡', '排', '探', '教', '数', '文', '斌', '新', '方', '日', '昌', '明', '春', '昭', '普', '會', '本', '李', '村', '板', '桦', '概', '民', '水', '江', '法', '泥', '泽', '湾', '溪', '潭', '澤', '濟', '無', '燈', '界', '皮', '石', '砲', '磨', '禪', '站', '维', '置', '義', '羹', '育', '胜', '臨', '花', '茜', '莲', '華', '董', '薦', '薩', '虚', '街', '装', '覺', '解', '訪', '語', '话', '语', '赤', '転', '軽', '辞', '農', '达', '逆', '通', '造', '連', '道', '那', '鄉', '里', '野', '録', '镇', '长', '門', '陈', '食', '馬', '马', '鹿', '黄', '김', '준', '태', 'ﬂ', '）', '｜']\n"
          ]
        }
      ],
      "source": [
        "vocab = set()\n",
        "\n",
        "# Ideally we should take all dataset items into account here.\n",
        "for text in dataset_text.take(1000):\n",
        "    vocab.update([char.decode('utf-8') for char in text.numpy()])\n",
        "    \n",
        "vocab = sorted(vocab)\n",
        "\n",
        "print('Unique characters: {}'.format(len(vocab)))\n",
        "print('vocab:')\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dj4e-AGMaV4"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before feeding the text to our RNN we need to convert the text from a sequence of characters to a sequence of numbers. To do so detect all unique characters in the text, form a vocabulary out of it and replace each character with its index in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFFpuXfGMPq2",
        "outputId": "f4e3f23d-4410-4ba8-91b8-e411d0c6cb0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\t':   0,\n",
            "  '\\n':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '\"' :   4,\n",
            "  '#' :   5,\n",
            "  '$' :   6,\n",
            "  '%' :   7,\n",
            "  '&' :   8,\n",
            "  \"'\" :   9,\n",
            "  '(' :  10,\n",
            "  ')' :  11,\n",
            "  '*' :  12,\n",
            "  '+' :  13,\n",
            "  ',' :  14,\n",
            "  '-' :  15,\n",
            "  '.' :  16,\n",
            "  '/' :  17,\n",
            "  '0' :  18,\n",
            "  '1' :  19,\n",
            "  '2' :  20,\n",
            "  '3' :  21,\n",
            "  '4' :  22,\n",
            "  '5' :  23,\n",
            "  '6' :  24,\n",
            "  '7' :  25,\n",
            "  '8' :  26,\n",
            "  '9' :  27,\n",
            "  ':' :  28,\n",
            "  ';' :  29,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Map characters to their indices in vocabulary.\n",
        "char2index = {char: index for index, char in enumerate(vocab)}\n",
        "\n",
        "print('{')\n",
        "for char, _ in zip(char2index, range(30)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2index[char]))\n",
        "print('  ...\\n}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQB33zI7NkRo",
        "outputId": "2b95fe08-9ad7-4cfe-e522-bab51ad2af83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\t' '\\n' ' ' '!' '\"' '#' '$' '%' '&' \"'\" '(' ')' '*' '+' ',' '-' '.' '/'\n",
            " '0' '1' '2' '3' '4' '5' '6' '7' '8' '9' ':' ';' '<' '=' '>' '?' '@' 'A'\n",
            " 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S'\n",
            " 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' '[' ']' '^' '_' '`' 'a' 'b' 'c' 'd' 'e' 'f'\n",
            " 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x'\n",
            " 'y' 'z' '{' '|' '}' '~' '\\xa0' '£' '§' '«' '®' '°' '±' '²' '·' '»' '¼'\n",
            " '½' '¿' 'Á' 'Å' 'Æ' 'Ç' 'É' 'Ë' 'Í' 'Î' 'Ó' 'Ö' '×' 'Ø' 'Ü' 'Þ' 'ß' 'à'\n",
            " 'á' 'â' 'ã' 'ä' 'å' 'æ' 'ç' 'è' 'é' 'ê' 'ë' 'ì' 'í' 'î' 'ï' 'ñ' 'ò' 'ó'\n",
            " 'ô' 'õ' 'ö' 'ø' 'ú' 'û' 'ü' 'ý' 'ā' 'ă' 'ą' 'Ć' 'ć' 'Č' 'č' 'đ' 'ė' 'ę'\n",
            " 'ě' 'ğ' 'ġ' 'Ħ' 'ī' 'İ' 'ı' 'ļ' 'Ł' 'ł' 'ń' 'ň' 'Ō' 'ō' 'ő' 'ř' 'Ś' 'ś'\n",
            " 'Ş' 'ş' 'Š' 'š' 'ţ' 'ū' 'ź' 'ż' 'Ž' 'ž' 'ơ' 'ư' 'ǔ' 'ș' 'ț' 'ɔ' 'ə' 'ɛ'\n",
            " 'ʷ' 'ʼ' 'ʿ' '˚' 'Ι' 'Π' 'α' 'β' 'ε' 'η' 'ι' 'κ' 'μ' 'ο' 'ρ' 'ς' 'τ' 'υ'\n",
            " 'χ' 'ψ' 'ό' 'Б' 'В' 'Д' 'Ж' 'З' 'И' 'К' 'Л' 'М' 'Н' 'О' 'П' 'С' 'У' 'Ф'\n",
            " 'Х' 'а' 'б' 'в' 'г' 'д' 'е' 'з' 'и' 'й' 'к' 'л' 'м' 'н' 'о' 'п' 'р' 'с'\n",
            " 'т' 'у' 'ф' 'х' 'ц' 'ч' 'ш' 'щ' 'ъ' 'ы' 'ь' 'ю' 'я' 'і' 'ј' 'ћ' 'ּ' 'א'\n",
            " 'ב' 'ג' 'ו' 'ט' 'י' 'ך' 'ל' 'מ' 'נ' 'ס' 'ע' 'פ' 'ץ' 'צ' 'ק' 'ר' 'ת' 'װ'\n",
            " '،' 'أ' 'إ' 'ا' 'ب' 'ة' 'ت' 'ج' 'ح' 'خ' 'د' 'ذ' 'ر' 'س' 'ش' 'ص' 'ط' 'ع'\n",
            " 'ف' 'ق' 'ل' 'م' 'ن' 'ه' 'و' 'ي' 'پ' 'ک' 'அ' 'ஆ' 'இ' 'க' 'ச' 'ட' 'ண' 'த'\n",
            " 'ந' 'ன' 'ப' 'ம' 'ர' 'ற' 'ல' 'ள' 'ழ' 'வ' 'ா' 'ி' 'ு' 'ே' 'ை' 'ொ' '்' 'ಡ'\n",
            " 'ಮ' 'ರ' 'ಲ' 'ಸ' 'ಿ' 'ก' 'ข' 'ค' 'ง' 'จ' 'ช' 'ฒ' 'ณ' 'ด' 'ต' 'ท' 'ธ' 'น'\n",
            " 'บ' 'ป' 'ผ' 'พ' 'ภ' 'ม' 'ย' 'ร' 'ฤ' 'ล' 'ว' 'ศ' 'ส' 'ห' 'อ' 'ะ' 'ั' 'า'\n",
            " 'ำ' 'ิ' 'ี' 'ื' 'ุ' 'ู' 'เ' 'แ' 'โ' 'ไ' '่' '้' '์' 'ზ' 'უ' 'ფ' 'ḩ' 'ḻ'\n",
            " 'ṟ' 'ṣ' 'ṭ' 'ạ' 'ễ' 'ệ' 'ὶ' '\\u200e' '–' '—' '‘' '’' '“' '”' '†' '‡' '•'\n",
            " '…' '′' '″' '₨' '€' '₱' '℃' 'ℓ' '№' '™' '→' '−' '≠' '♠' '♦' '➔' '\\u3000'\n",
            " 'り' 'ア' 'イ' 'ウ' 'カ' 'ク' 'コ' 'シ' 'ズ' 'ゼ' 'ソ' 'タ' 'チ' 'ッ' 'ツ' 'パ' 'ボ' 'マ'\n",
            " 'ム' 'ャ' 'ョ' 'リ' 'レ' 'ン' 'ー' '一' '三' '上' '下' '东' '中' '主' '义' '九' '乡' '事'\n",
            " '介' '伐' '会' '依' '俳' '僧' '光' '児' '全' '六' '兴' '其' '典' '况' '前' '加' '勇' '務'\n",
            " '化' '华' '単' '卡' '厂' '双' '句' '史' '号' '吉' '吹' '哈' '哪' '国' '國' '地' '坝' '坪'\n",
            " '堡' '大' '姚' '子' '孤' '安' '宗' '家' '寄' '寨' '射' '局' '屋' '岩' '島' '左' '巴' '師'\n",
            " '店' '庙' '延' '建' '得' '心' '怡' '排' '探' '教' '数' '文' '斌' '新' '方' '日' '昌' '明'\n",
            " '春' '昭' '普' '會' '本' '李' '村' '板' '桦' '概' '民' '水' '江' '法' '泥' '泽' '湾' '溪'\n",
            " '潭' '澤' '濟' '無' '燈' '界' '皮' '石' '砲' '磨' '禪' '站' '维' '置' '義' '羹' '育' '胜'\n",
            " '臨' '花' '茜' '莲' '華' '董' '薦' '薩' '虚' '街' '装' '覺' '解' '訪' '語' '话' '语' '赤'\n",
            " '転' '軽' '辞' '農' '达' '逆' '通' '造' '連' '道' '那' '鄉' '里' '野' '録' '镇' '长' '門'\n",
            " '陈' '食' '馬' '马' '鹿' '黄' '김' '준' '태' 'ﬂ' '）' '｜']\n"
          ]
        }
      ],
      "source": [
        "# Map character indices to characters from vacabulary.\n",
        "index2char = np.array(vocab)\n",
        "\n",
        "print(index2char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXUAlYmvN_Rj",
        "outputId": "17f9f67b-26a4-4519-90e2-ac1b354d8d8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL CHARS: \n",
            "---\n",
            "J\n",
            "o\n",
            "s\n",
            "e\n",
            "p\n",
            "h\n",
            " \n",
            "H\n",
            "a\n",
            "r\n",
            "\n",
            "\n",
            "\n",
            "INDEXED CHARS: \n",
            "---\n",
            "44\n",
            "80\n",
            "84\n",
            "70\n",
            "81\n",
            "73\n",
            "2\n",
            "42\n",
            "66\n",
            "83\n",
            "80\n",
            "77\n",
            "69\n",
            "2\n",
            "41\n",
            "83\n",
            "70\n",
            "70\n",
            "79\n",
            "67\n"
          ]
        }
      ],
      "source": [
        "def char_to_index(char):\n",
        "    char_symbol = char.numpy().decode('utf-8')\n",
        "    char_index = char2index[char_symbol] if char_symbol in char2index else char2index['?']\n",
        "    return char_index\n",
        "\n",
        "dataset_chars_indexed = dataset_chars.map(\n",
        "    lambda char: tf.py_function(func=char_to_index, inp=[char], Tout=tf.int32)\n",
        ")\n",
        "\n",
        "print('ORIGINAL CHARS:', '\\n---')\n",
        "for char in dataset_chars.take(10):\n",
        "    print(char.numpy().decode())\n",
        "\n",
        "print('\\n\\n')    \n",
        "    \n",
        "print('INDEXED CHARS:', '\\n---')\n",
        "for char_index in dataset_chars_indexed.take(20):\n",
        "    print(char_index.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHv5HhUuTQYS"
      },
      "source": [
        "## Create training sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rpdFJJc90-ML"
      },
      "outputs": [],
      "source": [
        "# The maximum length sentence we want for a single input in characters.\n",
        "sequence_length = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap71VjB2Vuct",
        "outputId": "fcfa63e1-075f-4ee3-d34d-6fec6942d911"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Joseph Harold Greenberg (May 28, 1915 – May 7, 2001) was an American linguist, known mainly for his work concerning linguistic typology and the genetic classification of languages.\\n\\nLife\\n\\nEarly life an'\n",
            "\n",
            "'d education \\n(Main source: Croft 2003)\\n\\nJoseph Greenberg was born on May 28, 1915 to Jewish parents in Brooklyn, New York. His first great interest was music. At the age of 14, he gave a piano concert '\n",
            "\n",
            "'in Steinway Hall. He continued to play the piano frequently throughout his life.\\n\\nAfter finishing high school, he decided to pursue a scholarly career rather than a musical one. He enrolled at Columbia'\n",
            "\n",
            "' University in New York. During his senior year, he attended a class taught by Franz Boas concerning American Indian languages. With references from Boas and Ruth Benedict, he was accepted as a graduat'\n",
            "\n",
            "'e student by Melville J. Herskovits at Northwestern University in Chicago. During the course of his graduate studies, Greenberg did fieldwork among the Hausa people of Nigeria, where he learned the Hau'\n",
            "\n",
            "'sa language. The subject of his doctoral dissertation was the influence of Islam on a Hausa group that, unlike most others, had not converted to it.\\n\\nDuring 1940, he began postdoctoral studies at Yale '\n",
            "\n",
            "'University. These were interrupted by service in the U.S. Army Signal Corps during World War II, for which he worked as a codebreaker and participated with the landing at Casablanca. Before leaving for'\n",
            "\n",
            "' Europe during 1943, Greenberg married Selma Berkowitz, whom he had met during his first year at Columbia University.\\n\\nCareer\\nAfter the war, Greenberg taught at the University of Minnesota before retur'\n",
            "\n",
            "'ning to Columbia University during 1948 as a teacher of anthropology. While in New York, he became acquainted with Roman Jakobson and André Martinet. They introduced him to the Prague school of structu'\n",
            "\n",
            "'ralism, which influenced his work.\\n\\nDuring 1962, Greenberg relocated to the anthropology department of Stanford University in California, where he continued to work for the rest of his life. During 196'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate batched sequences out of the char_dataset.\n",
        "sequences = dataset_chars_indexed.batch(sequence_length + 1, drop_remainder=True)\n",
        "\n",
        "# Sequences examples.\n",
        "for item in sequences.take(10):\n",
        "    print(repr(''.join(index2char[item.numpy()])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8spPCfe-iTn"
      },
      "outputs": [],
      "source": [
        "# sequences shape:\n",
        "# - Each sequence of length 101\n",
        "#\n",
        "#    201     201          201\n",
        "# [(.....) (.....) ...  (.....)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdcrcUs4Xxso"
      },
      "source": [
        "For each sequence, duplicate and shift it to form the input and target text. For example, say `sequence_length` is `4` and text is `Hello`. The input sequence would be `Hell`, and the target sequence `ello`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9fxvXsP0XFDh"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "454rWIQYXXRY"
      },
      "outputs": [],
      "source": [
        "dataset_sequences = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuoh4tCdYCck",
        "outputId": "0df68b12-2c74-4562-cd6a-9279371209d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence size: 200\n",
            "Target sequence size: 200\n",
            "\n",
            "Input:\n",
            " 'Joseph Harold Greenberg (May 28, 1915 – May 7, 2001) was an American linguist, known mainly for his work concerning linguistic typology and the genetic classification of languages.\\n\\nLife\\n\\nEarly life a'\n",
            "\n",
            "Target:\n",
            " 'oseph Harold Greenberg (May 28, 1915 – May 7, 2001) was an American linguist, known mainly for his work concerning linguistic typology and the genetic classification of languages.\\n\\nLife\\n\\nEarly life an'\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset_sequences.take(1):\n",
        "    print('Input sequence size:', repr(len(input_example.numpy())))\n",
        "    print('Target sequence size:', repr(len(target_example.numpy())))\n",
        "    print()\n",
        "    print('Input:\\n', repr(''.join(index2char[input_example.numpy()])))\n",
        "    print()\n",
        "    print('Target:\\n', repr(''.join(index2char[target_example.numpy()])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp0tl0sN807l"
      },
      "outputs": [],
      "source": [
        "# dataset shape:\n",
        "# - Each sequence is a tuple of 2 sub-sequences of length 100 (input_text and target_text)\n",
        "#\n",
        "#    200       200           200\n",
        "# /(.....)\\ /(.....)\\ ... /(.....)\\  <-- input_text\n",
        "# \\(.....)/ \\(.....)/     \\(.....)/  <-- target_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDYHEJ0pY1ai"
      },
      "source": [
        "Each index of these vectors are processed as one time step. For the input at time step 0, the model receives the index for \"F\" and trys to predict the index for \"i\" as the next character. At the next timestep, it does the same thing but the RNN considers the previous step context in addition to the current input character."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-0zpv53Y2o4",
        "outputId": "0167f7ba-2b3d-4bf2-d098-186eebedb3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step #0\n",
            "  input: 44 ('J')\n",
            "  expected output: 80 ('o')\n",
            "\n",
            "Step #1\n",
            "  input: 80 ('o')\n",
            "  expected output: 84 ('s')\n",
            "\n",
            "Step #2\n",
            "  input: 84 ('s')\n",
            "  expected output: 70 ('e')\n",
            "\n",
            "Step #3\n",
            "  input: 70 ('e')\n",
            "  expected output: 81 ('p')\n",
            "\n",
            "Step #4\n",
            "  input: 81 ('p')\n",
            "  expected output: 73 ('h')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print('Step #{:1d}'.format(i))\n",
        "    print('  input: {} ({:s})'.format(input_idx, repr(index2char[input_idx])))\n",
        "    print('  expected output: {} ({:s})'.format(target_idx, repr(index2char[target_idx])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDlp40lC5YB"
      },
      "source": [
        "## Split training sequences into batches\n",
        "\n",
        "Split the text into manageable sequences. But before feeding this data into the model, shuffle the data and pack it into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDq-wa5EC3wW",
        "outputId": "b89adb53-aa12-41a3-d4b6-105755767328"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.int32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Batch size.\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset (TF data is designed to work\n",
        "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in\n",
        "# which it shuffles elements).\n",
        "BUFFER_SIZE = 100\n",
        "\n",
        "# How many items to prefetch before the next iteration.\n",
        "PREFETCH_SIZE = 10\n",
        "\n",
        "dataset_sequence_batches = dataset_sequences \\\n",
        "    .shuffle(BUFFER_SIZE) \\\n",
        "    .batch(BATCH_SIZE, drop_remainder=True) \\\n",
        "    .prefetch(PREFETCH_SIZE)\n",
        "\n",
        "dataset_sequence_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_kYgvQGBO0U",
        "outputId": "264f6147-2f5f-49f6-c792-6a440c67005b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st batch: input_text: tf.Tensor(\n",
            "[[ 2 84 66 ... 77 78 66]\n",
            " [ 2 53 85 ... 66 85  2]\n",
            " [86 69 70 ... 37 66 79]\n",
            " ...\n",
            " [28 49 71 ... 85 83 66]\n",
            " [70 83 84 ... 74 66 85]\n",
            " [70  2 50 ... 73 70  2]], shape=(64, 200), dtype=int32)\n",
            "\n",
            "1st batch: target_text: tf.Tensor(\n",
            "[[84 66 78 ... 78 66 85]\n",
            " [53 85 70 ... 85  2 88]\n",
            " [69 70 79 ... 66 79 66]\n",
            " ...\n",
            " [49 71 71 ... 83 66 79]\n",
            " [83 84  1 ... 66 85 70]\n",
            " [ 2 50 66 ... 70  2 73]], shape=(64, 200), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for input_text, target_text in dataset_sequence_batches.take(1):\n",
        "    print('1st batch: input_text:', input_text)\n",
        "    print()\n",
        "    print('1st batch: target_text:', target_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkDCH15v_2I6"
      },
      "outputs": [],
      "source": [
        "# dataset shape:\n",
        "# - 64 sequences per batch\n",
        "# - Each sequence is a tuple of 2 sub-sequences of length 100 (input_text and target_text)\n",
        "#\n",
        "#\n",
        "#     200       200           200             200       200           200\n",
        "# |/(.....)\\ /(.....)\\ ... /(.....)\\| ... |/(.....)\\ /(.....)\\ ... /(.....)\\|  <-- input_text\n",
        "# |\\(.....)/ \\(.....)/     \\(.....)/| ... |\\(.....)/ \\(.....)/     \\(.....)/|  <-- target_text\n",
        "#\n",
        "# <------------- 64 ---------------->     <------------- 64 ---------------->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghB-VwLlD-Oz"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "I7ZuvZHBD_pS"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in chars.\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension.\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units.\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-sojdDCAICWO"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Embedding(\n",
        "      input_dim=vocab_size,\n",
        "      output_dim=embedding_dim,\n",
        "      batch_input_shape=[batch_size, None]\n",
        "    ))\n",
        "    \n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "      units=rnn_units,\n",
        "      return_sequences=True,\n",
        "      stateful=True,\n",
        "      recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
        "    ))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(vocab_size))\n",
        "  \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XoPwxyAPEg6z"
      },
      "outputs": [],
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLnlZFgU55bQ",
        "outputId": "709f2b24-240b-4068-c50f-18d5fc41a63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           158976    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 621)           636525    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,042,477\n",
            "Trainable params: 6,042,477\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "CcaO_rO_8-GH",
        "outputId": "83413627-2016-485a-da8c-1c87ae016545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAGVCAIAAACgshXKAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVxTV/ow8HND9pCwyDpoEIiK4FbUVqm8ltpxrNQFUcGtox0dXFqKolJEKVWgWiwwWrAflWFmWn+KogMVpe2vWrQuWKoiilMrUUBFZBEIkkAC3PeP8/a+GYQsJCTc8Hz/4m7nnntOeLicnPtcgiRJBAAAYGBjmLsCAAAAtINgDQAANADBGgAAaACCNQAA0ABTfeHq1aspKSnmqgoAAADKpk2bpk6dSi3+1531o0ePcnJyTF4lYApFRUVFRUXmrkW/e/z4MXyG+9sg+SyZV05OzqNHj9TXMF/e6cSJE6aqDzCdRYsWoUHQucePHw8NDbX4yzSvQfJZMi+CILqtgTFrAACgAQjWAABAAxCsAQCABiBYAwAADUCwBgAAGjBPsJ48ebKVldWECRMMKWT16tVCoZAgiJKSEl22nj171sbG5vTp04acVBcmO5EJWNK1AEBr5gnWxcXFgYGBBhZy+PDhQ4cO6b7VZPkFLSmRoSVdCwC01sM8a5N5eSJhvwoKCmpubrakEykUihkzZly5cqX/TmFJ1wIArZlzzJrFYhlYguZwb8Q/BiRJnjhx4uDBg8Yq0CgyMzNra2vNXQvjsKRrAaA/9CVYd3Z2xsXFicViHo83bty47OxshFBaWppAIGAwGBMnTnR2dmaxWAKBwM/PLyAgYNiwYVwu19bWduvWrerllJeXe3t7CwQCHo8XEBBw6dIlzadACJEkmZycPGrUKA6HY2Njs2XLFvUCNWy9dOmSWCwmCOKLL75ACGVkZAgEAj6fn5eX9/bbb4tEoqFDhx49elS9AklJSaNGjeLxeA4ODh4eHklJSYsXL9baOHqdaN++fVwu18nJae3ata6urlwu19/f/9q1a3hrREQEm812cXHBixs2bBAIBARB1NfXI4QiIyOjoqKkUilBEBKJRLeu048Zr+Xbb78ViUSJiYn9cV0A0BKpBsdEUpvNmzdzOJycnJzGxsZt27YxGIzi4mKSJD/++GOE0LVr11pbW+vr62fNmoUQOnPmTF1dXWtra0REBEKopKQEFzJjxgxPT8+HDx+qVKo7d+689tprXC73t99+03yK2NhYgiA+//zzxsZGuVyenp6OELp58yY+SvNW/KD9/v37qZ0RQufOnWtubq6trQ0ICBAIBEqlEm9NTEy0srLKy8uTy+XXr193dnZ+4403tLZMH04UHh4uEAju3r3b1tZWVlY2efJkoVBYVVWFty5btszZ2ZkqOTk5GSFUV1eHF0NCQry8vHSs1cKFCxcuXKjjzma/lvz8fKFQuHPnTn0rrONnGBiib58loBeEUHZ2tvoave+s29raMjIygoODQ0JCbG1tt2/fzmKxsrKyqB18fHz4fP6QIUOWLFmCEBKLxQ4ODnw+f/ny5QihX3/9ldpTKBQOHz6cyWT6+voeOnSora0NjzP0dgqFQpGamvrWW29t2rTJ1taWx+PZ29tTpWne2ht/f3+RSOTo6BgWFtba2lpVVYXX5+bmTpw4ce7cuTwez8/Pb968eRcvXlQqlfo2l9YTIYSYTObo0aM5HI6Pj09GRkZLS4t6ew5AJriWoKAgmUy2Y8cO49UaAHrTO1jfu3dPLpePGTMGL/J4PBcXF/UQTGGz2Qihjo4OvIhHqFUqVY/Fjh071sbGprS0VMMpysvL5XL5jBkzeixB81atcG2p6rW1tZFqEyE6OztZLJaVlVXfCtdwom4mTZrE5/N7bM8ByJKuBYABTu9g3draihDavn078bvKykq5XG54VVgsFv617+0Ujx8/Rgg5Ojr2eLjmrfqaPXv29evX8/LyFArFL7/8kpub+8477xglWGvF4XDq6upMcCITsKRrAcC89A7WOBqmpqaqD6ZcvXrVwHp0dHQ8f/5cLBZrOAWXy0UItbe391iC5q36io+Pf/PNN1euXCkSiRYsWLB48WINc7qNSKVSNTU1DR061ATn6m+WdC0AmJ3ewRpP7ejxoUFD/Pjjj11dXX5+fhpOMWbMGAaDceHChR5L0LxVX2VlZVKptK6uTqVSVVVVZWRk2NnZGaVkzQoLC0mSnDJlCl5kMpm9DTIMfJZ0LQCYnd7Bmsvlrlq16ujRoxkZGTKZrLOz8/Hjx0+fPu3DuZVKZXNzc0dHx40bNyIiItzd3VeuXKnhFI6OjiEhITk5OZmZmTKZrLS0VH3is+at+nr//ffFYvGLFy/6XILuurq6GhsbOzo6SktLIyMjxWIxbgeEkEQief78eW5urkqlqqurq6ysVD/Q3t6+urq6oqKipaVlgMRBY11LQUEBTN0D4L+oDzXoOO2pvb09OjpaLBYzmUwcIsvKytLS0vh8PkJo+PDhP/300+7du21sbBBCzs7OR44cOXbsmLOzM0LIzs7u6NGjJElmZWUFBgY6OTkxmUw8daSyslLzKUiSbGlpWb169ZAhQ6ytradNmxYXF4cQGjp06K1btzRv3b9/P57ky+fz586dm56ejms7YsQIqVR68OBBkUiEEHJ3d8fTB8+fPz9kyBCqlVgs1ujRo0+ePKm1cfQ9UXh4OIvFcnNzYzKZIpFo/vz5UqmUKq2hoSEwMJDL5Xp4eHzwwQd45rhEIsHz4W7cuOHu7s7j8aZNm1ZTU6O5Yn2YbmXGazl79qxQKExISNCrwiRM3TMJmLpnAuilqXt9CdaDQXp6emRkJLXY3t6+ceNGDocjl8uNe6Lw8HB7e3vjltkjE/yCmexaNIDPsAlAsDaBl4O1OXODDFg1NTURERHqg+ZsNlssFqtUKpVKxePxjHu6zs5O4xZoRpZ0LQAMKJDPugc8Ho/FYmVmZj579kylUlVXVx8+fDguLi4sLKy6uproXVhYmLnrDgCwTBCse2BjY/P999/fuXNn5MiRPB7Px8cnKytr9+7d//znP729vTX853Ls2DG9TrRt27asrKzm5mYPD4+cnJx+uhzToNe1rF27lvoTi5+tpfzwww8xMTH4Z5VKlZSUJJFI2Gy2ra3tmDFjKioqXi6tra3N29t7+/btupz65MmTnp6e+NQrVqxQ3zRz5kyhUGhlZeXr63vjxo0+XptG33zzzZ49e9T/AcrNzaWawsHBwYjngkam1hinkdVjDYz3WbBBMs6o42cYD68XFBTcu3cPP62KxcXFzZkzRyaT4cXg4OBRo0YVFRXhf7Dmzp17+/btl0vbtGkTQig2Nlb3enp5eeFvsPPz89XXFxQUzJs3T/dy+iAtLW369OmNjY14saur6/HjxxcvXpw9e/aQIUN0KUHHzxI0siGNjAzPDQKAZeDxeLNmzRo5ciSHw8Frdu/efezYsePHjwuFQoTQsWPHcnNzT5w48dprrzGZTFdX17y8PCoLAuXKlSt37tzpQwX27dvHYDDCw8NNkzGc8uGHH44fP3727Nk4FQRBEG5ubgEBASNGjDD6uaCRjdjIEKwBQAih8vLyHTt2fPLJJ/hRWITQgQMH/Pz8xo4dq+EohUKxZcuWtLS0PpzR398/MjLyyZMnmzdv7kuNDRAfH19SUtK3ahsCGtkQEKwBQAihffv2kSQ5d+5cvKhUKouKirS+JjQ2NnbDhg19zkiTkJAwcuTIw4cP//DDDz3uQJJkSkoKTmRoZ2c3f/58KjGWLjnZe0wKjxCys7ObPn16WloaadrXtkEjGwKCNQAIIXTmzJlRo0bhp34QQtXV1Uql8vr164GBgfhdCqNHj05PT1f/xbt8+bJUKl26dGmfT8rj8f7xj38wGIw1a9bg/GXdxMfHx8TExMbG1tbWXrx48dGjRwEBAc+ePUMIrV+/fuPGjQqFQigUZmdnS6VST0/PNWvWUM+yfvTRR5999llqaurTp0/nzJmzdOnSX375hSr5lVdeefLkya1bt/pc+T6ARjYEBGsAUGtr68OHD728vKg1ONOAo6NjYmJiWVnZs2fP5s+f//777//P//wP3kGhUERGRmZkZBh46qlTp27cuLGiouKjjz7qtkmhUKSkpCxYsGD58uU2NjZjx4798ssv6+vru+VR6DG9uNa883jw9Pbt2wbWX3fQyAbq4aEYE7/HFpgSdG6PamtrSZKk7vgQQvgLMV9fX39/f7zmk08+OXDgwMGDB5ctW4YQ2rZt21//+lc3NzfDz56QkJCfn5+enh4aGqq+vqys7MWLF5MmTaLWTJ48mc1mUy9L60Y9vbjWvPP4YvH9o2lAIxuoh2CtPuwCLEZqaipCaOPGjeauSP+6evVqH77SaWtrQ7/HDszV1RUhhF8RibHZbHd3d6lUihC6dOnS7du3U1JSjFBjhLhcblZW1rRp09577709e/ZQ65uamhBC1tbW6jvb2tq2tLRoLZNKCq8+MRlfFIYfxMUXbhrQyAbqIVjr8lpYQDsnTpxAg6Nz+xCs8S+V+lMM1tbWI0aMuHv3rvpuHR0dOD1ZZmbmuXPnGIz/GkVMTExMTEwsLi5Wv03T0dSpUzdt2rR3795du3bhrO4IIVtbW4RQt6ihY4pwKil8ZGRkjzvgd9QZPXeCBtDIBoIxawCQk5MTQRDdpuKGhobevHnzwYMHeFEul1dWVuJJZllZWepPK+C34eDnNfoQRLBdu3Z5e3vfvHmTWjNmzBhra2v1L6yuXbumVConTpyotTSteefxxeJcmKYBjWwgCNYAID6f7+npid8MR9m0aRPOsV5VVdXQ0BAdHa1QKF7+hqpHYWFhzs7Oej3NjP9PV391HJfLjYqKOnXq1Ndffy2TyW7fvr1u3TpXV9fw8HBdStOcdx5frOYJzsYFjWwgCNYAIIRQUFBQWVmZQqGg1tjZ2f30009Dhw6dMGGCm5vbzz//fObMGa2TgjGlUllbW5uXl/fypn//+98SiUQqlU6ePPmDDz5Q3zRlyhT8UDXl448/TkpK2rlzp4ODw/Tp04cPH15YWCgQCBBCGRkZ+HuIcePGPXjw4NChQ1FRUQihWbNm3b9/HyGUlpa2cePGPXv2DBkyxNXVNTIysrGxkSq5uLjYzc1t3LhxujeR4aCRDaL+jwbkBrFgkBtEXXh4uJubm/qa+/fvM5nMr776yijV6OzsDAgIyMzMNEppRldfX8/lcvfu3au+8sMPPzR6bhBo5D43MoLcIABgCoXiu+++u3//Pv4WSCKR7Ny5c+fOnYa/y62zszM3N7elpWXApsyNj4+fMGFCREQEQogkyerq6kuXLpWXlxv9RNDIRmxkMwfroqKi0aNHMxgMgiCcnZ0TEhJMdmr1JIouLi7dUjgCi/f8+XOcY+i9997Da2JiYhYtWhQWFmZg0p/CwsKTJ08WFBSozykeOFJSUkpKSs6ePctisRBCeXl5OMfQmTNnjH4uaGRjNrL6bba5hkH+9Kc/IYSodIKm5OXlZWNjY/rzmh4Mg+jou+++i46ONlZ9Bprc3NykpKSOjg5DCjH8swSNrBUa5MMgCoWCelYKGJ0Rm9eMPTVz5szdu3eb5dQmMG/evJiYGPXpEGYBjdwHgytYZ2Zm1tbWmrsWFsuIzQs9BUA3Ay5Ya85JuG/fPi6X6+TktHbtWpymy9/fn3qKPyIigs1mu7i44MUNGzYIBAKCIPDzrJGRkVFRUVKplCAIiUSiY31++uknHx8fGxsbLpc7duzY7777DiG0evVqPNjt5eWFJ9ivWrWKz+fb2Nh88803qJfEiZ999hmfzxcKhbW1tVFRUW5ubvfu3TNm2xkD2Xu6SL2a17g99e2334pEosTERBO3BgADiPqYyAAZs46NjUUInTt3rrm5uba2NiAgQCAQKJVKvDU8PFwgENy9e7etra2srGzy5MlCobCqqgpvXbZsmbOzM1VycnIyQqiurg4vhoSEeHl5qZ9a65j1iRMn4uPjnz9/3tDQMGXKFGraTUhIiJWV1ZMnT6g9ly5d+s033+CfN2/ezOFwcnJyGhsbt23bxmAwiouLqUv78MMP9+/fv2DBgv/85z99bTO96TjOGBcXx2azv/rqq6amptLSUj8/PwcHh5qaGrxVr+Y1Yk/l5+cLhcKdO3dqrT9MPzWBQfL9h3khGo1Z95iTEGMymfjWz8fHJyMjo6WlRT0toXEtXLjw448/trOzs7e3nzt3bkNDA37sdd26dZ2dndR5ZTJZcXHx7NmzkQ6JE3fv3v3++++fPHnS29u7n6rdNzqmi9SdsXoqKChIJpPt2LGjb9UAwAIM3GBNUc9J+LJJkybx+Xz1tIT9B8/CwZlo3nzzzZEjR/7973/HfwOPHTsWFhaGv1LQmjhxwNI3XaReTNlTAFgeGgRrrTgcDr7b7Q9nzpx54403HB0dORzO1q1bqfUEQaxdu/bBgwfnzp1DCP3rX//6y1/+gjdRiROpl89XVlbK5fJ+qqERGZIuUhf92lMAWDbaB2uVSqVjPkPdXbx4EScEqKqqCg4OdnFxuXbtWnNzs3oaXITQypUruVzu4cOH7927JxKJ3N3d8XoqcaL6eNPVq1eNWMN+Yki6SK36o6cAGDx6yGdNL4WFhSRJTpkyBS8ymczeBkx0d/36dZzG5fbt2yqVav369Z6enuil16zY2dmFhoYeO3ZMKBSuWbOGWq81ceKApTVdpCHN2x89BcDgQcs7666ursbGxo6OjtLS0sjISLFYvHLlSrxJIpE8f/48NzdXpVLV1dVVVlaqH2hvb19dXV1RUdHS0tJjpFCpVM+ePaNybuEM5T/88ENbW9v9+/dfHrpdt25de3t7fn7+nDlzqJVaEycOWFrTRerbvMbqqYKCApi6BwY79X/VTT/tqaioyNfXF78MwsXFJTExMT09HT/sP2LECKlUevDgQZFIhBByd3f/7bffSJIMDw9nsVhubm5MJlMkEs2fP18qlVIFNjQ0BAYGcrlcDw+PDz74YMuWLQghiUSCZ4zduHHD3d2dx+NNmzbtwIED6u/u7ObUqVO4wOjoaHt7e1tb20WLFn3xxRcIIS8vL2r+GUmSr7zySkxMTLfram9vj46OFovFTCbT0dExJCSkrKxsz549+J0Rw4YNM1biMd3pON2qq6srOTl5xIgRLBbLzs4uODj43r171Fbdm7empsZYPVVTU3P27FmhUJiQkKC1/jB1zwRg6p4JoJem7g2IedZ6CQ8Pt7e3N3ct/r/Zs2c/ePDA3LXQzvS/YGbpKVp8hukOgrUJvBysaTkMov4aN7OghlBKS0vxvaF56zNgmb2nALAYtP+C0Syio6PXrVtHkuSqVau++uorc1cHAGD5aHZnvW3btqysrObmZg8Pj5ycHHNVg8/ne3t7v/XWW/Hx8T4+PuaqxkA2QHoKAItBs2CdlJTU3t5OkuTDhw8XLlxormokJCR0dnZWVVWpTwIB6gZITwFgMWgWrAEAYHCCYA0AADQAwRoAAGgAgjUAANBAD1P3jh8/bvp6gP72+PFjNAg6FyfMsvjLNK9B8lkacNSfkMFPfwEAADC7bk8wEvi5RgAsxuLFixHc9wGLA2PWAABAAxCsAQCABiBYAwAADUCwBgAAGoBgDQAANADBGgAAaACCNQAA0AAEawAAoAEI1gAAQAMQrAEAgAYgWAMAAA1AsAYAABqAYA0AADQAwRoAAGgAgjUAANAABGsAAKABCNYAAEADEKwBAIAGIFgDAAANQLAGAAAagGANAAA0AMEaAABoAII1AADQAARrAACgAQjWAABAAxCsAQCABiBYAwAADUCwBgAAGoBgDQAANADBGgAAaACCNQAA0AAEawAAoAEI1gAAQAMESZLmrgMABjly5EhmZmZXVxdefPjwIULIw8MDLzIYjL/85S/Lli0zW/0AMAYI1oD2SktLx48fr2GHW7dujRs3zmT1AaA/QLAGlsDb2/vevXs9bpJIJPfv3zdxfQAwOhizBpZgxYoVLBbr5fUsFmvVqlWmrw8ARgd31sASPHjwQCKR9Phhvn//vkQiMX2VADAuuLMGlsDT09PPz48gCPWVBEFMmjQJIjWwDBCsgYV49913rays1NdYWVm9++675qoPAMYFwyDAQtTW1rq6ulIT+BBCDAajurra2dnZjLUCwFjgzhpYCCcnp+nTp1M311ZWVm+88QZEamAxIFgDy7FixQr1/xRXrFhhxsoAYFwwDAIsh0wmc3R0VCqVCCEWi1VbW2tra2vuSgFgHHBnDSyHSCSaNWsWk8lkMpmzZ8+GSA0sCQRrYFGWL1/e2dnZ2dkJyUCAhYFhEGBR2traHBwcSJKsr6/n8Xjmrg4ARmNQsO72DAIAAAANDIm3TAPPHRkZOXXqVAMLAVhoaOhgaM/U1FSE0MaNG/up/JKSEoIgNOfho7VB8jmxMFevXk1LSzOkBEPvrLOzsxcvXmxIDQBlkLTnokWLEEInTpzop/I7OjoQQkymoTciA9Yg+ZxYmOPHj4eGhprzzhqAgcaCwzQYzGA2CAAA0AAEawAAoAEI1gAAQAMQrAEAgAZoE6wnT55sZWU1YcIEQwpZvXq1UCgkCKKkpESXrWfPnrWxsTl9+rQhJ+1vtKgkAMBAtAnWxcXFgYGBBhZy+PDhQ4cO6b6VFo930qKSAAAD0WySk4mfmQwKCmpubjblGfvAZJVUKBQzZsy4cuWKCc4FAOiGNnfWWI9vsNaL5nBvxD8GJEmeOHHi4MGDxirQ7DIzM2tra81dCwAGKRMF687Ozri4OLFYzOPxxo0bl52djRBKS0sTCAQMBmPixInOzs4sFksgEPj5+QUEBAwbNozL5dra2m7dulW9nPLycm9vb4FAwOPxAgICLl26pPkUCCGSJJOTk0eNGsXhcGxsbLZs2aJeoIatly5dEovFBEF88cUXCKGMjAyBQMDn8/Py8t5++22RSDR06NCjR4+qVyApKWnUqFE8Hs/BwcHDwyMpKam/HzPTq5L79u3jcrlOTk5r1651dXXlcrn+/v7Xrl3DWyMiIthstouLC17csGGDQCAgCKK+vh4hFBkZGRUVJZVKCYLAr6D99ttvRSJRYmJiv14gAOD/IQ2AEMrOztZlz82bN3M4nJycnMbGxm3btjEYjOLiYpIkP/74Y4TQtWvXWltb6+vrZ82ahRA6c+ZMXV1da2trREQEQqikpAQXMmPGDE9Pz4cPH6pUqjt37rz22mtcLve3337TfIrY2FiCID7//PPGxka5XJ6eno4QunnzJj5K89ZHjx4hhPbv30/tjBA6d+5cc3NzbW1tQECAQCBQKpV4a2JiopWVVV5enlwuv379urOz8xtvvNFP7alOr0qGh4cLBIK7d++2tbWVlZVNnjxZKBRWVVXhrcuWLXN2dqZKTk5ORgjV1dXhxZCQEC8vL2prfn6+UCjcuXOnvhVeuHDhwoUL9T0KUPr2OQHmhW8fDSnBFHfWbW1tGRkZwcHBISEhtra227dvZ7FYWVlZ1A4+Pj58Pn/IkCFLlixBCInFYgcHBz6fv3z5coTQr7/+Su0pFAqHDx/OZDJ9fX0PHTrU1taGxxl6O4VCoUhNTX3rrbc2bdpka2vL4/Hs7e2p0jRv7Y2/v79IJHJ0dAwLC2ttba2qqsLrc3NzJ06cOHfuXB6P5+fnN2/evIsXL+K3lpheb5VECDGZzNGjR3M4HB8fn4yMjJaWFvW+0F1QUJBMJtuxY4fxag0A6JUpgvW9e/fkcvmYMWPwIo/Hc3FxUQ/BFDabjX5PxIN+H6FWqVQ9Fjt27FgbG5vS0lINpygvL5fL5TNmzOixBM1btcK1parX1tZGqk3M6OzsZLFY1PtbzaVbJbuZNGkSn8/vsS8AAAOKKYJ1a2srQmj79u3E7yorK+VyueEls1gsHIZ6O8Xjx48RQo6Ojj0ernmrvmbPnn39+vW8vDyFQvHLL7/k5ua+8847Zg/WWnE4nLq6OnPXAgCghSmCNY6Gqamp6uMvV69eNbDYjo6O58+fi8ViDafgcrkIofb29h5L0LxVX/Hx8W+++ebKlStFItGCBQsWL16sYU73AKFSqZqamoYOHWruigAAtDBFsMZTO3p8aNAQP/74Y1dXl5+fn4ZTjBkzhsFgXLhwoccSNG/VV1lZmVQqraurU6lUVVVVGRkZdnZ2Rim5/xQWFpIkOWXKFLzIZDJ7GzABAJiXKYI1l8tdtWrV0aNHMzIyZDJZZ2fn48ePnz592oeilEplc3NzR0fHjRs3IiIi3N3dV65cqeEUjo6OISEhOTk5mZmZMpmstLRUfeKz5q36ev/998Vi8YsXL/pcgml0dXU1NjZ2dHSUlpZGRkaKxWLchgghiUTy/Pnz3NxclUpVV1dXWVmpfqC9vX11dXVFRUVLS4tKpSooKICpewCYjiFTSZDOU4ja29ujo6PFYjGTycQhsqysLC0tjc/nI4SGDx/+008/7d6928bGBiHk7Ox85MiRY8eOOTs7I4Ts7OyOHj1KkmRWVlZgYKCTkxOTycRTRyorKzWfgiTJlpaW1atXDxkyxNraetq0aXFxcQihoUOH3rp1S/PW/fv340nHfD5/7ty56enpuLYjRoyQSqUHDx4UiUQIIXd3dzx98Pz580OGDKEalsVijR49+uTJk/3RnhR9KxkeHs5isdzc3JhMpkgkmj9/vlQqpUpraGgIDAzkcrkeHh4ffPABnnUukUjw3L4bN264u7vzeLxp06bV1NScPXtWKBQmJCToVWESpu4ZrA+fE2B2hk/dM1GwHgzS09MjIyOpxfb29o0bN3I4HLlcrmMJJmjP8PBwe3v7fj2FVhCsDQS/d3RkeLCmWW6QAaumpiYiIkJ90JzNZovFYpVKpVKpeDyeGevWTWdnp7mrAADQG81ygwxYPB6PxWJlZmY+e/ZMpVJVV1cfPnw4Li4uLCwMD0SAPvvhhx9iYmLwzyqVKikpSSKRsNlsW1vbMWPGVFRUvHxIW1ubt7f39u3bdSn/5MmTnp6eeMbnihUr1DfNnDlTKBRaWVn5+vreuHHD4EvpwTfffLNnz57++wtq2a2n1c6dO318fEQiEYfDkUgkW7duVf9WKQc4FuQAACAASURBVCEhgfhv1LMaWG8t1t+91jNDbssR/Dum5uLFi2+99ZZIJLKysrKxsfH3909PT1epVLqX0N/tGRMTg5+RGT58+IkTJ/rvRJrpNQwSFxc3Z84cmUyGF4ODg0eNGlVUVIT/Is6dO/f27dsvH7Vp0yaEUGxsrO618vLywl855Ofnq68vKCiYN2+e7uX0QVpa2vTp0xsbG3XcX/fPyWBoPc2mT5+enp7e0NAgk8mys7NZLNasWbOorbt27eoWD319fdUP19Bi+vYajFlblEHSnroH608//XTkyJEKhQIvHj16lCCI0tJSzUddvnx55syZfQg3R44cYTAYbm5uTU1N1HrThJuIiIipU6fq+Kddx8/J4Gk9DYKCgjo6OqhFnFiNSoaza9eur776qrdjtbaYXr1Gj9wgAPRBeXn5jh07PvnkE/zsEkLowIEDfn5+Y8eO1XCUQqHYsmVLWlpaH87o7+8fGRn55MmTzZs396XGBoiPjy8pKelbtXs0qFpPg/z8fPWniB0cHBBCOj4+rbXFjN5rmkGwBgPUvn37SJKcO3cuXlQqlUVFRVrf6xYbG7thw4Y+pxBISEgYOXLk4cOHf/jhhx53IEkyJSUFZ8Kys7ObP38+lVlFlyS6PWbxRQjZ2dlNnz49LS2NNNJ7fwZV6+nuyZMnPB7Pw8ND6566tJjRe00zCNZggDpz5syoUaPwtHGEUHV1tVKpvH79emBgIE7GPXr06PT0dPXfk8uXL0ul0qVLl/b5pDwe7x//+AeDwVizZg1OONNNfHx8TExMbGxsbW3txYsXHz16FBAQ8OzZM4TQ+vXrN27cqFAohEJhdna2VCr19PRcs2YN9VDoRx999Nlnn6Wmpj59+nTOnDlLly795ZdfqJJfeeWVJ0+e3Lp1q8+VVzfYWk8Xcrn8/Pnza9aswd/cYDExMXZ2dmw228PDY/78+cXFxXi9Li2GjN1rWhgyhoIGxxiryQyS9tRlzPrFixcEQcyZM4dac/v2bYTQH//4x8uXLzc0NDQ1NX300UcIoa+//hrvIJfLJ02a9PjxY5IkcWoqfUddHz58iH+OiopCCL3//vvkf4+6yuVya2vrsLAw6qiff/4ZIUQl9cbJxKlhYpwevby8nCRJhULB5/OpY+VyOYfDWb9+PVXU3//+d4TQv/71L61V1fo5GYStp4vY2NiRI0dSX7eSJFlVVXXjxo2Wlpb29varV6++8sorPB7vzp07urQYpnuvmX+eteH5mIC6wdCejx8/1po6qra2liRJ6sYQIcThcBBCvr6+/v7+eM0nn3xy4MCBgwcPLlu2DCG0bdu2v/71r25ubobXMCEhIT8/Pz09PTQ0VH19WVnZixcvJk2aRK2ZPHkym82m3rbTjXp+Wq2JgvHF4ttMAw3C1tPq1KlTx48f//7774VCIbVy2LBhw4YNwz9PmTIlKytrwoQJ6enpGRkZWlsMM2KvaWVosE5LSzPZ+PpgMEjac+HChZp3aGtrQ7+HGMzV1RUhhN8xhrHZbHd3d6lUihC6dOnS7du3U1JSjFI9LpeblZU1bdq09957b8+ePdT6pqYmhJC1tbX6zra2ti0tLVrLpLL4qs9fxheF4Sen8IUbaBC2nmbHjh1LSUkpLCz8wx/+oGG3sWPHWllZ/fbbb0hbi1GM2GtaGTpmPRj+bTeZQdKeWiM1+v13QP2hA2tr6xEjRty9e1d9t46ODpxPJjMz89y5cwwGAz/agL8iS0xMJAhC35FNbOrUqZs2bbp//776VFxbW1uEULfgomOOWa2JgvFLhYzysOsgbD0N9u/f//XXX58/f15zpEYIdXV1dXV14T9ymluMYsRe0wq+YAQDkZOTE0EQzc3N6itDQ0Nv3rz54MEDvCiXyysrK/HMqqysLPVfY/VRV/X/u/Wya9cub2/vmzdvUmvGjBljbW2tHr+uXbumVConTpyotTStiYLxxeLkZQYahK3XI5Iko6Ojb9++nZub2+2OHvvTn/6kvojf2jp16lS8qKHFKEbsNa0gWIOBiM/ne3p64lf5UDZt2oST4lZVVTU0NERHRysUCvy1j1ZhYWHOzs56PfSM/51Xn6XL5XKjoqJOnTr19ddfy2Sy27dvr1u3ztXVNTw8XJfSNCcKxhereR60jgZV62mo2927dz/77LNDhw6xWCz1Z8r37t2Ld3jy5MmxY8eamppUKtXVq1dXr14tFovXrVuHt+rSYkbsNe0M+X8WDY5/201mkLSnjk8wRkREsFisbjkLHz16tGTJEjs7Ow6H8+qrrxYUFPR47MvzGYKDgxFCcXFxL+986tQpLy8vhJCDgwOew6Buy5Yt6s/gdXV1JScnjxgxgsVi2dnZBQcH37t3D2/Smp+2tyy+WFBQkJubW1dXl9aW0eVzMnhaT0Pd8IyOlyUnJ+MdoqKivLy8BAIBk8kcOnTomjVrqqur9Wox3XsNHje3KIOkPXUM1vfv32cymRqeBtZLZ2dnQEBAZmamUUozuvr6ei6Xu3fvXl121uVzMnhaz4x106vX4HFzYLEkEsnOnTt37txp+Mt3Ojs7c3NzW1pawsLCjFI3o4uPj58wYUJERISxChwkrWfeuhm91zSDYA0GrpiYmEWLFoWFhXX7rkxfhYWFJ0+eLCgoUJ96PHCkpKSUlJScPXuWxWIZsdjB0HpmrFs/9ZoG/Rus1XPddjN8+PA+FDh58mQrKyutKQ40W716tVAoJAiixy+XX9569uxZGxub06dPG3JS0DeJiYkRERGffvqpIYXMmDHjyJEj+P1nA01eXl57e3thYWF/vF7Z4lvPXHXr117rTf8G65CQkAcPHnh5ednY2OBhl46ODrlc/uzZs779JSwuLg4MDDSwVocPHz506JDuW0mTZGkBvZk5c+bu3bvNXYv+Mm/evJiYGPVZE8Zl2a1nLv3daz0y9TCIlZUVj8dzcnIaOXJknwshCMKIVdIqKCioubl5zpw5pjxpf1AoFNSzswOnKACALsw2Zp2bm9vnYw0fJNIc7o34x4AkyRMnThw8eNBYBRoiMzOztrZ2oBUFANCF+b9gTEtLEwgEDAZj4sSJzs7OLBZLIBD4+fkFBATgx5ZsbW23bt2qfkh5ebm3t7dAIODxeAEBAZcuXaI29Zb0liTJ5OTkUaNGcTgcGxubLVu2qBeoYeulS5fEYjFBEF988QXSLetuUlLSqFGjeDyeg4ODh4dHUlISfj+FUZC9ZwSOiIhgs9nU+N2GDRsEAgFBEDi/QWRkZFRUlFQqJQhCIpHs27ePy+U6OTmtXbsWZ4D09/enUuroVRRC6NtvvxWJRImJica6TABAd4bM+0O6zQtWH7MmSfLDDz/s9ua3jz/+GCF07dq11tbW+vr6WbNmIYTOnDlTV1fX2tqKZ8aUlJTgnWfMmOHp6fnw4UOVSnXnzp3XXnuNy+XiafMkSW7evJnD4eTk5DQ2Nm7bto3BYOBHSGNjYwmC+PzzzxsbG+VyOc6+ePPmTXyU5q2PHj1CCO3fv5/aGSF07ty55ubm2tragIAAgUCgVCrx1sTERCsrq7y8PLlcfv36dWdn5zfeeMOI7RkXF8dms7/66qumpqbS0lI/Pz8HB4eamhq8ddmyZc7OztTOycnJCKG6ujq8GBIS4uXlRW0NDw8XCAR3795ta2srKyubPHmyUCik3nikV1H5+flCoZDKdamZXu9gBC/T8fcODCi0mWfd3NxMzQP529/+1uM+Pj4+fD5/yJAhS5YsQQiJxWIHBwc+n798+XKEkHo6RKFQOHz4cCaT6evre+jQoba2NjzO0NbWlpGRERwcHBISYmtru337dhaLlZWVpVAoUlNT33rrrU2bNtna2vJ4PHt7e6o0zVt74+/vLxKJHB0dw8LCWltbq6qq8Prc3NyJEyfOnTuXx+P5+fnNmzfv4sWLONuL4RQKRUpKyoIFC5YvX25jYzN27Ngvv/yyvr6+z8MsTCYT36T7+PhkZGS0tLRkZWX1oZygoCCZTLZjx46+VQMAoJWJgnW3O2vNO+M8th0dHXgRj1BTL4zoZuzYsTY2NqWlpaj3pLfl5eVyuXzGjBk9lqB5q1bqWXcRQm1tbaTa7JHOzk4Wi2Wsb431zQisl0mTJvH5fL1yBAMATMYMY9ZpaWlUPDUKFouFYyWV9Ja6i6+srJTL5TjZSm9vltO8VV+zZ8++fv16Xl6eQqH45ZdfcnNz33nnHWMFa0MyAuuCw+HgvBAAgIHG/F8wGqijo+P58+disRj1nvQWv+C5vb29xxI0b9VXfHz8m2++uXLlSpFItGDBgsWLF2uY060vQzICa6VSqYxVFADA6MwWrJ8+fbpq1SrDy/nxxx+7urr8/PxQ70lvx4wZw2AwLly40GMJmrfqq6ysTCqV1tXVqVSqqqqqjIwMIz7jpDUjMJPJ7G28SKvCwkKSJKdMmWJ4UQAAozNDsCZJUqFQnDx5EqdA7AOlUtnc3NzR0XHjxo2IiAiccxb1nvQWJ1TMycnJzMyUyWSlpaXq38hp3qqv999/XywWG549p0daMwJLJJLnz5/n5uaqVKq6urrKykr1w+3t7aurqysqKlpaWnAg7urqamxs7OjoKC0tjYyMFIvFuCX1LaqgoACm7gHQvwyZSoK0TSGict32aPv27SRJpqWl4UfPhw8f/tNPP+3evRu/OMfZ2fnIkSPHjh3Db2Gws7M7evQoSZJZWVmBgYFOTk5MJhNPHamsrKTO2FvS25aWltWrVw8ZMsTa2nratGlxcXEIoaFDh966dUvz1v379+Ppxnw+f+7cuVqz7p4/f37IkCHUNbJYrNGjR588edIo7UlqzAhMkmRDQ0NgYCCXy/Xw8Pjggw/whHGJRIIn5N24ccPd3Z3H402bNq2mpiY8PJzFYrm5uTGZTJFINH/+fKlU2reizp49KxQKExISdLlMmLpnIF0+J2CggXzWA056enpkZCS12N7evnHjRg6H0y0NfI9M3J7h4eH29vYmOx0FgrWB4PeOjgwP1oa+3Ryoq6mpiYiIUB80Z7PZYrFYpVKpVCrTvFVTL+rvVAUADGS0nw0yoPB4PBaLlZmZ+ezZM5VKVV1dffjw4bi4uLCwsD4P0AMAAIJgbVw2Njbff//9nTt3Ro4cyePxfHx8srKydu/e/c9//tPcVetu27ZtWVlZzc3NHh4eOTk55q4OAEALGAYxsoCAgP/93/81dy20S0pKSkpKMnctAAC6gjtrAACgAQjWAABAAxCsAQCABiBYAwAADRCkAW+DJQhiypQpkPrHWHJycgZDexYVFSGEqCQkQF+D5HNiYR4/flxUVGRQvDXk4EWLFvX5WAD6yc2bNxFCr7zyirkrAkB3J06c6POxBgVrAAYg/MbL48ePm7siABgTjFkDAAANQLAGAAAagGANAAA0AMEaAABoAII1AADQAARrAACgAQjWAABAAxCsAQCABiBYAwAADUCwBgAAGoBgDQAANADBGgAAaACCNQAA0AAEawAAoAEI1gAAQAMQrAEAgAYgWAMAAA1AsAYAABqAYA0AADQAwRoAAGgAgjUAANAABGsAAKABCNYAAEADEKwBAIAGIFgDAAANQLAGAAAagGANAAA0AMEaAABoAII1AADQAARrAACgAQjWAABAAxCsAQCABpjmrgAAhpLL5e3t7dSiUqlECDU2NlJrOBwOn883Q80AMB6CJElz1wEAg2RkZGzYsEHDDunp6evXrzdZfQDoDxCsAe3V1dW5urp2dnb2uNXKyurp06eOjo4mrhUAxgVj1oD2HB0dZ8yYYWVl9fImKyurt956CyI1sAAQrIElWL58eY//I5IkuXz5ctPXBwCjg2EQYAlaWlocHR3Vv2bE2Gx2XV2dSCQyS60AMCK4swaWQCgUzpkzh8Viqa9kMpnz5s2DSA0sAwRrYCGWLVvW0dGhvqazs3PZsmXmqg8AxgXDIMBCKJVKBweHlpYWao21tXV9fT2HwzFjrQAwFrizBhaCzWYvWrSIzWbjRRaLFRoaCpEaWAwI1sByLF26FD++iBBSqVRLly41b30AMCIYBgGWo6ury8XFpa6uDiHk4OBQU1PT4+RrAOgI7qyB5WAwGEuXLmWz2SwWa9myZRCpgSWBYA0sypIlS5RKJYyBAMujR9a948eP9189ADAKkiSHDBmCEHr48GFFRYW5qwOAFosXL9ZxTz3GrAmC6Gt9AAAA9ED3CKxfPuvs7Gzd/w7Qy/Hjx0NDQwfD160EQVhwPyKE7t69ixDy8fExd0WMafB8PgcP3Ke67w8vHwCWxsLCNAAYfMEIAAA0AMEaAABoAII1AADQAARrAACgAQjWAABAA6YL1nv37nVyciII4ssvvzTZSfvb2bNnbWxsTp8+be6KAAAsnOmC9ebNm69cuWKy05kGzHsFAJjGgBsGUSgU/v7+5q6FroKCgpqbm+fMmdPfJ6JXswAAjG7ABevMzMza2lpz12LAgWYBYJAzZ7C+cOHCq6++yufzRSLR2LFjZTJZZGRkVFSUVColCEIikaSlpQkEAgaDMXHiRGdnZxaLJRAI/Pz8AgIChg0bxuVybW1tt27daq76X7p0SSwWEwTxxRdfIIQyMjIEAgGfz8/Ly3v77bdFItHQoUOPHj2Kd963bx+Xy3Vyclq7dq2rqyuXy/X397927RreGhERwWazXVxc8OKGDRsEAgFBEPX19Qihbs2CEPr2229FIlFiYqIZLhsAYBakzhBC2dnZuu//svv37yOEDhw4QJLkixcvRCLRnj17FApFTU3NggUL6urqSJIMCQnx8vKiDvn4448RQteuXWttba2vr581axZC6MyZM3V1da2trREREQihkpISQ2qFZWdn69Ua2KNHjxBC+/fvx4uxsbEIoXPnzjU3N9fW1gYEBAgEAqVSibeGh4cLBIK7d++2tbWVlZVNnjxZKBRWVVXhrcuWLXN2dqZKTk5ORgjhNiFfapb8/HyhULhz584+XKnh/QhMr2+fTzCQ6dunZruzrqiokMlkvr6+XC7X2dn55MmTDg4Ove3s4+PD5/OHDBmyZMkShJBYLHZwcODz+cuXL0cI/frrr6artw78/f1FIpGjo2NYWFhra2tVVRW1iclkjh49msPh+Pj4ZGRktLS0ZGVl9eEUQUFBMplsx44dxqs1AGBAM1uw9vT0dHJyWr58eXx8vO55h/HrUDs6OvAii8VCCKlUqv6po6FwbXur3qRJk/h8/kD7SwMAGJjMFqx5PN758+enTZuWmJjo6ekZFhamUCjMVRlz4XA4+IWBAACgmTm/YPT19T19+nR1dXV0dHR2dvbevXvNWBnTU6lUTU1NQ4cONXdFAAA0YLZgXV1djZPEOzo6fvrpp35+fnhx8CgsLCRJcsqUKXiRyWQO2PEcAIDZmTNYr1279tdff1UqlTdv3qysrMRhy97evrq6uqKioqWlxfKCV1dXV2NjY0dHR2lpaWRkpFgsXrlyJd4kkUieP3+em5urUqnq6uoqKyvVD+zWLAUFBTB1D4DBRfeJI8iwKV+ff/65s7MzQkggECxYsKCiosLf39/Ozs7KyuoPf/hDbGxsR0cHSZI3btxwd3fn8XjTpk2LiYnh8/kIoeHDh//000+7d++2sbFBCDk7Ox85cuTYsWO4QDs7u6NHj/a5Ylgfpkbt378fz4zm8/lz585NT0/HtR0xYoRUKj148KBIJEIIubu7//bbbyRJhoeHs1gsNzc3JpMpEonmz58vlUqp0hoaGgIDA7lcroeHxwcffLBlyxaEkEQiwXP71Julpqbm7NmzQqEwISGhD1dqYD8Cs4Cpe5ZH3z416TzrgcwEvwzh4eH29vb9egpdWHY/WioI1paHNvOsB6fOzk5zVwEAQEsQrIEmP/zwQ0xMDP5ZpVIlJSVJJBI2m21raztmzJgeJ8i3tbV5e3tv375dl/JPnjzp6elJEARBECtWrFDfNHPmTKFQaGVl5evre+PGDYMvpS927tzp4+MjEok4HI5EItm6deuLFy+orQkJCcR/GzNmjPrhvbXYN998s2fPnn79yz3IOw7r6upKTU3tMQPapUuXXn/9dT6f7+rqGh0d3d7eTm3S3OnqurVYv3er7jfhyKL/fe7vfzNjYmLwMzLDhw8/ceJE/51IK937MS4ubs6cOTKZDC8GBwePGjWqqKhIpVJVV1fPnTv39u3bLx+1adMmhFBsbKzuVfLy8hoyZAhCKD8/X319QUHBvHnzdC/H6KZPn56ent7Q0CCTybKzs1ks1qxZs6itu3bt6vbb5Ovrq364hhZLS0ubPn16Y2OjjjXR6/MJHUeS5G+//fb6668jhMaPH99t0507d3g83o4dO168eHHlyhUHB4dVq1ZRWzV3urqXW0yvboUx6z4aPGOCOvbjp59+OnLkSIVCgRePHj1KEERpaanmoy5fvjxz5sw+/M4fOXKEwWC4ubk1NTVR683+Ox8UFIS/98YWL16MEKLSuezateurr77q7VitLRYRETF16lSVSqVLTXT/fELHkSRZUlKyYMGCr7/+esKECS8H69DQUA8Pj66uLryYnJxMEMR//vMfvKi50ym9tZju3Qpj1sAIysvLd+zY8cknn3C5XLzmwIEDfn5+Y8eO1XCUQqHYsmVLWlpaH87o7+8fGRn55MmTzZs396XG/SM/P9/KyopaxOlr5HK5LsdqbbH4+PiSkpK+NVdvoOOw8ePHnzx5ctmyZRwOp9umjo6OM2fOTJ8+nSAIvObtt98mSTIvLw8v6tLpGlqsP7oVg2ANerBv3z6SJOfOnYsXlUplUVHRhAkTNB8VGxu7YcMGR0fHvp00ISFh5MiRhw8f/uGHH3rcgSTJlJQUnAnLzs5u/vz5VGYVzflpEUKdnZ1xcXFisZjH440bNw7f1OjryZMnPB7Pw8ND6566tJidnd306dPT0tJI471vCDpOqwcPHrx48UIsFlNrvLy8EEKlpaU97t9jp2tosf7oVgyCNejBmTNnRo0ahaeNI4Sqq6uVSuX169cDAwNxMu7Ro0enp6erfxwvX74slUqXLl3a55PyeLx//OMfDAZjzZo1ra2tL+8QHx8fExMTGxtbW1t78eLFR48eBQQEPHv2DCG0fv36jRs3KhQKoVCYnZ0tlUo9PT3XrFlDPVf10UcfffbZZ6mpqU+fPp0zZ87SpUt/+eUXvaonl8vPnz+/Zs0a/N0DFhMTY2dnx2azPTw85s+fX1xcjNfr0mIIoVdeeeXJkye3bt3SqyYaQMdpVVNTgxASCoXUGi6Xy+PxcH266bHTtbaY0bv1/9F9xATBmLVF0NqPL168IAhizpw51Jrbt28jhP74xz9evny5oaGhqanpo48+Qgh9/fXXeAe5XD5p0qTHjx+TJIlTU+k79Pnw4UP8c1RUFELo/fffJ/976FMul1tbW4eFhVFH/fzzzwghKqk3TiZOjdWmp6cjhMrLy0mSVCgUfD6fOlYul3M4nPXr1+teQ1z+yJEjqW/tSJKsqqq6ceNGS0tLe3v71atXX3nlFR6Pd+fOHV1aDPv73/+OEPrXv/6l9ey6fD6h41722muvdRuz/v777xFCKSkp6itFIpG/v//Lh7/c6bq0mI7dqm/MYeoV2VNTU0+cOGHYX4cB6vHjxwihRYsWmbsi5ldbW0uSJHV3hhDCA3++vr7ULKhPPvnkwIEDBw8eXLZsGUJo27Ztf/3rX93c3Aw/e0JCQn5+fnp6emhoqPr6srKyFy9eTJo0iVozefJkNptNvW2nG/X8tPfu3ZPL5dS8Oh6P5+Lioldy2lOnTh0/fvz7779XvyMbNmzYsGHD8M9TpkzJysqaMGFCenp6RkaG1hbDcCP3eE/XB9BxusCj+VSaZUypVPJ4vG579tjpurSYcbuVAsMgoLu2tjb0++855urqihDC7xjD2Gy2u7u7VCpFCF26dOn27durV682ytm5XG5WVhZBEO+995561tympiaEkLW1tfrOtra2LS0tWsvE/5tv376dmhBdWVmp4/eECKFjx47t3r27sLBw+PDhGnYbO3aslZXVb7/9hrS1GAUHCNzghoOO0wVOESGTyag1crm8ra0NtxWlx07XscWM260U/e6sN27ciCeyWJ7jx4+HhoZa6v8N6qgvwXuDP2rqc/utra1HjBjRLS1iR0cHTtWSmZl57tw5BuO//vAnJiYmJiYWFxer31LpaOrUqZs2bdq7d++uXbuoL4JsbW0RQt1+w3XMMYu/CEpNTY2MjNS3Mvv37//uu+/Onz/fLdy8rKurq6urC8dKzS1GUSqV6PcGNxx0nC48PDyEQqF6orTy8nKE0Lhx46g1vXW6ji1m3G6lwJ016M7JyYkgiObmZvWVoaGhN2/efPDgAV6Uy+WVlZV4QlhWVpb6yJr6QF4ffuGxXbt2eXt737x5k1ozZswYa2tr9S+Xrl27plQqJ06cqLU0/HrlkpISvepAkmR0dPTt27dzc3N7jNR/+tOf1BeLi4tJkpw6dSpe1NBiFNzIOB+Z4aDjdMFkMmfPnn3x4sWuri68pqCggCAIPIVGc6fr2GLG7VYKBGvQHZ/P9/T0xIP4lE2bNrm7u69cubKqqqqhoSE6OlqhUOBvq7QKCwtzdnbW68lj/D+1+nRXLpcbFRV16tSpr7/+WiaT3b59e926da6uruHh4bqUtmrVqqNHj2ZkZMhkss7OzsePHz99+lRz3e7evfvZZ58dOnSIxWKpP1NOvSXjyZMnx44da2pqUqlUV69eXb16tVgsXrduHd6qS4vhRtY8CVp30HE62rFjx7Nnzz7++OPW1tarV68mJyevXLly1KhRSIdO14Vxu/X/0/27SASzQSyCLv0YERHBYrHkcrn6ykePHi1ZssTOzo7D4bz66qsFBQU9HvvyV+TBwcEIobi4uJd3PnXqFJ7l6uDggCcSqNuyZYv6g3BdXV3JyckjRoxgsVh2dnbBwcH37t3Dm7TmKEFSbgAAHcZJREFUp21vb4+OjhaLxUwm09HRMSQkpKysTHPd8FSKlyUnJ+MdoqKivLy8BAIBk8kcOnTomjVrqqur9WqxoKAgNzc36lE6DXT8fELHYVevXn399depYWgXFxd/f/8LFy5QO1y4cOHVV1/lcDiurq5btmxpa2vD67V2uuYWw3TsVnjcvI8gWKu7f/8+k8nU8Cy1Xjo7OwMCAjIzM41SmnGZsW719fVcLnfv3r267Kzj5xM6zux071Z43BwYgUQi2blz586dO3vLN6a7zs7O3NzclpaWsLAwo9TNiMxbt/j4+AkTJkRERBixTOg4s+uPbsWMGazVsya6uLgsX768tz1v3boVFhbm4eHB4XAcHBzGjx+fkJCAN4WFhREa5efnq59ox44dPZ4iJSWFIAgGg+Ht7X3x4kUjXuYgERMTs2jRorCwsG5fWOmrsLDw5MmTBQUF6vN/Bwgz1i0lJaWkpOTs2bMsFsu4JUPHmVH/dStC/TBm7eXlZWNjo2GH0tJSPp//4YcfPnz4UKFQ3Lt3b+vWrTNmzMBbQ0NDv//+e/ylDf4mYe7cuUqlsrW1tba2ds2aNadPn6ZOhBBycXFRKpXdTtHR0eHu7o4QoorVCoZBevTdd99FR0f3a30Godzc3KSkJPXUblrp+/mEjjM9fbuVBsMge/futbW1TUtLGz58OJfLHTly5K5du6g5iQRBvP766zY2Nkwmk1rDYrH4fL6jo2O36T4TJ06sqanJzc3tdoqTJ08a5aEs41IoFD3mQTdvUZrNnDlz9+7dJjjRoDJv3ryYmBj1KRNGBx1nev3drWYI1g0NDc3Nzc+fP6fWsNns06dP45+PHj2q4V+b8PDwd955h1pcv349QujAgQPddktJScGZCgaUzMzM2tragVYUAIAWzBCsJ0+e3Nra+uabb16+fNnAot58883Ro0f/+OOP9+7do1ZevnxZLpfjvOBGR/ae7DEiIoLNZuOHWRFCGzZsEAgEBEHgh30jIyOjoqKkUilBEBKJZN++fVwu18nJae3atTgdmr+/P5UtQa+iEELffvutSCRKTEzsj0sGAAwEZgjWW7dunTRp0q1bt6ZNm+br6/vZZ5+p32Xra+3atQihL7/8klrz+eef49ft9AcNyR737dun/ix+enr6J598Qi2mpaXNmTPHy8uLJMny8vKIiIiVK1fK5fIPP/ywoqLixo0bHR0df/zjHx89eqRvUej3J4ypJ7IAAJbHDMGax+NduXLlb3/7m7e39927d6Ojo0ePHn3hwoW+lfbnP/9ZIBD885//xLljHjx4UFxcbEhyXg0UCkVKSsqCBQuWL19uY2MzduzYL7/8sr6+/uDBg30rkMlk4pt0Hx+fjIyMlpaWrKysPpQTFBQkk8l6mxgDALAA5plnzWKxIiIi/vOf/xQVFc2fP7+2tnbRokWNjY19KMrGxmbp0qWNjY3Hjh1DCKWmpq5fv149U7gR6ZvsUS+TJk3i8/kGpn8EAFgqMz8U89prr/373/9et25dXV3djz/+2LdC8NeMX375ZVNT04kTJ/DASH8wJNmjLjgcDn6AFQAAujFRsL548WJqair+OSQkpFvm7xUrViCd30P6sgkTJkyZMuXnn38ODw9ftGiRnZ2dgbXtjSHJHrVSqVTGKgoAYHlMFKyvX78uEAjwz+3t7d0S7OK5HOr5ZPWFb65zcnI2btxoQDW10JrskclkUu+O01dhYSFJklOmTDG8KACA5en3YK1SqZ49e1ZYWEgFa4RQcHDw8ePHm5qampub8/LyPvroo3nz5hkSrBcvXuzg4BAcHOzp6WmMWvdMa7JHiUTy/Pnz3NxclUpVV1ennuAcIWRvb19dXV1RUdHS0oIDcVdXV2NjY0dHR2lpaWRkpFgsXrlyZR+KKigogKl7AFg43R92RNoeU6ayJvbo1KlTeLfvv/8+NDTUy8uLw+Gw2exRo0bFx8dTKQoxmUz2f/7P/7G3t0cIMRgMiUSSmJj48onU0zNu3br1ypUr+Oft27fjScoMBsPHx+enn37SenU6PvqpIdkjSZINDQ2BgYFcLtfDw+ODDz7YsmULQkgikVRVVZEkeePGDXd3dx6PN23atJqamvDwcBaL5ebmxmQyRSLR/PnzpVJp34o6e/asUChMSEjQWn/S0rMnWqrBkw5h8IAUqX1k+l+G8PBwe3t7U54Rs+x+tFQQrC0PDXKDAIr66/IAAEADCNYAAEADEKzNY9u2bVlZWc3NzR4eHjk5OeauDgBgoGOauwKDVFJSUlJSkrlrAQCgDbizBgAAGoBgDQAANADBGgAAaACCNQAA0AAEawAAoAGCJElddyWIfq0KAAAMNrpHYD2m7uGHIwEY4HAy3n7NvwiA6elxZw0ALeDXVx4/ftzcFQHAmGDMGgAAaACCNQAA0AAEawAAoAEI1gAAQAMQrAEAgAYgWAMAAA1AsAYAABqAYA0AADQAwRoAAGgAgjUAANAABGsAAKABCNYAAEADEKwBAIAGIFgDAAANQLAGAAAagGANAAA0AMEaAABoAII1AADQAARrAACgAQjWAABAAxCsAQCABiBYAwAADUCwBgAAGoBgDQAANADBGgAAaACCNQAA0AAEawAAoAEI1gAAQAMQrAEAgAYgWAMAAA1AsAYAABqAYA0AADTANHcFADDUtWvXbt26RS0+ePAAIXTw4EFqzfjx41977TUz1AwA4yFIkjR3HQAwSH5+/pw5c6ysrBgMBkIIf6QJgkAIdXV1dXZ2nj59+p133jFzLQEwDARrQHsqlcrBwUEmk/W4VSQS1dXVsdlsE9cKAOOCMWtAeywWa8mSJT2GYw2bAKAXCNbAEixZskSpVL68XqVSLV261PT1AcDoYBgEWIKurq4//OEPz54967be0dGxpqYGj2UDQGvwIQaWgMFgrFixottwB5vNXrlyJURqYBngcwwsxMsjIUqlcsmSJeaqDwDGBcMgwHKMGDGivLycWvT09JRKpWasDwBGBHfWwHIsX76cxWLhn9ls9p///Gfz1gcAI4I7a2A5ysvLR4wYQS3eu3dv5MiRZqwPAEYEd9bAckgkkvHjxxMEQRDE+PHjIVIDSwLBGliUd99918rKysrK6t133zV3XQAwJhgGARalurp62LBhJEk+evTIzc3N3NUBwGj0DtZXr15NSUnpp9oAYLjCwkKE0BtvvGHmegDQu02bNk2dOlWvQ/QeBnn06FFOTo6+Rw1kOTk5jx8/Nnct+l1RUVFRUZG5a2EKYrHY3d3d3LUwhcHTpxYmJyfn0aNH+h7Vx3zWJ06c6NuBAxBBEBs3bly8eLG5K9K/Fi1ahCyr43rz/PlzhJC9vb25K9LvBk+fWhicv1df8PIBYGkGQ5gGgxDMBgEAABqAYA0AADQAwRoAAGgAgjUAANCA6YL16tWrhUIhQRAlJSUmO2n/OXv2rI2NzenTp81dEQDAoGC6YH348OFDhw6Z7HT9DZ78BACYEkzd66OgoKDm5mYTnEihUMyYMePKlSsmOBcAYMAy6Zh136aCD3KZmZm1tbXmrgUAwMz6N1iTJJmcnDxq1CgOh2NjY7Nlyxb1rZ2dnXFxcWKxmMfjjRs3Ljs7GyGUkZEhEAj4fH5eXt7bb78tEomGDh169OhR6qgLFy68+uqrfD5fJBKNHTtWJpP1VlT/uXTpklgsJgjiiy++0Frnffv2cblcJyentWvXurq6crlcf3//a9eu4a0RERFsNtvFxQUvbtiwQSAQEARRX1+PEIqMjIyKipJKpQRBSCQShNC3334rEokSExP79QIBAAMOqSccB3XcOTY2liCIzz//vLGxUS6Xp6enI4Ru3ryJt27evJnD4eTk5DQ2Nm7bto3BYBQXF+OjEELnzp1rbm6ura0NCAgQCARKpZIkyRcvXohEoj179igUipqamgULFtTV1WkoShcIoezsbH3bAT/av3//fupKe6szSZLh4eECgeDu3bttbW1lZWWTJ08WCoVVVVV467Jly5ydnamSk5OTEUL4ukiSDAkJ8fLyorbm5+cLhcKdO3fqW+GFCxcuXLhQ36PAQAZ9SlN9izn9eGetUChSU1PfeuutTZs22dra8ng89eeA29raMjIygoODQ0JCbG1tt2/fzmKxsrKyqB38/f1FIpGjo2NYWFhra2tVVRVCqKKiQiaT+fr6crlcZ2fnkydPOjg4aC3KZHqsM8ZkMkePHs3hcHx8fDIyMlpaWvpWw6CgIJlMtmPHDuPVGgBAA/0YrMvLy+Vy+YwZM3rceu/ePblcPmbMGLzI4/FcXFx+/fXXl/dks9kIIZVKhRDy9PR0cnJavnx5fHx8RUWFvkWZjHqdXzZp0iQ+n2/eGgIA6KUfgzXOO+ro6Njj1tbWVoTQ9u3bid9VVlbK5XLNZfJ4vPPnz0+bNi0xMdHT0zMsLEyhUPStKPPicDh1dXXmrgUAgDb6MVhzuVyEUHt7e49bcRBPTU1VH5S5evWq1mJ9fX1Pnz5dXV0dHR2dnZ29d+/ePhdlLiqVqqmpaejQoeauCACANvoxWI8ZM4bBYFy4cKHHrcOGDeNyufo+zVhdXX337l2EkKOj46effurn53f37t2+FWVGhYWFJElOmTIFLzKZzN4GTAAAAOvHYO3o6BgSEpKTk5OZmSmTyUpLSw8ePEht5XK5q1atOnr0aEZGhkwm6+zsfPz48dOnTzWXWV1dvXbt2l9//VWpVN68ebOysnLKlCl9K8rEurq6GhsbOzo6SktLIyMjxeL/297dxjR1vQEAP4W2tIWWFxEGOEihiBNRxtRIgSBfyBxRkc2UqUuYGYNNJYgyBAZDBBxCgGhwZhthie4FBMKcUkmUocHh4qYIg23MOpij48WqvEhZC9z/h5P/9a6U9ra0QPH5fbL33p57zn3aY7n3nOd4xsXF4V0ikejRo0f19fVqtXpoaKi3t5f6RicnJ7lc3tPTMzo6qlarpVIpDN0D4Hlk6PARg4bujY6OvvPOO8uWLbOzswsNDc3OzkYIrVix4u7duwRB/Pvvv2lpaZ6enkwmE/fsnZ2d5eXlPB4PIeTr6yuTyT799FOBQIAQ8vLy6u7u7unpEYvFjo6O1tbW7u7umZmZk5OTsxVFs5LI8GE0p06dwiOjeTzetm3bdNeZIIiEhAQWi+Xh4cFkMgUCQXR0tEwmI0tTKBQREREcDkcoFB44cACPRheJRHhs3+3bt728vLhcbmhoaH9/f0NDA5/Pz8vLM6jCBAzzWoogphbKiD6HIAiDF8ytrq6WSCSGvmsxYzAYVVVVZl3WKzEx8fz58wqFwnyn0AuWgFp6IKYWyrg+B1KkzpOpqamFrgIAwIJBZw0AABYAOmuzy8jIqKysHB4eFgqFNTU1C10duq5cuZKeno7/rVarCwoKRCIRm812cHBYs2YNOSOJamJiYtWqVR9++CGd8mtra729vfG4+Lfeeou6KzIyks/nW1tb+/v73759e85NMd709HRpaalYLJ65q6WlJSQkhMfjubm5paWlUYeo5ubmrl69WiAQ2NjYiESiDz74YGxsTGv5GlfswoULhYWF5vsjDGKqo9V0oqb182DuqD1j6E1ugx4wWgRk1M1+i2PQw6js7OytW7eOjIzglzt27PDz87t586ZarZbL5du2bevo6Jj5rpSUFIRQZmYm/Vr5+PgsW7YMIXTx4kXqdqlUun37dvrlmEN3d3dISAhCaN26dRq7fvnlFy6Xm5WVNTY29sMPPzg7O7/99tvk3vDw8PLycoVCMTIyUlVVxWKxXn31Va2nmHnFysrKwsPDHz9+TKeGEFND6Wi13qjp+DwYFDXC2D4HOmvorDUdP3585cqVSqUSv/z6668ZDEZ7e7vud924cSMyMtKIL/aXX35pZWXl4eHx5MkTcvuCf7Hb2tpiYmLOnTsXGBg488spkUiEQuH09DR+WVRUxGAwfv31V/wyKioKD1LC8HMkMm8XabYrlpSUFBwcrFar9VYSYmoQ3a3WHTXdnwfCkKgRizCRE7BE9+7dy8rKOnr0KJ6AihD65JNPgoKCAgICdLxLqVSmpqaWlZUZcUaxWJycnNzX13f48GFjamwe69atq62t3b17t42NjcauycnJS5cuhYeHk/nZt2zZQhDEt99+i19evHjR2tqaPN7Z2RkhpJH/QMcVy8nJaWtrM+5iagUxxXS3WnfUdHweMJNHbSborMF/nDx5kiCIbdu24ZcqlermzZuBgYG635WZmblv377Z8sDolZeXt3Llys8///zKlStaDyAIoqSkBKctdHR0jI6OJtNg6U2AbvJc5/fv3x8bG/P09CS3+Pj4IITa29u1Ht/X18flcoVCIXWjjivm6OgYHh5eVlZGmGiALMQU0W41SWvUdDB51GaCzhr8x6VLl/z8/PAcH4SQXC5XqVQ///xzREQEXjnhpZdeKi8vp34ib9y4IZPJdu3aZfRJuVzuF198YWVlFR8fj9NyacjJyUlPT8/MzBwcHLx+/fqDBw/CwsIGBgYQQu+///7BgweVSiWfz6+qqpLJZN7e3vHx8eQM/iNHjpw4caK0tPSff/7ZunXrrl27fvrpJ6OrihDq7+9HCPH5fHILh8Phcrm4PhrGx8ebmpri4+NxIkZM7xV7+eWX+/r67t69O5d6kiCmNFtN0ho1vUwbtZmgswbPPH369M8//8S/EzH8QHz58uX5+fmdnZ0DAwPR0dH79+//6quv8AFKpTI5Ofn06dNzPHVwcPDBgwd7enqOHDmisUupVJaUlMTExOzZs8fe3j4gIODMmTMPHz6kZi9AsyQTN0euczzwg/onM0KIxWIplcqZBxcUFLi5ueXl5VGbo/eK+fr6IoQ6OjrmUk8MYkqz1VQzo0aHCaOmlZGdNWMJQQhJJJKFroXZ0Rk1ODg4SBAE+RMMIYTv0Pn7+4vFYicnJ3t7+6NHj9rb25NfqoyMjHfffdfDw8O4DxJVXl6en59feXl5S0sLdXtnZ+fY2Nj69evJLRs2bGCz2eTSaBqoycTNkesc3/mdnJykblSpVFwuV+PIurq66urqxsZG6s9wOlcMh0DrT3VDQUwxva0maY0aHSaMmlZGrm5u7kUO55NEIklOTg4ODl7oiphXaWmp3mMmJibQ/z/WmJubG0IILwiJsdlsLy8vmUyGEGppaeno6CgpKTFJDTkcTmVlZWho6N69ewsLC8ntT548QQjZ2dlRD3ZwcBgdHdVbJpnrnDpSGDfKaDgtDF78ExsfH5+YmNAo9ptvvikpKWlubnZ3dyc30rxiuN/H4ZgjiCn1gNlaTdIaNZpMGDWtjOyszZpJY55JJJLg4OCl1CKt6GSQwJ826vB+Ozs7X19fnJaWNDk5aW9vjxCqqKi4evWqldV//j7Lz8/Pz8+/desW9XcTTcHBwSkpKcXFxceOHSOf4Dk4OCCENL7GNBOCk7nOk5OTDa3MbIRCIZ/PpyZHvHfvHkJo7dq15JZTp041NjY2NTVp9Ec0r5hKpUL/D8ccQUwx3a3GZosaTSaMmlZwzxo84+LiwmAwhoeHqRslEsmdO3fu37+PX46Pj/f29uLxT5WVldRxoHjtGzwm14hvNXbs2LFVq1bduXOH3LJmzRo7OzvqE6Qff/xRpVK98sorekszR65zJpP52muvXb9+fXp6Gm+RSqUMBgMPtyAIIi0traOjo76+fuZ3nuYVwyFwdXWde20hpiQdrdYdNZpMGDWtoLMGz/B4PG9vb7weGyklJcXLyysuLu6vv/5SKBRpaWlKpXLmIyOtYmNjXV1dDZpejP9wpj6+43A4hw4dqqurO3fu3MjISEdHx3vvvefm5paQkECntNlynRtRN1JWVtbAwMBHH3309OnT1tbWoqKiuLg4Pz8/hFBXV9eJEyc+++wzFotFfWZQXFxMv3wcAt3joGmCmJJ0tHqxRU07Q2fRwAxGC0VztltSUhKLxRofH6dufPDgwZtvvuno6GhjY7Nx40apVKr1vdRfYdiOHTsQQtnZ2TMPrqurw0MUnJ2d9+/fr7E3NTWVOtttenq6qKjI19eXxWI5Ojru2LHj999/x7v0JhOfLde5jroRBNHa2hoSEkLeCX3hhRfEYvG1a9fIA65du7Zx40YbGxs3N7fU1NSJiQm8fbbBAEVFRXSuGBYVFeXh4UHOkJwNxNSgmOpotd6o6f08ELSjRsB0c6NBZ031xx9/MJnMs2fPmuSkU1NTYWFhFRUVJinNtBZt3R4+fMjhcIqLi/UeCTHVsIB1ox81AqabA5MQiUS5ubm5ubmzJYqjb2pqqr6+fnR0NDY21iR1M6HFXLecnJzAwMCkpCRTFQgxnQcmj9pMZumsqZkSMTab7eLisnnz5qKiosePH5vjpMBU0tPTd+7cGRsbq/FUylDNzc21tbVSqZQ6yHeRWLR1KykpaWtra2hoYLFYJiwWYmpWZoqaJkN/itO/DeLj42Nvb08QBF4r9vvvv4+Li2MwGG5ubrdu3TL0vOaD4DaINo2NjWlpaearD5ipvr6+oKCAmvtNN4jpYmBo1IjFfBuEwWA4ODhs3ry5srKyurp6YGAgKipqjv/DWxClUqk1e/3CFqVXZGTkxx9/PD/nAtj27dvT09M1JrKbEMTUHMwdNdJ837N+44034uLiBgcHz5w5M8+nXigVFRWDg4OLrSgAgGVZgAeMcXFxCCGpVIpfas12qDdHIh44xePxBAJBQEAAnvtr8mSYJGL2dI5JSUlsNhtPQUYI7du3z9bWlsFg4ImtycnJhw4dkslkDAZDJBKdPHmSw+G4uLgkJibi1F9isZjMh2BQUQihy5cvCwSC/Px8UzUTALB4GXrfxIh71hpwx/riiy/il4cPH7axsampqXn8+HFGRoaVlRW+o52ZmYkQunr16vDw8ODgYFhYmK2trUqlIghibGxMIBAUFhYqlcr+/v6YmJihoSEdRemGaNw/ys7OZrPZZ8+effLkSXt7e1BQkLOzc39/P967e/duV1dX8uCioiKEEK4SQRCvv/66j48PuTchIcHW1rarq2tiYqKzs3PDhg18Pp9ckMKgoi5evMjn83Nzc/W2kTD8/iZY/CCmFopOnzPTAvyy5vP5DAYDpwXQm+1Qa47Enp6ekZERf39/Dofj6upaW1vr7OxsjmSYGM10jvQxmUz8I3316tWnT58eHR01rp5RUVEjIyNZWVnGVQMAYEEWoLN++vQpQRB4ShL9bIfUHIne3t4uLi579uzJyckhFyc2RzJMzNB0jgZZv349j8czST0BAEvYAnTW3d3dCKFVq1YhSrZDckR2b2+vxmp1M3G53KamptDQ0Pz8fG9v79jYWKVSaVxRdMwlnSMdNjY2eFIvAADMZgE668uXLyOEtmzZgijZDqm3ZlpbW/UW4u/v/91338nl8rS0tKqqquLiYqOL0msu6Rz1UqvVpioKALCEzXdn3d/fX1paumLFir179yJjsx3K5XKcl3b58uXHjx8PCgrq6uoyRzJMTG86RyaTSa4OZ6jm5maCIDZt2jT3ogAAS5h5O2uCIMbGxnAaqqGhoaqqqpCQEGtr6/r6enzPWke2Qx3kcnliYuJvv/2mUqnu3LnT29u7adMm44qiQ286R5FI9OjRo/r6erVaPTQ0RE1LjxBycnKSy+U9PT2jo6O4I8ZTOicnJ9vb25OTkz09PfFwRkOLkkqlMHQPgOeFocNH6Azdu3Dhwtq1a3k8HpvNxktO4EmMGzduzM3NVSgU1IO1ZjvUnSOxp6dHLBY7OjpaW1u7u7tnZmbiuZ6zJU7UDdEYRqMjnSNBEAqFIiIigsPhCIXCAwcOpKamIoREIhEekHf79m0vLy8ulxsaGtrf35+QkMBisTw8PJhMpkAgiI6OlslkxhXV0NDA5/Pz8vL0tpGAYV5LEcTUQtHpc2ZiENpWYtehurpaIpEY+q7FjMFgVFVVzduyXomJiefPn1coFPNzOtLOnTsRvcW9gKWAmFoo4/ocSJG6AKgL4gEAAB3QWQMAgAWAznpeZWRkVFZWDg8PC4XCmpqaha4OAMBiMBe6As+XgoKCgoKCha4FAMDywC9rAACwANBZAwCABYDOGgAALAB01gAAYAGMfMBYXV1t2nosLJPke1rk/v77b7TkAvecg5g+Xwyd8mjCtbIAAOD5NB/TzQEAAMw/uGcNAAAWADprAACwANBZAwCABYDOGgAALMD/ADrITD75zlMTAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpL9idwZV6fL"
      },
      "source": [
        "For each character the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npruiy2RAPkt"
      },
      "source": [
        "## Try the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4DCLA0GASL1",
        "outputId": "7cb0da8f-35fb-4a0b-d1ce-e9669b571fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 200, 621) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset_sequence_batches.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWebJXU9CEPd"
      },
      "source": [
        "To get actual predictions from the model we need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Jgo-iECFWI",
        "outputId": "dfb3d1d5-c785-4a1c-e5c0-a724626d8cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the 1st letter of the batch 1st sequense:\n",
            "tf.Tensor(\n",
            "[ 9.67553817e-04 -1.32447877e-03  4.20299266e-03 -3.07718292e-03\n",
            " -5.53964730e-03 -2.40335427e-03  4.15250426e-04 -6.05621724e-04\n",
            "  1.90670879e-04 -2.55828025e-04 -5.64306043e-03 -1.93131377e-03\n",
            "  1.69167004e-03 -3.21730186e-04 -1.35243870e-03  4.45078331e-04\n",
            "  4.57338087e-04 -1.50511484e-03  2.34352145e-03 -1.02574646e-03\n",
            "  1.36300304e-03  3.14017583e-04 -1.95305981e-03 -1.14943285e-03\n",
            "  6.36739598e-04  9.97564406e-04  2.86451867e-03  5.15818654e-04\n",
            "  8.94985453e-04 -4.80319548e-04 -2.23535718e-03 -6.61546539e-04\n",
            " -6.12757402e-03 -1.59340654e-03  8.81651649e-04  3.78053100e-03\n",
            "  3.91772483e-03 -1.24532473e-03  3.18357162e-03 -1.20841246e-03\n",
            "  4.98600816e-03  3.20875598e-03  2.48961471e-04 -3.65147949e-03\n",
            " -4.72564204e-03  7.43770215e-05 -5.60463348e-04 -1.56961242e-03\n",
            "  2.48030853e-03 -1.48022163e-03 -2.60224356e-03  1.63893070e-04\n",
            " -7.44520128e-03  3.85469059e-04 -1.44548400e-03  7.37630879e-04\n",
            "  3.08791175e-03  1.61876739e-03 -3.81436112e-04 -7.43623532e-04\n",
            "  4.00087709e-04  1.85155438e-03 -1.71567535e-03 -8.77977698e-04\n",
            "  1.12440775e-03  2.20217160e-03 -5.09562809e-03  2.26272875e-03\n",
            "  4.49755043e-03  3.14021274e-03 -2.93425238e-03 -2.82555958e-03\n",
            " -6.49301568e-03 -2.05938099e-03  6.03881013e-03  2.63633369e-03\n",
            " -1.09704304e-03  3.20476526e-03  4.74104332e-03  4.23230114e-04\n",
            " -4.11667489e-03 -7.38070230e-04 -3.06591205e-03  1.58037874e-03\n",
            "  8.77138868e-04  1.91938641e-04 -2.11883360e-03  3.50379874e-03\n",
            "  6.88104238e-03 -2.39535421e-03  7.49735220e-04 -1.44392252e-03\n",
            "  4.72534308e-03 -5.62725775e-03  4.65203496e-03 -1.95503584e-03\n",
            " -3.24872788e-04 -1.20093476e-03 -4.56246402e-04 -2.85166968e-03\n",
            " -1.32528844e-03  2.20220209e-05  8.74431396e-04 -6.32766227e-04\n",
            " -3.76901170e-03  4.99711419e-03  1.89547183e-03 -1.22047751e-03\n",
            " -4.86758165e-03  3.63017526e-03 -6.28554320e-04  1.37445575e-04\n",
            " -1.27145846e-03  4.84515820e-03  1.00955169e-03  4.44211625e-03\n",
            "  4.25981171e-03 -5.03505813e-03 -9.56950593e-04 -1.79977692e-03\n",
            "  4.52082744e-03  4.01902432e-03  5.58007136e-03 -2.50958325e-03\n",
            "  1.04083563e-03  3.22317192e-03  8.11615027e-04  5.05569577e-03\n",
            " -3.99730809e-04  4.18130439e-05  6.69918861e-03 -5.25582815e-03\n",
            " -1.99985877e-03  8.68097879e-04 -3.49893537e-03  1.55183137e-04\n",
            "  4.14438313e-03  2.56213848e-03 -1.92963774e-03  1.70253275e-03\n",
            "  2.81216414e-03 -2.43475870e-03  1.94127660e-03  1.15659391e-03\n",
            "  1.04300831e-04 -4.16287407e-03  4.99772932e-03 -1.66303304e-03\n",
            "  9.01863968e-05 -1.11697626e-03  3.13560595e-03 -1.41433021e-03\n",
            "  2.52761692e-03 -5.27384167e-04  2.23828852e-03 -3.82372062e-03\n",
            " -6.40579674e-04  2.60822824e-04  1.95675902e-03  3.51543189e-03\n",
            "  7.21253222e-04  1.06463267e-04  3.42826732e-03  1.62865769e-03\n",
            " -2.52833799e-03  4.53047641e-03  3.44045181e-03 -8.02778872e-04\n",
            "  5.14520332e-04 -1.61102333e-03  9.69295681e-04  3.61514132e-04\n",
            " -6.85805455e-04 -1.24863361e-03 -3.05455946e-03  3.71413375e-03\n",
            "  2.18189147e-04 -5.54884493e-04  5.25122043e-03 -9.12387564e-04\n",
            " -3.27899191e-03  8.86539696e-04 -2.96319998e-03  6.25985069e-03\n",
            "  3.07778991e-03  2.87321489e-03  1.11739303e-03 -1.62738259e-03\n",
            "  5.46279480e-04  2.53144972e-05  3.26863024e-03 -1.57724309e-03\n",
            " -1.24493381e-03 -4.82797623e-03 -1.09432172e-03  5.85002184e-04\n",
            " -9.35103220e-04 -8.99003819e-04  4.00084391e-04 -4.40967066e-04\n",
            " -6.60922425e-03  2.48440076e-03 -1.11269392e-03 -1.63778488e-03\n",
            " -4.19637421e-03  5.15905768e-03 -8.03879520e-04  5.46943105e-04\n",
            "  2.50794087e-03 -2.94677867e-03 -1.66290022e-06  3.72950570e-03\n",
            " -1.04531331e-03  5.23049338e-03 -2.04465189e-03  1.38678215e-03\n",
            " -3.05478997e-03 -7.44038355e-03 -1.19963568e-03 -2.42874282e-03\n",
            "  2.63905409e-03 -7.04389007e-04 -2.55378056e-03  2.47672619e-03\n",
            "  5.28550567e-03  8.49775912e-04  4.34249116e-04  2.14951276e-03\n",
            " -4.04521544e-03  1.46342069e-03 -2.56026833e-04 -7.96957756e-04\n",
            " -5.20975236e-03 -2.17531365e-03  6.31780177e-03 -4.47073113e-03\n",
            " -3.68886977e-03  4.80409060e-03  6.04355568e-03  1.03533221e-03\n",
            "  2.14887434e-03  1.95085804e-03  6.67940127e-03  6.34517381e-03\n",
            " -1.64965715e-03 -1.62270747e-03 -2.02873512e-03  3.07647162e-03\n",
            "  2.97738356e-03 -2.87442585e-03 -1.32617878e-03  7.55504007e-04\n",
            " -2.17171619e-03 -3.16137890e-03 -2.30488228e-03 -2.12588161e-03\n",
            "  3.62528185e-03  9.80684534e-04 -2.66464427e-03  2.15888070e-03\n",
            " -1.77725009e-03  1.28886546e-03  2.71031214e-03 -3.02963686e-04\n",
            "  9.21619067e-04  1.29085046e-03  1.46703573e-03  4.60093562e-03\n",
            "  3.72011936e-03  4.89122875e-04  4.71240550e-04 -9.18617414e-04\n",
            "  6.01376314e-03 -3.59594403e-03  5.25917113e-03  1.60783494e-03\n",
            " -3.45947425e-04 -1.86092092e-03  3.17484001e-03  1.13150093e-03\n",
            " -2.49844254e-03 -2.78642727e-03 -4.12132638e-03  1.82518759e-03\n",
            " -5.24643762e-03  1.61146873e-03 -1.97764928e-03  1.55002985e-03\n",
            "  4.21438552e-03 -7.04540289e-04  9.17755824e-04 -6.67328597e-04\n",
            "  4.80600400e-03 -1.49762811e-04 -2.41404655e-03 -1.05903752e-03\n",
            " -1.85389328e-03  6.05925685e-04  1.88053108e-03  1.03810884e-03\n",
            "  3.53704602e-03 -3.64823965e-03  3.72908381e-03 -3.42299842e-04\n",
            " -3.33536067e-03  5.01762028e-04 -1.57466554e-03  8.82966269e-04\n",
            "  2.83644209e-03  9.39281075e-04  1.55732327e-03 -2.81895424e-04\n",
            "  1.32040528e-04  2.91604572e-03  9.96268936e-04  3.76608968e-03\n",
            " -3.57448356e-03  1.66871038e-03  4.72618826e-03  2.06351280e-04\n",
            "  8.31665820e-04  1.90074102e-03 -4.03566193e-03  4.13925201e-03\n",
            " -4.41115786e-04  6.64120540e-04  1.04049162e-03  3.62027506e-03\n",
            "  3.29523277e-03  4.58136958e-04  2.02621124e-03  2.03024293e-03\n",
            "  2.92524433e-04  2.49616220e-03  5.18017448e-03 -1.40395563e-03\n",
            " -3.40774166e-03 -7.21137691e-03 -3.41022736e-03  5.96888480e-04\n",
            " -4.77916515e-03 -3.84305348e-03  3.64618655e-03  4.32187133e-03\n",
            " -2.14072457e-03  9.24255350e-04  9.11690877e-04 -2.05056579e-03\n",
            " -4.75335447e-03  3.60124093e-03 -4.17981530e-03  1.01463753e-03\n",
            " -5.80376829e-04  1.52523688e-03 -8.03492125e-03  1.91391958e-03\n",
            " -1.48803869e-03  8.38945433e-03 -8.51401244e-04  1.97936734e-03\n",
            "  3.65687476e-04 -1.19870761e-03 -4.35703667e-03  1.05752435e-03\n",
            " -3.38916946e-03 -5.21126622e-03  4.40315763e-03 -6.74719806e-04\n",
            " -3.74511816e-03 -4.33025137e-03 -1.68006809e-03 -2.43712938e-03\n",
            "  1.61703210e-04  2.71516386e-03  3.49860522e-03  4.11350699e-03\n",
            "  7.96623179e-04  4.84318618e-04  2.88758916e-03  2.38059973e-03\n",
            " -1.70068850e-03 -9.58667297e-05 -2.15470535e-03  6.95817464e-04\n",
            " -1.11687626e-03  3.77102429e-03 -4.81182506e-04 -1.70776923e-03\n",
            "  6.16990589e-03  3.19778919e-03 -7.15899689e-04  3.06686998e-05\n",
            "  1.39324926e-03  2.47694412e-03  4.39158641e-03 -3.70305474e-03\n",
            " -2.61907629e-03 -3.19406181e-03 -3.27123748e-03 -7.61816591e-06\n",
            " -4.93229181e-03 -6.62054168e-04 -6.68147160e-03 -3.37396795e-03\n",
            " -1.10259256e-03 -2.27944227e-03 -4.51042037e-03  5.02690719e-03\n",
            " -2.84024078e-04  3.20907403e-03  3.01520922e-03 -1.68991322e-03\n",
            "  4.72460734e-03 -3.48501606e-03  5.02595864e-03 -2.75887526e-03\n",
            "  1.48483727e-03 -5.56816021e-03 -3.10084247e-03  3.35951080e-03\n",
            " -5.96669561e-04  2.38757208e-03  1.68804976e-03  1.62734708e-03\n",
            " -1.54836837e-03 -2.68473127e-03  1.05154573e-03 -8.82754452e-04\n",
            "  6.50175934e-05  4.36949963e-03  1.20111601e-03  2.36016087e-04\n",
            " -1.98314688e-03  3.33534833e-03  3.40566179e-03  1.85508840e-03\n",
            "  3.27653834e-03  4.03933600e-03 -1.97609793e-03  7.92160688e-04\n",
            "  3.28902737e-03 -3.77875054e-03  5.42146992e-03 -6.30150724e-04\n",
            " -4.40141978e-03  3.47818062e-03  1.65148091e-03  1.06873584e-03\n",
            "  2.60876585e-03 -1.62696058e-03  4.92650783e-03  3.19063314e-04\n",
            " -1.07957819e-03  5.57820546e-03  2.22076965e-03  3.90869053e-03\n",
            "  3.51401535e-03 -2.64207995e-03  3.47438734e-03 -2.10872517e-04\n",
            "  6.02374645e-03 -4.68395930e-03  1.52942329e-03 -1.14036351e-03\n",
            " -3.42085608e-04  4.22004261e-04 -7.46014295e-04  2.42803548e-03\n",
            "  4.30600531e-03 -3.08138947e-03  1.06298574e-03 -6.60891063e-04\n",
            "  1.72004441e-03  2.91763735e-03  2.62219575e-03 -2.70256097e-03\n",
            " -3.71338427e-03  4.04021330e-03  1.83426702e-04 -4.07095486e-03\n",
            " -2.19334921e-04 -1.56621914e-03  6.92207657e-04 -1.54444482e-03\n",
            " -7.33886962e-04 -4.80655755e-04 -2.12805625e-03 -1.30460097e-03\n",
            "  1.70861336e-03 -4.15927358e-03  4.47043712e-05  2.19001854e-03\n",
            " -2.53696856e-03  2.40563718e-03 -2.26988632e-04 -5.37065091e-04\n",
            " -2.98336567e-03  3.72625713e-04 -1.13630341e-03 -3.74957011e-03\n",
            "  3.87542485e-03  1.56835478e-04 -2.86613125e-03 -2.18332093e-03\n",
            "  1.79720199e-04  9.49759851e-04 -4.97637922e-03  4.99618379e-03\n",
            " -2.49444100e-04  4.37299395e-03 -2.52510072e-04  2.94400030e-04\n",
            " -1.85634091e-03 -1.41540600e-03  3.92869627e-03  3.42406216e-03\n",
            " -3.07882857e-03  1.17083626e-04 -3.48339789e-03  2.62394809e-04\n",
            "  4.04505897e-03  3.92971124e-04  3.52886342e-03  6.02652505e-03\n",
            "  5.22791874e-03  3.52258794e-03  1.56966038e-03 -1.47934631e-03\n",
            " -1.03723060e-03  7.01761601e-05 -1.49604585e-03  1.29557541e-03\n",
            " -7.15975417e-04 -1.13701494e-03 -5.47925942e-03  2.79185222e-03\n",
            " -3.85273923e-03  2.02148873e-03 -1.01761729e-03 -3.53257824e-03\n",
            " -4.78925911e-04  1.87799009e-03 -4.92445799e-03 -4.50992538e-03\n",
            "  5.25204232e-03  1.19950762e-03  8.00023042e-03 -3.71610466e-03\n",
            "  1.87153614e-03  1.27244357e-03  1.84228329e-03 -3.78552987e-03\n",
            " -3.65390093e-03  1.03903026e-03 -6.62077742e-04  9.44374362e-04\n",
            " -6.72240183e-03 -1.08162779e-03 -9.76940850e-04 -1.34522200e-03\n",
            " -5.61117241e-03  4.74136975e-03 -2.39817402e-03 -1.64117990e-03\n",
            "  3.08135612e-04  1.00262894e-03 -6.98005641e-03 -1.63401105e-03\n",
            " -5.10477787e-03 -2.45703873e-03  3.65167949e-03 -2.42593745e-03\n",
            " -1.63002522e-03  2.80043605e-04  4.72978270e-03  3.29364411e-04\n",
            " -2.03438732e-03  2.94367713e-03 -8.24794464e-04 -1.68593181e-03\n",
            " -2.72666337e-04 -2.67967745e-03  8.46944633e-04  2.35086191e-03\n",
            "  1.79434754e-03  2.24484829e-03 -2.58711749e-03  7.74339540e-04\n",
            " -2.25592870e-03  2.11216349e-04 -2.40332820e-03  1.36333995e-03\n",
            " -4.04220773e-03  1.46238296e-03 -6.09874493e-04 -4.56164312e-03\n",
            " -4.82456107e-03  3.82393901e-03 -6.07703347e-03 -4.08918504e-03\n",
            " -2.36585247e-03 -2.10341439e-03  2.87481293e-04  5.44964522e-03\n",
            "  2.05345685e-03 -1.26734003e-03 -3.25432193e-05 -1.99167361e-03\n",
            "  4.34056018e-03  6.43816660e-04  1.78701943e-03  2.64039583e-04\n",
            "  2.12757543e-04  9.05742520e-04 -2.33786600e-03  1.53450866e-03\n",
            "  5.43264067e-03 -1.49118481e-03 -1.29245699e-03 -2.24632351e-03\n",
            " -4.42537246e-03], shape=(621,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print('Prediction for the 1st letter of the batch 1st sequense:')\n",
        "print(example_batch_predictions[0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dOr0MwFHlRb",
        "outputId": "398814d1-3935-44e0-b8b3-c52fe8d96eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[2 1 2 2 2]], shape=(1, 5), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# Quick overview of how tf.random.categorical() works.\n",
        "\n",
        "# logits is 2-D Tensor with shape [batch_size, num_classes].\n",
        "# Each slice [i, :] represents the unnormalized log-probabilities for all classes.\n",
        "# In the example below we say that the probability for class \"0\" is low but the\n",
        "# probability for class \"2\" is much higher.\n",
        "tmp_logits = [\n",
        "  [-0.95, 0, 0.95],\n",
        "];\n",
        "\n",
        "# Let's generate 5 samples. Each sample is a class index. Class probabilities \n",
        "# are being taken into account (we expect to see more samples of class \"2\").\n",
        "tmp_samples = tf.random.categorical(\n",
        "    logits=tmp_logits,\n",
        "    num_samples=5\n",
        ")\n",
        "\n",
        "print(tmp_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPzr0r4zCgS3",
        "outputId": "e0b41abd-cbfc-4b39-ed70-0281a46141e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([200, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(\n",
        "    logits=example_batch_predictions[0],\n",
        "    num_samples=1\n",
        ")\n",
        "\n",
        "sampled_indices.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaA7DclID8dz",
        "outputId": "cdb13c9d-a7eb-4a2e-cc1b-904439364750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "sampled_indices = tf.squeeze(\n",
        "    input=sampled_indices,\n",
        "    axis=-1\n",
        ").numpy()\n",
        "\n",
        "sampled_indices.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ubGQ0gVENhB",
        "outputId": "ca7bee30-ca6d-4a68-ec23-c78a5cf2c5b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([277, 306, 150, 472, 490, 539, 509, 289,  53, 564, 127, 505, 388,\n",
              "       476, 270, 218,  67, 266, 311, 200, 461, 351, 149, 372, 307,  99,\n",
              "       180,  78, 473, 379, 503,  12, 347, 351, 413,  77, 180,  26, 497,\n",
              "        74, 533, 407, 465, 453, 541, 325, 334, 210, 610, 266, 158, 315,\n",
              "       500, 550, 478,  23, 462, 479, 220, 354, 550, 366, 551,  94, 220,\n",
              "       301, 293, 549, 616, 355, 248,  69,  20, 199, 355, 191, 411, 126,\n",
              "       321, 252, 226, 384, 358, 342, 258, 209,  57,  53, 181, 606, 357,\n",
              "       201, 377, 449, 351, 157, 560, 125, 315, 608, 167, 249,   0, 618,\n",
              "       417, 595, 449,  95, 579, 400,  21, 571,  92, 617, 471, 457, 306,\n",
              "       325, 322, 290,  98, 488, 495, 109, 288, 337, 123, 395, 366, 562,\n",
              "       251, 541, 545, 433,  21, 383, 137, 243,  53, 612, 501, 581,  50,\n",
              "       107, 194, 583, 170, 569, 475, 302, 104, 101, 137,  85, 396, 480,\n",
              "       284,  88, 324, 406, 170, 236, 357, 140, 137, 405, 228, 143, 123,\n",
              "       306, 475, 540, 593, 597,  20, 476,  26, 122, 358, 448, 404, 129,\n",
              "        95, 386,  63, 108, 399, 556, 313, 578, 435,   3, 242, 472, 180,\n",
              "       547, 396,  32, 448, 417])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi9HOzw9EajS",
        "outputId": "8868f795-2198-49f8-e9f5-f7e16de681ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " 'tance from an earlier common ancestor rather than being explained by a combination of errors, accidental similarity, excessive semantic latitude in comparisons, borrowings, onomatopoeia, etc.\\n\\nThe lan'\n",
            "\n",
            "Next char prediction:\n",
            " 'נقý児史普寄إS磨ã孤้其גБbћو˚义ชüหل«şm全ี姚*ขช′lş8國i方“介ー本பிο食ћđஅ坪法况5九前Дด法ร泥}Дشت江준ตпd2ʿตǔ•âணуМแนರщμWSŠ镇ธΙำョชč界áஅ門ıр\\tﬂ₱达ョ~薦ệ3育{태光下قபதا§双哪Áأைßṟร石т本桦カ3เíкS马堡虚P½ɔ装ł義兴ص·°ítṣ加רwன’łвธñí‘Оôßق兴會辞通2其8Þนャ—å~ไ^¿ễ澤پ董コ!й児ş民ṣ>ャ₱'\n"
          ]
        }
      ],
      "source": [
        "print('Input:\\n', repr(''.join(index2char[input_example_batch[0]])))\n",
        "print()\n",
        "print('Next char prediction:\\n', repr(''.join(index2char[sampled_indices])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b87e0lsYMTsv",
        "outputId": "58b27829-bf2b-46e4-c50f-f3ed3e22897f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction #0\n",
            "  input: 85 ('t')\n",
            "  next predicted: 73 ('נ')\n",
            "\n",
            "Prediction #1\n",
            "  input: 66 ('a')\n",
            "  next predicted: 73 ('ق')\n",
            "\n",
            "Prediction #2\n",
            "  input: 79 ('n')\n",
            "  next predicted: 73 ('ý')\n",
            "\n",
            "Prediction #3\n",
            "  input: 68 ('c')\n",
            "  next predicted: 73 ('児')\n",
            "\n",
            "Prediction #4\n",
            "  input: 70 ('e')\n",
            "  next predicted: 73 ('史')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, (input_idx, sample_idx) in enumerate(zip(input_example_batch[0][:5], sampled_indices[:5])):\n",
        "    print('Prediction #{:1d}'.format(i))\n",
        "    print('  input: {} ({:s})'.format(input_idx, repr(index2char[input_idx])))\n",
        "    print('  next predicted: {} ({:s})'.format(target_idx, repr(index2char[sample_idx])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqcBufKEE_p6"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4s0-PvrFub5"
      },
      "source": [
        "### Attach an optimizer, and a loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOEUUm6JE95a",
        "outputId": "efdd21e7-cefb-4313-8394-adbe679ce17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 200, 621)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       6.431178\n"
          ]
        }
      ],
      "source": [
        "# An objective function.\n",
        "# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
        "      y_true=labels,\n",
        "      y_pred=logits,\n",
        "      from_logits=True\n",
        "    )\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SXhJsB6eFgrJ"
      },
      "outputs": [],
      "source": [
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss=loss\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFg9MFJoGZWf"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "AVk-pARPGaja"
      },
      "outputs": [],
      "source": [
        "EPOCHS=150\n",
        "STEPS_PER_EPOCH = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0rveBdAGeEz",
        "outputId": "e19b08ed-9b1c-407b-b63b-5ac03c521e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 4.3816\n",
            "Epoch 2/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 3.3779\n",
            "Epoch 3/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 3.2766\n",
            "Epoch 4/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 3.2857\n",
            "Epoch 5/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 3.1747\n",
            "Epoch 6/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 3.0932\n",
            "Epoch 7/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 3.0513\n",
            "Epoch 8/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.9807\n",
            "Epoch 9/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.9098\n",
            "Epoch 10/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.9249\n",
            "Epoch 11/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 3.0286\n",
            "Epoch 12/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.7936\n",
            "Epoch 13/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 2.7389\n",
            "Epoch 14/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.6971\n",
            "Epoch 15/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.6530\n",
            "Epoch 16/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5929\n",
            "Epoch 17/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5814\n",
            "Epoch 18/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.6751\n",
            "Epoch 19/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.6039\n",
            "Epoch 20/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5761\n",
            "Epoch 21/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 2.4891\n",
            "Epoch 22/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5214\n",
            "Epoch 23/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 2.5498\n",
            "Epoch 24/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5384\n",
            "Epoch 25/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5010\n",
            "Epoch 26/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4632\n",
            "Epoch 27/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4413\n",
            "Epoch 28/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.5647\n",
            "Epoch 29/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4215\n",
            "Epoch 30/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4334\n",
            "Epoch 31/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4085\n",
            "Epoch 32/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 2.3837\n",
            "Epoch 33/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4060\n",
            "Epoch 34/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3098\n",
            "Epoch 35/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.4310\n",
            "Epoch 36/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3782\n",
            "Epoch 37/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3258\n",
            "Epoch 38/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3682\n",
            "Epoch 39/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3593\n",
            "Epoch 40/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3407\n",
            "Epoch 41/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 2.2635\n",
            "Epoch 42/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2072\n",
            "Epoch 43/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.3768\n",
            "Epoch 44/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2803\n",
            "Epoch 45/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2590\n",
            "Epoch 46/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2867\n",
            "Epoch 47/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2130\n",
            "Epoch 48/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2033\n",
            "Epoch 49/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2077\n",
            "Epoch 50/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1716\n",
            "Epoch 51/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2358\n",
            "Epoch 52/150\n",
            "10/10 [==============================] - 33s 3s/step - loss: 2.2421\n",
            "Epoch 53/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2602\n",
            "Epoch 54/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1678\n",
            "Epoch 55/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1700\n",
            "Epoch 56/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1441\n",
            "Epoch 57/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1395\n",
            "Epoch 58/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1424\n",
            "Epoch 59/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1022\n",
            "Epoch 60/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1526\n",
            "Epoch 61/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0471\n",
            "Epoch 62/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1422\n",
            "Epoch 63/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1343\n",
            "Epoch 64/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.2307\n",
            "Epoch 65/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0991\n",
            "Epoch 66/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0670\n",
            "Epoch 67/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0713\n",
            "Epoch 68/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 2.1828\n",
            "Epoch 69/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0907\n",
            "Epoch 70/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 2.0783\n",
            "Epoch 71/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0344\n",
            "Epoch 72/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0231\n",
            "Epoch 73/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1919\n",
            "Epoch 74/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 2.0502\n",
            "Epoch 75/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1463\n",
            "Epoch 76/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1058\n",
            "Epoch 77/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0523\n",
            "Epoch 78/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0714\n",
            "Epoch 79/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.1430\n",
            "Epoch 80/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 2.0438\n",
            "Epoch 81/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9487\n",
            "Epoch 82/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9881\n",
            "Epoch 83/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9699\n",
            "Epoch 84/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9569\n",
            "Epoch 85/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9816\n",
            "Epoch 86/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9986\n",
            "Epoch 87/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9558\n",
            "Epoch 88/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9125\n",
            "Epoch 89/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9602\n",
            "Epoch 90/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9017\n",
            "Epoch 91/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9396\n",
            "Epoch 92/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9121\n",
            "Epoch 93/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9423\n",
            "Epoch 94/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9767\n",
            "Epoch 95/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9107\n",
            "Epoch 96/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8814\n",
            "Epoch 97/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9132\n",
            "Epoch 98/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8786\n",
            "Epoch 99/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9184\n",
            "Epoch 100/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9145\n",
            "Epoch 101/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9237\n",
            "Epoch 102/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.9067\n",
            "Epoch 103/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8654\n",
            "Epoch 104/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8568\n",
            "Epoch 105/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8758\n",
            "Epoch 106/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8733\n",
            "Epoch 107/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8961\n",
            "Epoch 108/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8627\n",
            "Epoch 109/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 2.0236\n",
            "Epoch 110/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8952\n",
            "Epoch 111/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8164\n",
            "Epoch 112/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8421\n",
            "Epoch 113/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8281\n",
            "Epoch 114/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8384\n",
            "Epoch 115/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8910\n",
            "Epoch 116/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8624\n",
            "Epoch 117/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8111\n",
            "Epoch 118/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8167\n",
            "Epoch 119/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7837\n",
            "Epoch 120/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8723\n",
            "Epoch 121/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9789\n",
            "Epoch 122/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8598\n",
            "Epoch 123/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8294\n",
            "Epoch 124/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7955\n",
            "Epoch 125/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8087\n",
            "Epoch 126/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7790\n",
            "Epoch 127/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8425\n",
            "Epoch 128/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8287\n",
            "Epoch 129/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8974\n",
            "Epoch 130/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.7536\n",
            "Epoch 131/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8103\n",
            "Epoch 132/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8230\n",
            "Epoch 133/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9005\n",
            "Epoch 134/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8131\n",
            "Epoch 135/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.8047\n",
            "Epoch 136/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.7767\n",
            "Epoch 137/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7925\n",
            "Epoch 138/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7674\n",
            "Epoch 139/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7811\n",
            "Epoch 140/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7913\n",
            "Epoch 141/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8168\n",
            "Epoch 142/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7723\n",
            "Epoch 143/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7476\n",
            "Epoch 144/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7981\n",
            "Epoch 145/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.9236\n",
            "Epoch 146/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8293\n",
            "Epoch 147/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.8586\n",
            "Epoch 148/150\n",
            "10/10 [==============================] - 32s 3s/step - loss: 1.7614\n",
            "Epoch 149/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.7570\n",
            "Epoch 150/150\n",
            "10/10 [==============================] - 31s 3s/step - loss: 1.6417\n"
          ]
        }
      ],
      "source": [
        "tmp_dataset = dataset_sequence_batches.repeat()\n",
        "    \n",
        "history = model.fit(\n",
        "    x=tmp_dataset.as_numpy_iterator(),\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mLdnOyvzMggJ"
      },
      "outputs": [],
      "source": [
        "def render_training_history(training_history):\n",
        "    loss = training_history.history['loss']\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(loss, label='Training set')\n",
        "    plt.legend()\n",
        "    plt.grid(linestyle='--', linewidth=1, alpha=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "4Ghveem_OQBV",
        "outputId": "b083d5fe-2f07-429d-908b-fff70de96b55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "render_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "print(\"BPC:\"+ str(1.6417 / math.log(2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7r7KhflkXkI",
        "outputId": "398b4b2b-cdf3-482c-d755-90f86febc9e4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BPC:2.3684724486274114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-dhNP2OG2EM"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "l7evN0LvH01P"
      },
      "outputs": [],
      "source": [
        "simplified_batch_size = 1\n",
        "\n",
        "restored_model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "restored_model.set_weights(model.get_weights())\n",
        "\n",
        "restored_model.build(tf.TensorShape([simplified_batch_size, None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3eduDtZI9zQ",
        "outputId": "f9e7f9fd-dfb1-452f-e783-ff4d668ae7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 256)            158976    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (1, None, 1024)           5246976   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 621)            636525    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,042,477\n",
            "Trainable params: 6,042,477\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "restored_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euNvAtr4JC3A"
      },
      "source": [
        "### The prediction loop\n",
        "\n",
        "The following code block generates the text:\n",
        "\n",
        "- It Starts by choosing a start string, initializing the RNN state and setting the number of characters to generate.\n",
        "\n",
        "- Get the prediction distribution of the next character using the start string and the RNN state.\n",
        "\n",
        "- Then, use a categorical distribution to calculate the index of the predicted character. Use this predicted character as our next input to the model.\n",
        "\n",
        "- The RNN state returned by the model is fed back into the model so that it now has more context, instead than only one character. After predicting the next character, the modified RNN states are again fed back into the model, which is how it learns as it gets more context from the previously predicted characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bOqdqGouJFf_"
      },
      "outputs": [],
      "source": [
        "# num_generate\n",
        "# - number of characters to generate.\n",
        "#\n",
        "# temperature\n",
        "# - Low temperatures results in more predictable text.\n",
        "# - Higher temperatures results in more surprising text.\n",
        "# - Experiment to find the best setting.\n",
        "def generate_text(model, start_string, num_generate = 1000, temperature=1.0):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing).\n",
        "    input_indices = [char2index[s] for s in start_string]\n",
        "    input_indices = tf.expand_dims(input_indices, 0)\n",
        "\n",
        "    # Empty string to store our results.\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1.\n",
        "    model.reset_states()\n",
        "    for char_index in range(num_generate):\n",
        "        predictions = model(input_indices)\n",
        "        # remove the batch dimension\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # Using a categorical distribution to predict the character returned by the model.\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(\n",
        "        predictions,\n",
        "        num_samples=1\n",
        "        )[-1,0].numpy()\n",
        "\n",
        "        # We pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state.\n",
        "        input_indices = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(index2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VHWjhPBFV64Q",
        "outputId": "3c6c8f60-964f-4639-979d-851cb48fa1b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature: 0.2\n",
            "---\n",
            "Science is a series of the competition of the program and the time of the transport of the served and the competitors of the three the the present of the control of the town the program of the program of the the terring the track the track the first served the transing the time of the competitors of the the t\n",
            "\n",
            "\n",
            "Temperature: 0.4\n",
            "---\n",
            "Science is a signal of the first of the production was a streat settle of the competition of the first part of the action of the competitors of the organian massic program to the group and state of the competitors and a special streat with the most of the time of the Marina of the March School of the Stard of\n",
            "\n",
            "\n",
            "Temperature: 0.6\n",
            "---\n",
            "Science is reals of the elexing in the retir present from British while may the three its required the other had of twe not the second from the station of the story larger competitory of Harler (international Airprine (A Aurtroud historical and moder 1, 2009. It was presentation of the battle of Hardel Orenia\n",
            "\n",
            "\n",
            "Temperature: 0.8\n",
            "---\n",
            "Science is off allown ab renamed with a due to be one were only tenedalizal light recorded of the studing that to the reconners, which wrote was edition and step. Jo ras new other, constitute moresions made the cantains a served the called from a truring the pocition conding in a were office-songy, which a do\n",
            "\n",
            "\n",
            "Temperature: 1.0\n",
            "---\n",
            "Science is the rotals, only enailly into the Come Graze Cheber-High.\". Česping in fecture liker trached for three forsed dace de soliers, the musicors and other of stirld by an intercents of not promitable in the frum real swraller of the Flogist, when his when Ition. In 1999, up founder called is a teem sole\n",
            "\n",
            "\n",
            "Temperature: 1.2\n",
            "---\n",
            "Science issumed over the were defigure firms of propleen). Hetcens, in the specing levio start signs flamorabodyetm a Quel\"st base consite resent the quéstry or éarnat) of supplement pplodinaly senses weres frohing tyree high proporration iopodted, he ļetains veovels of-expired rove state of the easpers: (‎Vh\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_generate = 300\n",
        "temperatures = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2]\n",
        "start_string = 'Science is'\n",
        "\n",
        "for temperature in temperatures:\n",
        "    print(\"Temperature: {}\".format(temperature))\n",
        "    print('---')\n",
        "    print(generate_text(restored_model, start_string, num_generate=num_generate, temperature=temperature))\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_generate = 300\n",
        "temperatures = [0.2, 0.4, 0.6, 0.8, 1.0, 1.2]\n",
        "start_string = 'What is'\n",
        "\n",
        "for temperature in temperatures:\n",
        "    print(\"Temperature: {}\".format(temperature))\n",
        "    print('---')\n",
        "    print(generate_text(restored_model, start_string, num_generate=num_generate, temperature=temperature))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR2smflYj8y3",
        "outputId": "b87e9ea5-50c8-49a6-ca60-113cc95def5e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature: 0.2\n",
            "---\n",
            "What is a served the first the the two control of the survent of the two the control of the second the program in the term of the contember of the second the served a string program of the control of the second with the program and the program in the competitors of the control of the competition of the com\n",
            "\n",
            "\n",
            "Temperature: 0.4\n",
            "---\n",
            "What is a second the program which assembly and the served the competition of the competition of the special sumpers of the program in the same of the respection with the month of the areas and the character of the China Carron and State of the track in the first first starts of the base the broad and the \n",
            "\n",
            "\n",
            "Temperature: 0.6\n",
            "---\n",
            "What is not a program from a society competited in fired by the competitor was a baseball in the sarist of the contuin the music school from the list of the sublegation and the counts of the Barrood International Armania Lational Regional Atall Brigal, 1990. The competitor of the transide present of the se\n",
            "\n",
            "\n",
            "Temperature: 0.8\n",
            "---\n",
            "What is competition easters that , , 160 on the part latter the end of is only the Ranger, where  Marrai Libited until Latters and played from Chille (1999), chisting the who matting in well the replace, and stored the pregion brother, which transport on the part between which first of the 1 Va and retired\n",
            "\n",
            "\n",
            "Temperature: 1.0\n",
            "---\n",
            "What is formers including vade sequent sixt.  The ware three arpasters\n",
            "Category:EFfilin Carhles workerse\n",
            "Marby. Or only whon minor of Thossey, and movement this programp tower oreach the sitter. Afters personal general his first ligles Backbai Games of day, and Signship instate only 1999: Adaip 120, at the\n",
            "\n",
            "\n",
            "Temperature: 1.2\n",
            "---\n",
            "What is to depide operative fed E Rack sawe from 1999 and cestem holvere in maneral wadelfic.GTSpion) wither firn, but arti-lays 3lon\n",
            ", unting of  or fire on arl states in order of Eder Marlinsi the time >2 Wonlympix, comssive smetrant in thise. Grene then be anorgaced to intensistancy working rporthi:* To\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hh80MqEO_XI"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VPE98xa8PA-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c35d47b-7b6f-4790-8497-8c18c02457a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "model_name = 'wikipedia_rnn.h5'\n",
        "restored_model.save(model_name, save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7btfVWYRj7L6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "wikipedia_rnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54eecfe79eb94c5c99da114100bcc773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba9c35ae1b2d4d319c49e3e082ebd6a0",
              "IPY_MODEL_d92aa3c2a711465d9231404fdb1b7d7c",
              "IPY_MODEL_37081c453e7c4311aaf25248568da59f"
            ],
            "layout": "IPY_MODEL_beac80ee20824617b033b3e46ca1c924"
          }
        },
        "ba9c35ae1b2d4d319c49e3e082ebd6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b24fba6a52049cf811bc7149ced948a",
            "placeholder": "​",
            "style": "IPY_MODEL_768533de65524f5d9437f84d4ef7b78d",
            "value": "Dl Completed...: 100%"
          }
        },
        "d92aa3c2a711465d9231404fdb1b7d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f5e7a5c7bc42c2aba4afd3ed3faa0c",
            "max": 258,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b34d165ff304e9282c8e86dc83e23ff",
            "value": 258
          }
        },
        "37081c453e7c4311aaf25248568da59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dcccf36369a431b9ce8ba503c23d5a0",
            "placeholder": "​",
            "style": "IPY_MODEL_71b63b483b2d407f8d1d5a686e4870c9",
            "value": " 258/258 [01:31&lt;00:00,  2.22 file/s]"
          }
        },
        "beac80ee20824617b033b3e46ca1c924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b24fba6a52049cf811bc7149ced948a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768533de65524f5d9437f84d4ef7b78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78f5e7a5c7bc42c2aba4afd3ed3faa0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b34d165ff304e9282c8e86dc83e23ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dcccf36369a431b9ce8ba503c23d5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b63b483b2d407f8d1d5a686e4870c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}