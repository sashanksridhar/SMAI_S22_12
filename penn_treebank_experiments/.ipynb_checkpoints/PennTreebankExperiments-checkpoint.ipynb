{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from collections import Counter\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "\n",
    "from torch.nn.utils import vector_to_parameters, parameters_to_vector\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgHmdlPhL8oF",
    "outputId": "aa6336f4-446a-4e23-e69b-76ef7f67cfee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Acquiring datasets ===\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "!echo \"=== Acquiring datasets ===\"\n",
    "!echo \"---\"\n",
    "\n",
    "!mkdir -p data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oz_r7xiOI_6s",
    "outputId": "edc3838e-cbce-4dfa-efec-7f8a1cbc1a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd_scratch/cvit/sashank.sridhar/data\n"
     ]
    }
   ],
   "source": [
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L0wfV1YeMKok"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penn  pennchar\tsimple-examples.tgz\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EK7K7MACI4nY",
    "outputId": "73c09e7d-b960-4b3c-d7f3-d71398222e19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Downloading Penn Treebank (PTB)\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"- Downloading Penn Treebank (PTB)\"\n",
    "!wget --quiet --continue http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
    "!tar -xzf simple-examples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdDffaaGJAer",
    "outputId": "1eb554c1-348a-48a5-f8c7-f51aa7f1e6b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd_scratch/cvit/sashank.sridhar/data/penn\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p penn\n",
    "%cd penn\n",
    "!mv ../simple-examples/data/ptb.train.txt train.txt\n",
    "!mv ../simple-examples/data/ptb.test.txt test.txt\n",
    "!mv ../simple-examples/data/ptb.valid.txt valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCTp_5tbNPhS",
    "outputId": "ae20e2a6-7912-42de-bd4d-4a52e24453d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Downloading Penn Treebank (Character)\n",
      "/ssd_scratch/cvit/sashank.sridhar/data/pennchar\n"
     ]
    }
   ],
   "source": [
    "!echo \"- Downloading Penn Treebank (Character)\"\n",
    "!mkdir -p ../pennchar\n",
    "%cd ../pennchar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "74fCeou3JAqF"
   },
   "outputs": [],
   "source": [
    "!mv ../simple-examples/data/ptb.char.train.txt train.txt\n",
    "!mv ../simple-examples/data/ptb.char.test.txt test.txt\n",
    "!mv ../simple-examples/data/ptb.char.valid.txt valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5-sFaSl5NbMX"
   },
   "outputs": [],
   "source": [
    "!rm -rf ../simple-examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rnPPAw67682"
   },
   "source": [
    "**Character - Without Noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "m_kekY5EAKbx"
   },
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp) # Token2Embeddings\n",
    "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout) #(seq_len, batch_size, emb_size)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        self.init_weights()\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.05\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input size(bptt, bsz)\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        # emb size(bptt, bsz, embsize)\n",
    "        # hid size(layers, bsz, nhid)\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        # output size(bptt, bsz, nhid)\n",
    "        output = self.drop(output)\n",
    "        # decoder: nhid -> ntoken\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        # LSTM h and c\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new_zeros(self.nlayers, bsz, self.nhid), weight.new_zeros(self.nlayers, bsz, self.nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3_xiIWpEAOGD"
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.counter = Counter()\n",
    "        self.total = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        token_id = self.word2idx[word]\n",
    "        self.counter[token_id] += 1\n",
    "        self.total += 1\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r') as f:\n",
    "            ids = torch.LongTensor(tokens)\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx[word]\n",
    "                    token += 1\n",
    "\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9y8nlquAgmg",
    "outputId": "033baaac-e2c5-4702-c648-d2c3a9e2622d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd_scratch/cvit/sashank.sridhar/data\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOf8u9RhAlcT",
    "outputId": "65c30ab5-2de1-42c4-d8bb-c17da3adf157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd_scratch/cvit/sashank.sridhar\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char_Noise_Adaptive.png  data\t\t\t\tvalidation.txt\r\n",
      "Char_Noise.png\t\t losses.txt\t\t\tWord_Noise.png\r\n",
      "Char_None.png\t\t output\r\n",
      "checkpoint.pt\t\t PennTreebankExperiments.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pzlWhsBYAYMl"
   },
   "outputs": [],
   "source": [
    "data = 'data/pennchar'\n",
    "batch_size = 256\n",
    "emsize = 256\n",
    "nlayers = 1\n",
    "nhid = 1000\n",
    "lr = 0.0001\n",
    "dropout = 0.5\n",
    "checkpoint = ''\n",
    "clip = 1\n",
    "bptt = 35\n",
    "save = 'output/model_test_character_none.pt'\n",
    "\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "# Load data\n",
    "corpus = Corpus(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6FvrRumyA1L7"
   },
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bGLbW8TzAbRw"
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 256\n",
    "train_data = batchify(corpus.train, batch_size) # size(total_len//bsz, bsz)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CNXQXMK9BA4B",
    "outputId": "c5a072d6-129f-4399-de1b-1600076cec1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byMAy3UfBCKQ",
    "outputId": "fc894476-d76b-4a5d-cfed-ca493ba4152a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  9,  ...,  3, 20,  0],\n",
       "        [ 1,  2, 10,  ...,  7,  7, 24],\n",
       "        [ 2,  3,  7,  ..., 17, 13,  0],\n",
       "        ...,\n",
       "        [ 8,  4,  7,  ..., 21, 28, 26],\n",
       "        [ 7, 10, 15,  ...,  3,  3, 10],\n",
       "        [ 4,  9,  2,  ..., 16, 12,  5]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1NZXjd9BLM7",
    "outputId": "7f4a296a-0a65-4716-dbe6-6b41e93d14e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  3,  3,  ...,  7,  3, 14],\n",
       "        [ 7, 29, 24,  ..., 15, 18,  3],\n",
       "        [ 3,  3,  0,  ...,  5,  2, 33],\n",
       "        ...,\n",
       "        [ 3,  3,  3,  ...,  7,  2, 17],\n",
       "        [ 7,  0,  8,  ..., 18, 21,  3],\n",
       "        [ 2, 16, 20,  ...,  1,  0, 13]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.to(device)\n",
    "test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-dm-QF-BQlt",
    "outputId": "30eae925-e0ed-484c-8518-3fc9e17156ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (encoder): Embedding(50, 256)\n",
      "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
      "  (decoder): Linear(in_features=1000, out_features=50, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sashank.sridhar/miniconda3/envs/TripletLoss/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "interval = 50 # interval to report\n",
    "ntokens = len(corpus.dictionary) # 10000\n",
    "epochs = 50\n",
    "model = RNNModel(ntokens, emsize, nhid, nlayers, dropout)\n",
    "\n",
    "# Load checkpoint\n",
    "if checkpoint != '':\n",
    "    model = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6Sd1VoOBYb3",
    "outputId": "72beda04-ea32-420c-9b4e-25f3b0bfd020"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): Embedding(50, 256)\n",
       "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
       "  (decoder): Linear(in_features=1000, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "a4NH_KQaBbW-"
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    # detach\n",
    "    return tuple(v.clone().detach() for v in h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YolhdEasBgCt"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(source, i):\n",
    "    # source: size(total_len//bsz, bsz)\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    #data = torch.tensor(source[i:i+seq_len]) # size(bptt, bsz)\n",
    "    data = source[i:i+seq_len].clone().detach()\n",
    "    target = source[i+1:i+1+seq_len].clone().detach().view(-1)\n",
    "    #target = torch.tensor(source[i+1:i+1+seq_len].view(-1)) # size(bptt * bsz)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "RyWNpGhkBgyt"
   },
   "outputs": [],
   "source": [
    "def evaluate(data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        ntokens = len(corpus.dictionary)\n",
    "        hidden = model.init_hidden(eval_batch_size) #hidden size(nlayers, bsz, hdsize)\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):# iterate over every timestep\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output, hidden = model(data.to(device), hidden)\n",
    "            # model input and output\n",
    "            # inputdata size(bptt, bsz), and size(bptt, bsz, embsize) after embedding\n",
    "            # output size(bptt*bsz, ntoken)\n",
    "            total_loss += len(data) * criterion(output.to(device), targets.to(device)).data\n",
    "            hidden = repackage_hidden(hidden)\n",
    "        return total_loss / len(data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "37Y1ELGCBiaF"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # choose a optimizer\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    # train_data size(batchcnt, bsz)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        # print(hidden.to(device))\n",
    "        output, hidden = model(data.to(device), hidden)\n",
    "        loss = criterion(output.to(device), targets.to(device))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), clip)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if batch % interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "                epoch, batch, len(train_data) // bptt, lr,\n",
    "                elapsed * 1000 / interval, cur_loss, math.exp(cur_loss), cur_loss / math.log(2)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIOn7vmfBtif",
    "outputId": "a549bd30-8a60-4e2c-bb64-9151c4d41b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:\n",
      "Train:  5017483\n",
      "Valid:  393043\n",
      "Test:   442424\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\")\n",
    "print(\"Train: \", len(corpus.train))\n",
    "print(\"Valid: \", len(corpus.valid))\n",
    "print(\"Test:  \", len(corpus.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCKEoCZjBk9q",
    "outputId": "07266aa7-1694-4a72-c758-1f9fbaebaa7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  559 batches | lr 0.0001 | ms/batch 38.79 | loss  3.99 | ppl    53.98 | bpc    5.754\n",
      "| epoch   1 |   100/  559 batches | lr 0.0001 | ms/batch 36.95 | loss  3.89 | ppl    49.16 | bpc    5.619\n",
      "| epoch   1 |   150/  559 batches | lr 0.0001 | ms/batch 36.91 | loss  3.87 | ppl    47.96 | bpc    5.584\n",
      "| epoch   1 |   200/  559 batches | lr 0.0001 | ms/batch 37.22 | loss  3.84 | ppl    46.56 | bpc    5.541\n",
      "| epoch   1 |   250/  559 batches | lr 0.0001 | ms/batch 37.26 | loss  3.81 | ppl    45.04 | bpc    5.493\n",
      "| epoch   1 |   300/  559 batches | lr 0.0001 | ms/batch 37.21 | loss  3.77 | ppl    43.52 | bpc    5.444\n",
      "| epoch   1 |   350/  559 batches | lr 0.0001 | ms/batch 37.23 | loss  3.74 | ppl    42.01 | bpc    5.393\n",
      "| epoch   1 |   400/  559 batches | lr 0.0001 | ms/batch 37.37 | loss  3.70 | ppl    40.53 | bpc    5.341\n",
      "| epoch   1 |   450/  559 batches | lr 0.0001 | ms/batch 37.34 | loss  3.67 | ppl    39.08 | bpc    5.288\n",
      "| epoch   1 |   500/  559 batches | lr 0.0001 | ms/batch 37.35 | loss  3.63 | ppl    37.66 | bpc    5.235\n",
      "| epoch   1 |   550/  559 batches | lr 0.0001 | ms/batch 37.36 | loss  3.59 | ppl    36.26 | bpc    5.180\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 28.46s | valid loss  3.56 | valid ppl    35.20 | bpc    5.138\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 3.561103).  Saving model ...\n",
      "| epoch   2 |    50/  559 batches | lr 0.0001 | ms/batch 38.29 | loss  3.62 | ppl    37.20 | bpc    5.217\n",
      "| epoch   2 |   100/  559 batches | lr 0.0001 | ms/batch 37.71 | loss  3.51 | ppl    33.31 | bpc    5.058\n",
      "| epoch   2 |   150/  559 batches | lr 0.0001 | ms/batch 37.71 | loss  3.47 | ppl    32.05 | bpc    5.002\n",
      "| epoch   2 |   200/  559 batches | lr 0.0001 | ms/batch 37.75 | loss  3.43 | ppl    30.84 | bpc    4.947\n",
      "| epoch   2 |   250/  559 batches | lr 0.0001 | ms/batch 37.72 | loss  3.39 | ppl    29.59 | bpc    4.887\n",
      "| epoch   2 |   300/  559 batches | lr 0.0001 | ms/batch 37.83 | loss  3.35 | ppl    28.52 | bpc    4.834\n",
      "| epoch   2 |   350/  559 batches | lr 0.0001 | ms/batch 37.86 | loss  3.32 | ppl    27.53 | bpc    4.783\n",
      "| epoch   2 |   400/  559 batches | lr 0.0001 | ms/batch 37.85 | loss  3.28 | ppl    26.67 | bpc    4.737\n",
      "| epoch   2 |   450/  559 batches | lr 0.0001 | ms/batch 37.93 | loss  3.25 | ppl    25.91 | bpc    4.695\n",
      "| epoch   2 |   500/  559 batches | lr 0.0001 | ms/batch 37.92 | loss  3.23 | ppl    25.20 | bpc    4.655\n",
      "| epoch   2 |   550/  559 batches | lr 0.0001 | ms/batch 37.90 | loss  3.20 | ppl    24.53 | bpc    4.616\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 28.87s | valid loss  3.18 | valid ppl    24.00 | bpc    4.585\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.561103 --> 3.178010).  Saving model ...\n",
      "| epoch   3 |    50/  559 batches | lr 0.0001 | ms/batch 38.84 | loss  3.24 | ppl    25.41 | bpc    4.668\n",
      "| epoch   3 |   100/  559 batches | lr 0.0001 | ms/batch 38.10 | loss  3.15 | ppl    23.31 | bpc    4.543\n",
      "| epoch   3 |   150/  559 batches | lr 0.0001 | ms/batch 38.23 | loss  3.13 | ppl    22.93 | bpc    4.519\n",
      "| epoch   3 |   200/  559 batches | lr 0.0001 | ms/batch 38.20 | loss  3.12 | ppl    22.68 | bpc    4.504\n",
      "| epoch   3 |   250/  559 batches | lr 0.0001 | ms/batch 38.28 | loss  3.10 | ppl    22.31 | bpc    4.479\n",
      "| epoch   3 |   300/  559 batches | lr 0.0001 | ms/batch 38.32 | loss  3.10 | ppl    22.13 | bpc    4.468\n",
      "| epoch   3 |   350/  559 batches | lr 0.0001 | ms/batch 38.33 | loss  3.09 | ppl    21.94 | bpc    4.456\n",
      "| epoch   3 |   400/  559 batches | lr 0.0001 | ms/batch 38.44 | loss  3.08 | ppl    21.79 | bpc    4.446\n",
      "| epoch   3 |   450/  559 batches | lr 0.0001 | ms/batch 39.61 | loss  3.07 | ppl    21.62 | bpc    4.434\n",
      "| epoch   3 |   500/  559 batches | lr 0.0001 | ms/batch 39.49 | loss  3.07 | ppl    21.51 | bpc    4.427\n",
      "| epoch   3 |   550/  559 batches | lr 0.0001 | ms/batch 40.27 | loss  3.06 | ppl    21.37 | bpc    4.417\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 29.96s | valid loss  3.06 | valid ppl    21.23 | bpc    4.408\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.178010 --> 3.055452).  Saving model ...\n",
      "| epoch   4 |    50/  559 batches | lr 0.0001 | ms/batch 39.77 | loss  3.12 | ppl    22.67 | bpc    4.503\n",
      "| epoch   4 |   100/  559 batches | lr 0.0001 | ms/batch 41.66 | loss  3.05 | ppl    21.19 | bpc    4.406\n",
      "| epoch   4 |   150/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.05 | ppl    21.14 | bpc    4.402\n",
      "| epoch   4 |   200/  559 batches | lr 0.0001 | ms/batch 41.44 | loss  3.05 | ppl    21.17 | bpc    4.404\n",
      "| epoch   4 |   250/  559 batches | lr 0.0001 | ms/batch 41.24 | loss  3.04 | ppl    21.00 | bpc    4.392\n",
      "| epoch   4 |   300/  559 batches | lr 0.0001 | ms/batch 41.07 | loss  3.04 | ppl    20.99 | bpc    4.392\n",
      "| epoch   4 |   350/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.04 | ppl    20.94 | bpc    4.388\n",
      "| epoch   4 |   400/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  3.04 | ppl    20.90 | bpc    4.385\n",
      "| epoch   4 |   450/  559 batches | lr 0.0001 | ms/batch 41.43 | loss  3.04 | ppl    20.84 | bpc    4.381\n",
      "| epoch   4 |   500/  559 batches | lr 0.0001 | ms/batch 41.58 | loss  3.04 | ppl    20.81 | bpc    4.380\n",
      "| epoch   4 |   550/  559 batches | lr 0.0001 | ms/batch 41.48 | loss  3.03 | ppl    20.75 | bpc    4.375\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 31.61s | valid loss  3.03 | valid ppl    20.62 | bpc    4.366\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.055452 --> 3.026276).  Saving model ...\n",
      "| epoch   5 |    50/  559 batches | lr 0.0001 | ms/batch 40.29 | loss  3.09 | ppl    22.08 | bpc    4.465\n",
      "| epoch   5 |   100/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.03 | ppl    20.70 | bpc    4.371\n",
      "| epoch   5 |   150/  559 batches | lr 0.0001 | ms/batch 41.88 | loss  3.03 | ppl    20.70 | bpc    4.372\n",
      "| epoch   5 |   200/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.03 | ppl    20.76 | bpc    4.375\n",
      "| epoch   5 |   250/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.03 | ppl    20.64 | bpc    4.367\n",
      "| epoch   5 |   300/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  3.03 | ppl    20.65 | bpc    4.368\n",
      "| epoch   5 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  3.03 | ppl    20.63 | bpc    4.367\n",
      "| epoch   5 |   400/  559 batches | lr 0.0001 | ms/batch 41.57 | loss  3.03 | ppl    20.63 | bpc    4.367\n",
      "| epoch   5 |   450/  559 batches | lr 0.0001 | ms/batch 39.85 | loss  3.02 | ppl    20.58 | bpc    4.363\n",
      "| epoch   5 |   500/  559 batches | lr 0.0001 | ms/batch 41.19 | loss  3.02 | ppl    20.58 | bpc    4.363\n",
      "| epoch   5 |   550/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.02 | ppl    20.54 | bpc    4.360\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 31.81s | valid loss  3.02 | valid ppl    20.40 | bpc    4.350\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.026276 --> 3.015363).  Saving model ...\n",
      "| epoch   6 |    50/  559 batches | lr 0.0001 | ms/batch 39.73 | loss  3.09 | ppl    21.87 | bpc    4.451\n",
      "| epoch   6 |   100/  559 batches | lr 0.0001 | ms/batch 39.95 | loss  3.02 | ppl    20.53 | bpc    4.360\n",
      "| epoch   6 |   150/  559 batches | lr 0.0001 | ms/batch 40.97 | loss  3.02 | ppl    20.53 | bpc    4.360\n",
      "| epoch   6 |   200/  559 batches | lr 0.0001 | ms/batch 40.85 | loss  3.03 | ppl    20.61 | bpc    4.365\n",
      "| epoch   6 |   250/  559 batches | lr 0.0001 | ms/batch 41.63 | loss  3.02 | ppl    20.51 | bpc    4.358\n",
      "| epoch   6 |   300/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.02 | ppl    20.51 | bpc    4.359\n",
      "| epoch   6 |   350/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.02 | ppl    20.51 | bpc    4.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   400/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  3.02 | ppl    20.52 | bpc    4.359\n",
      "| epoch   6 |   450/  559 batches | lr 0.0001 | ms/batch 42.03 | loss  3.02 | ppl    20.49 | bpc    4.357\n",
      "| epoch   6 |   500/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.02 | ppl    20.49 | bpc    4.357\n",
      "| epoch   6 |   550/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.02 | ppl    20.44 | bpc    4.354\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 31.73s | valid loss  3.01 | valid ppl    20.30 | bpc    4.344\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.015363 --> 3.010698).  Saving model ...\n",
      "| epoch   7 |    50/  559 batches | lr 0.0001 | ms/batch 39.51 | loss  3.08 | ppl    21.78 | bpc    4.445\n",
      "| epoch   7 |   100/  559 batches | lr 0.0001 | ms/batch 40.47 | loss  3.02 | ppl    20.45 | bpc    4.354\n",
      "| epoch   7 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  3.02 | ppl    20.47 | bpc    4.355\n",
      "| epoch   7 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  3.02 | ppl    20.53 | bpc    4.360\n",
      "| epoch   7 |   250/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.02 | ppl    20.43 | bpc    4.353\n",
      "| epoch   7 |   300/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.02 | ppl    20.45 | bpc    4.354\n",
      "| epoch   7 |   350/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.02 | ppl    20.45 | bpc    4.354\n",
      "| epoch   7 |   400/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.02 | ppl    20.45 | bpc    4.354\n",
      "| epoch   7 |   450/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.02 | ppl    20.43 | bpc    4.353\n",
      "| epoch   7 |   500/  559 batches | lr 0.0001 | ms/batch 41.91 | loss  3.02 | ppl    20.43 | bpc    4.353\n",
      "| epoch   7 |   550/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.02 | ppl    20.40 | bpc    4.350\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 31.87s | valid loss  3.01 | valid ppl    20.25 | bpc    4.340\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.010698 --> 3.008168).  Saving model ...\n",
      "| epoch   8 |    50/  559 batches | lr 0.0001 | ms/batch 40.03 | loss  3.08 | ppl    21.72 | bpc    4.441\n",
      "| epoch   8 |   100/  559 batches | lr 0.0001 | ms/batch 40.23 | loss  3.02 | ppl    20.40 | bpc    4.351\n",
      "| epoch   8 |   150/  559 batches | lr 0.0001 | ms/batch 40.57 | loss  3.02 | ppl    20.42 | bpc    4.352\n",
      "| epoch   8 |   200/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  3.02 | ppl    20.48 | bpc    4.356\n",
      "| epoch   8 |   250/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.02 | ppl    20.39 | bpc    4.350\n",
      "| epoch   8 |   300/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.02 | ppl    20.41 | bpc    4.351\n",
      "| epoch   8 |   350/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.02 | ppl    20.41 | bpc    4.351\n",
      "| epoch   8 |   400/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.02 | ppl    20.42 | bpc    4.352\n",
      "| epoch   8 |   450/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.02 | ppl    20.39 | bpc    4.350\n",
      "| epoch   8 |   500/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.02 | ppl    20.40 | bpc    4.350\n",
      "| epoch   8 |   550/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.01 | ppl    20.37 | bpc    4.348\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 31.83s | valid loss  3.01 | valid ppl    20.22 | bpc    4.337\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.008168 --> 3.006441).  Saving model ...\n",
      "| epoch   9 |    50/  559 batches | lr 0.0001 | ms/batch 42.67 | loss  3.08 | ppl    21.69 | bpc    4.439\n",
      "| epoch   9 |   100/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.01 | ppl    20.37 | bpc    4.348\n",
      "| epoch   9 |   150/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.01 | ppl    20.39 | bpc    4.349\n",
      "| epoch   9 |   200/  559 batches | lr 0.0001 | ms/batch 42.03 | loss  3.02 | ppl    20.45 | bpc    4.354\n",
      "| epoch   9 |   250/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.36 | bpc    4.348\n",
      "| epoch   9 |   300/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.38 | bpc    4.349\n",
      "| epoch   9 |   350/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.37 | bpc    4.348\n",
      "| epoch   9 |   400/  559 batches | lr 0.0001 | ms/batch 42.06 | loss  3.01 | ppl    20.38 | bpc    4.349\n",
      "| epoch   9 |   450/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.01 | ppl    20.36 | bpc    4.348\n",
      "| epoch   9 |   500/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.36 | bpc    4.348\n",
      "| epoch   9 |   550/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  3.01 | ppl    20.32 | bpc    4.345\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 32.14s | valid loss  3.01 | valid ppl    20.19 | bpc    4.335\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.006441 --> 3.005063).  Saving model ...\n",
      "| epoch  10 |    50/  559 batches | lr 0.0001 | ms/batch 40.53 | loss  3.08 | ppl    21.65 | bpc    4.436\n",
      "| epoch  10 |   100/  559 batches | lr 0.0001 | ms/batch 40.43 | loss  3.01 | ppl    20.34 | bpc    4.346\n",
      "| epoch  10 |   150/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.01 | ppl    20.34 | bpc    4.347\n",
      "| epoch  10 |   200/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.02 | ppl    20.42 | bpc    4.352\n",
      "| epoch  10 |   250/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.33 | bpc    4.346\n",
      "| epoch  10 |   300/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.34 | bpc    4.346\n",
      "| epoch  10 |   350/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.34 | bpc    4.347\n",
      "| epoch  10 |   400/  559 batches | lr 0.0001 | ms/batch 42.06 | loss  3.01 | ppl    20.35 | bpc    4.347\n",
      "| epoch  10 |   450/  559 batches | lr 0.0001 | ms/batch 41.91 | loss  3.01 | ppl    20.33 | bpc    4.346\n",
      "| epoch  10 |   500/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.01 | ppl    20.33 | bpc    4.346\n",
      "| epoch  10 |   550/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.30 | bpc    4.343\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 31.94s | valid loss  3.00 | valid ppl    20.16 | bpc    4.334\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.005063 --> 3.003839).  Saving model ...\n",
      "| epoch  11 |    50/  559 batches | lr 0.0001 | ms/batch 39.87 | loss  3.07 | ppl    21.62 | bpc    4.435\n",
      "| epoch  11 |   100/  559 batches | lr 0.0001 | ms/batch 41.01 | loss  3.01 | ppl    20.31 | bpc    4.344\n",
      "| epoch  11 |   150/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.01 | ppl    20.33 | bpc    4.345\n",
      "| epoch  11 |   200/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.02 | ppl    20.39 | bpc    4.350\n",
      "| epoch  11 |   250/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.30 | bpc    4.344\n",
      "| epoch  11 |   300/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.01 | ppl    20.31 | bpc    4.344\n",
      "| epoch  11 |   350/  559 batches | lr 0.0001 | ms/batch 42.02 | loss  3.01 | ppl    20.32 | bpc    4.345\n",
      "| epoch  11 |   400/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.33 | bpc    4.345\n",
      "| epoch  11 |   450/  559 batches | lr 0.0001 | ms/batch 42.02 | loss  3.01 | ppl    20.30 | bpc    4.344\n",
      "| epoch  11 |   500/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.01 | ppl    20.31 | bpc    4.344\n",
      "| epoch  11 |   550/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  3.01 | ppl    20.26 | bpc    4.341\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 31.95s | valid loss  3.00 | valid ppl    20.14 | bpc    4.332\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.003839 --> 3.002685).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |    50/  559 batches | lr 0.0001 | ms/batch 41.05 | loss  3.07 | ppl    21.59 | bpc    4.432\n",
      "| epoch  12 |   100/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.27 | bpc    4.341\n",
      "| epoch  12 |   150/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.30 | bpc    4.343\n",
      "| epoch  12 |   200/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.01 | ppl    20.37 | bpc    4.349\n",
      "| epoch  12 |   250/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.28 | bpc    4.342\n",
      "| epoch  12 |   300/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.29 | bpc    4.343\n",
      "| epoch  12 |   350/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.29 | bpc    4.343\n",
      "| epoch  12 |   400/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.29 | bpc    4.343\n",
      "| epoch  12 |   450/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.01 | ppl    20.28 | bpc    4.342\n",
      "| epoch  12 |   500/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.01 | ppl    20.28 | bpc    4.342\n",
      "| epoch  12 |   550/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.24 | bpc    4.339\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 32.04s | valid loss  3.00 | valid ppl    20.12 | bpc    4.330\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.002685 --> 3.001534).  Saving model ...\n",
      "| epoch  13 |    50/  559 batches | lr 0.0001 | ms/batch 40.02 | loss  3.07 | ppl    21.56 | bpc    4.430\n",
      "| epoch  13 |   100/  559 batches | lr 0.0001 | ms/batch 41.49 | loss  3.01 | ppl    20.25 | bpc    4.340\n",
      "| epoch  13 |   150/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.01 | ppl    20.26 | bpc    4.341\n",
      "| epoch  13 |   200/  559 batches | lr 0.0001 | ms/batch 42.04 | loss  3.01 | ppl    20.33 | bpc    4.346\n",
      "| epoch  13 |   250/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.24 | bpc    4.339\n",
      "| epoch  13 |   300/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.26 | bpc    4.340\n",
      "| epoch  13 |   350/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.01 | ppl    20.26 | bpc    4.340\n",
      "| epoch  13 |   400/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.01 | ppl    20.27 | bpc    4.341\n",
      "| epoch  13 |   450/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  3.01 | ppl    20.25 | bpc    4.340\n",
      "| epoch  13 |   500/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.01 | ppl    20.26 | bpc    4.340\n",
      "| epoch  13 |   550/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  3.01 | ppl    20.21 | bpc    4.337\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 31.98s | valid loss  3.00 | valid ppl    20.09 | bpc    4.329\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.001534 --> 3.000330).  Saving model ...\n",
      "| epoch  14 |    50/  559 batches | lr 0.0001 | ms/batch 42.82 | loss  3.07 | ppl    21.53 | bpc    4.428\n",
      "| epoch  14 |   100/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.01 | ppl    20.22 | bpc    4.337\n",
      "| epoch  14 |   150/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.01 | ppl    20.24 | bpc    4.339\n",
      "| epoch  14 |   200/  559 batches | lr 0.0001 | ms/batch 42.03 | loss  3.01 | ppl    20.31 | bpc    4.344\n",
      "| epoch  14 |   250/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.01 | ppl    20.22 | bpc    4.338\n",
      "| epoch  14 |   300/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.01 | ppl    20.23 | bpc    4.338\n",
      "| epoch  14 |   350/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.23 | bpc    4.338\n",
      "| epoch  14 |   400/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.01 | ppl    20.24 | bpc    4.339\n",
      "| epoch  14 |   450/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.01 | ppl    20.22 | bpc    4.338\n",
      "| epoch  14 |   500/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.01 | ppl    20.22 | bpc    4.338\n",
      "| epoch  14 |   550/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.00 | ppl    20.18 | bpc    4.335\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 32.13s | valid loss  3.00 | valid ppl    20.07 | bpc    4.327\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (3.000330 --> 2.999039).  Saving model ...\n",
      "| epoch  15 |    50/  559 batches | lr 0.0001 | ms/batch 40.40 | loss  3.07 | ppl    21.50 | bpc    4.426\n",
      "| epoch  15 |   100/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  3.01 | ppl    20.19 | bpc    4.335\n",
      "| epoch  15 |   150/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  3.01 | ppl    20.20 | bpc    4.337\n",
      "| epoch  15 |   200/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  3.01 | ppl    20.27 | bpc    4.342\n",
      "| epoch  15 |   250/  559 batches | lr 0.0001 | ms/batch 41.88 | loss  3.00 | ppl    20.18 | bpc    4.335\n",
      "| epoch  15 |   300/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  3.01 | ppl    20.21 | bpc    4.337\n",
      "| epoch  15 |   350/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  3.01 | ppl    20.20 | bpc    4.336\n",
      "| epoch  15 |   400/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.01 | ppl    20.21 | bpc    4.337\n",
      "| epoch  15 |   450/  559 batches | lr 0.0001 | ms/batch 42.04 | loss  3.00 | ppl    20.18 | bpc    4.335\n",
      "| epoch  15 |   500/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.00 | ppl    20.18 | bpc    4.335\n",
      "| epoch  15 |   550/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.00 | ppl    20.15 | bpc    4.333\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 31.98s | valid loss  3.00 | valid ppl    20.04 | bpc    4.325\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.999039 --> 2.997607).  Saving model ...\n",
      "| epoch  16 |    50/  559 batches | lr 0.0001 | ms/batch 40.55 | loss  3.07 | ppl    21.45 | bpc    4.423\n",
      "| epoch  16 |   100/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.00 | ppl    20.16 | bpc    4.333\n",
      "| epoch  16 |   150/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.00 | ppl    20.17 | bpc    4.334\n",
      "| epoch  16 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  3.01 | ppl    20.24 | bpc    4.339\n",
      "| epoch  16 |   250/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  3.00 | ppl    20.15 | bpc    4.333\n",
      "| epoch  16 |   300/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.00 | ppl    20.17 | bpc    4.334\n",
      "| epoch  16 |   350/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.00 | ppl    20.16 | bpc    4.334\n",
      "| epoch  16 |   400/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  3.00 | ppl    20.17 | bpc    4.334\n",
      "| epoch  16 |   450/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.00 | ppl    20.15 | bpc    4.332\n",
      "| epoch  16 |   500/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  3.00 | ppl    20.14 | bpc    4.332\n",
      "| epoch  16 |   550/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.00 | ppl    20.11 | bpc    4.330\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 31.99s | valid loss  3.00 | valid ppl    20.01 | bpc    4.322\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.997607 --> 2.995986).  Saving model ...\n",
      "| epoch  17 |    50/  559 batches | lr 0.0001 | ms/batch 40.81 | loss  3.06 | ppl    21.42 | bpc    4.421\n",
      "| epoch  17 |   100/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.00 | ppl    20.12 | bpc    4.331\n",
      "| epoch  17 |   150/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.00 | ppl    20.13 | bpc    4.332\n",
      "| epoch  17 |   200/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.01 | ppl    20.20 | bpc    4.336\n",
      "| epoch  17 |   250/  559 batches | lr 0.0001 | ms/batch 41.70 | loss  3.00 | ppl    20.12 | bpc    4.330\n",
      "| epoch  17 |   300/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.00 | ppl    20.12 | bpc    4.331\n",
      "| epoch  17 |   350/  559 batches | lr 0.0001 | ms/batch 41.91 | loss  3.00 | ppl    20.13 | bpc    4.331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  17 |   400/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  3.00 | ppl    20.13 | bpc    4.331\n",
      "| epoch  17 |   450/  559 batches | lr 0.0001 | ms/batch 41.91 | loss  3.00 | ppl    20.11 | bpc    4.330\n",
      "| epoch  17 |   500/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.00 | ppl    20.11 | bpc    4.330\n",
      "| epoch  17 |   550/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.00 | ppl    20.07 | bpc    4.327\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 32.01s | valid loss  2.99 | valid ppl    19.97 | bpc    4.320\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.995986 --> 2.994123).  Saving model ...\n",
      "| epoch  18 |    50/  559 batches | lr 0.0001 | ms/batch 40.19 | loss  3.06 | ppl    21.37 | bpc    4.418\n",
      "| epoch  18 |   100/  559 batches | lr 0.0001 | ms/batch 40.77 | loss  3.00 | ppl    20.08 | bpc    4.328\n",
      "| epoch  18 |   150/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.00 | ppl    20.09 | bpc    4.329\n",
      "| epoch  18 |   200/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.00 | ppl    20.16 | bpc    4.334\n",
      "| epoch  18 |   250/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  3.00 | ppl    20.07 | bpc    4.327\n",
      "| epoch  18 |   300/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.00 | ppl    20.09 | bpc    4.328\n",
      "| epoch  18 |   350/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.00 | ppl    20.08 | bpc    4.328\n",
      "| epoch  18 |   400/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.00 | ppl    20.09 | bpc    4.329\n",
      "| epoch  18 |   450/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  3.00 | ppl    20.06 | bpc    4.326\n",
      "| epoch  18 |   500/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  3.00 | ppl    20.06 | bpc    4.326\n",
      "| epoch  18 |   550/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.00 | ppl    20.02 | bpc    4.324\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 31.94s | valid loss  2.99 | valid ppl    19.92 | bpc    4.316\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.994123 --> 2.991934).  Saving model ...\n",
      "| epoch  19 |    50/  559 batches | lr 0.0001 | ms/batch 40.57 | loss  3.06 | ppl    21.32 | bpc    4.414\n",
      "| epoch  19 |   100/  559 batches | lr 0.0001 | ms/batch 41.12 | loss  3.00 | ppl    20.03 | bpc    4.324\n",
      "| epoch  19 |   150/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.00 | ppl    20.04 | bpc    4.325\n",
      "| epoch  19 |   200/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  3.00 | ppl    20.12 | bpc    4.330\n",
      "| epoch  19 |   250/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.00 | ppl    20.02 | bpc    4.323\n",
      "| epoch  19 |   300/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.00 | ppl    20.02 | bpc    4.324\n",
      "| epoch  19 |   350/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  3.00 | ppl    20.02 | bpc    4.324\n",
      "| epoch  19 |   400/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  3.00 | ppl    20.03 | bpc    4.324\n",
      "| epoch  19 |   450/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  3.00 | ppl    20.01 | bpc    4.323\n",
      "| epoch  19 |   500/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  3.00 | ppl    20.01 | bpc    4.323\n",
      "| epoch  19 |   550/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  2.99 | ppl    19.97 | bpc    4.320\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 31.96s | valid loss  2.99 | valid ppl    19.87 | bpc    4.313\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.991934 --> 2.989327).  Saving model ...\n",
      "| epoch  20 |    50/  559 batches | lr 0.0001 | ms/batch 39.85 | loss  3.06 | ppl    21.26 | bpc    4.410\n",
      "| epoch  20 |   100/  559 batches | lr 0.0001 | ms/batch 40.72 | loss  2.99 | ppl    19.98 | bpc    4.320\n",
      "| epoch  20 |   150/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  3.00 | ppl    19.99 | bpc    4.321\n",
      "| epoch  20 |   200/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  3.00 | ppl    20.05 | bpc    4.326\n",
      "| epoch  20 |   250/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  2.99 | ppl    19.97 | bpc    4.320\n",
      "| epoch  20 |   300/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  2.99 | ppl    19.97 | bpc    4.320\n",
      "| epoch  20 |   350/  559 batches | lr 0.0001 | ms/batch 41.99 | loss  2.99 | ppl    19.97 | bpc    4.320\n",
      "| epoch  20 |   400/  559 batches | lr 0.0001 | ms/batch 41.92 | loss  2.99 | ppl    19.97 | bpc    4.320\n",
      "| epoch  20 |   450/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  2.99 | ppl    19.95 | bpc    4.318\n",
      "| epoch  20 |   500/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  2.99 | ppl    19.95 | bpc    4.318\n",
      "| epoch  20 |   550/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  2.99 | ppl    19.91 | bpc    4.315\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 31.91s | valid loss  2.99 | valid ppl    19.81 | bpc    4.308\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.989327 --> 2.986188).  Saving model ...\n",
      "| epoch  21 |    50/  559 batches | lr 0.0001 | ms/batch 40.23 | loss  3.05 | ppl    21.19 | bpc    4.406\n",
      "| epoch  21 |   100/  559 batches | lr 0.0001 | ms/batch 40.35 | loss  2.99 | ppl    19.91 | bpc    4.315\n",
      "| epoch  21 |   150/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  2.99 | ppl    19.92 | bpc    4.316\n",
      "| epoch  21 |   200/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  2.99 | ppl    19.98 | bpc    4.321\n",
      "| epoch  21 |   250/  559 batches | lr 0.0001 | ms/batch 41.93 | loss  2.99 | ppl    19.90 | bpc    4.315\n",
      "| epoch  21 |   300/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  2.99 | ppl    19.90 | bpc    4.314\n",
      "| epoch  21 |   350/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  2.99 | ppl    19.89 | bpc    4.314\n",
      "| epoch  21 |   400/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  2.99 | ppl    19.90 | bpc    4.314\n",
      "| epoch  21 |   450/  559 batches | lr 0.0001 | ms/batch 41.88 | loss  2.99 | ppl    19.88 | bpc    4.313\n",
      "| epoch  21 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.99 | ppl    19.87 | bpc    4.312\n",
      "| epoch  21 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.99 | ppl    19.83 | bpc    4.309\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 31.85s | valid loss  2.98 | valid ppl    19.73 | bpc    4.303\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.986188 --> 2.982354).  Saving model ...\n",
      "| epoch  22 |    50/  559 batches | lr 0.0001 | ms/batch 39.53 | loss  3.05 | ppl    21.11 | bpc    4.400\n",
      "| epoch  22 |   100/  559 batches | lr 0.0001 | ms/batch 41.66 | loss  2.99 | ppl    19.83 | bpc    4.310\n",
      "| epoch  22 |   150/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  2.99 | ppl    19.84 | bpc    4.310\n",
      "| epoch  22 |   200/  559 batches | lr 0.0001 | ms/batch 41.95 | loss  2.99 | ppl    19.91 | bpc    4.315\n",
      "| epoch  22 |   250/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  2.99 | ppl    19.81 | bpc    4.308\n",
      "| epoch  22 |   300/  559 batches | lr 0.0001 | ms/batch 41.97 | loss  2.99 | ppl    19.81 | bpc    4.308\n",
      "| epoch  22 |   350/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  2.99 | ppl    19.81 | bpc    4.308\n",
      "| epoch  22 |   400/  559 batches | lr 0.0001 | ms/batch 41.98 | loss  2.99 | ppl    19.81 | bpc    4.308\n",
      "| epoch  22 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.98 | ppl    19.79 | bpc    4.306\n",
      "| epoch  22 |   500/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.98 | ppl    19.78 | bpc    4.306\n",
      "| epoch  22 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.98 | ppl    19.74 | bpc    4.303\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 31.89s | valid loss  2.98 | valid ppl    19.64 | bpc    4.296\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.982354 --> 2.977661).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  23 |    50/  559 batches | lr 0.0001 | ms/batch 40.01 | loss  3.04 | ppl    21.00 | bpc    4.392\n",
      "| epoch  23 |   100/  559 batches | lr 0.0001 | ms/batch 41.13 | loss  2.98 | ppl    19.73 | bpc    4.303\n",
      "| epoch  23 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.98 | ppl    19.74 | bpc    4.303\n",
      "| epoch  23 |   200/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.99 | ppl    19.81 | bpc    4.308\n",
      "| epoch  23 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.98 | ppl    19.71 | bpc    4.301\n",
      "| epoch  23 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.98 | ppl    19.71 | bpc    4.301\n",
      "| epoch  23 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.98 | ppl    19.70 | bpc    4.300\n",
      "| epoch  23 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.98 | ppl    19.71 | bpc    4.301\n",
      "| epoch  23 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.98 | ppl    19.68 | bpc    4.299\n",
      "| epoch  23 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.98 | ppl    19.68 | bpc    4.298\n",
      "| epoch  23 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.98 | ppl    19.63 | bpc    4.295\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 31.84s | valid loss  2.97 | valid ppl    19.53 | bpc    4.288\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.977661 --> 2.971902).  Saving model ...\n",
      "| epoch  24 |    50/  559 batches | lr 0.0001 | ms/batch 40.79 | loss  3.04 | ppl    20.89 | bpc    4.385\n",
      "| epoch  24 |   100/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.98 | ppl    19.62 | bpc    4.294\n",
      "| epoch  24 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.98 | ppl    19.63 | bpc    4.295\n",
      "| epoch  24 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.98 | ppl    19.69 | bpc    4.299\n",
      "| epoch  24 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.98 | ppl    19.59 | bpc    4.292\n",
      "| epoch  24 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.97 | ppl    19.59 | bpc    4.292\n",
      "| epoch  24 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.97 | ppl    19.57 | bpc    4.291\n",
      "| epoch  24 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.97 | ppl    19.58 | bpc    4.291\n",
      "| epoch  24 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.97 | ppl    19.54 | bpc    4.289\n",
      "| epoch  24 |   500/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.97 | ppl    19.54 | bpc    4.288\n",
      "| epoch  24 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.97 | ppl    19.49 | bpc    4.285\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 31.90s | valid loss  2.96 | valid ppl    19.39 | bpc    4.277\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.971902 --> 2.964878).  Saving model ...\n",
      "| epoch  25 |    50/  559 batches | lr 0.0001 | ms/batch 40.60 | loss  3.03 | ppl    20.74 | bpc    4.374\n",
      "| epoch  25 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.97 | ppl    19.48 | bpc    4.284\n",
      "| epoch  25 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.97 | ppl    19.49 | bpc    4.284\n",
      "| epoch  25 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.97 | ppl    19.54 | bpc    4.289\n",
      "| epoch  25 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.97 | ppl    19.45 | bpc    4.281\n",
      "| epoch  25 |   300/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.97 | ppl    19.43 | bpc    4.280\n",
      "| epoch  25 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.97 | ppl    19.43 | bpc    4.280\n",
      "| epoch  25 |   400/  559 batches | lr 0.0001 | ms/batch 41.71 | loss  2.97 | ppl    19.42 | bpc    4.280\n",
      "| epoch  25 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.96 | ppl    19.39 | bpc    4.277\n",
      "| epoch  25 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.96 | ppl    19.38 | bpc    4.277\n",
      "| epoch  25 |   550/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.96 | ppl    19.33 | bpc    4.273\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 31.89s | valid loss  2.96 | valid ppl    19.23 | bpc    4.265\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.964878 --> 2.956457).  Saving model ...\n",
      "| epoch  26 |    50/  559 batches | lr 0.0001 | ms/batch 40.26 | loss  3.02 | ppl    20.55 | bpc    4.361\n",
      "| epoch  26 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.96 | ppl    19.31 | bpc    4.271\n",
      "| epoch  26 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.96 | ppl    19.32 | bpc    4.272\n",
      "| epoch  26 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.96 | ppl    19.37 | bpc    4.276\n",
      "| epoch  26 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.96 | ppl    19.27 | bpc    4.269\n",
      "| epoch  26 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.96 | ppl    19.26 | bpc    4.267\n",
      "| epoch  26 |   350/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.96 | ppl    19.24 | bpc    4.266\n",
      "| epoch  26 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.96 | ppl    19.24 | bpc    4.266\n",
      "| epoch  26 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.96 | ppl    19.21 | bpc    4.264\n",
      "| epoch  26 |   500/  559 batches | lr 0.0001 | ms/batch 41.59 | loss  2.95 | ppl    19.20 | bpc    4.263\n",
      "| epoch  26 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.95 | ppl    19.15 | bpc    4.259\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 31.85s | valid loss  2.95 | valid ppl    19.04 | bpc    4.251\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.956457 --> 2.946620).  Saving model ...\n",
      "| epoch  27 |    50/  559 batches | lr 0.0001 | ms/batch 40.03 | loss  3.01 | ppl    20.35 | bpc    4.347\n",
      "| epoch  27 |   100/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  2.95 | ppl    19.13 | bpc    4.257\n",
      "| epoch  27 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.95 | ppl    19.13 | bpc    4.258\n",
      "| epoch  27 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.95 | ppl    19.18 | bpc    4.262\n",
      "| epoch  27 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.95 | ppl    19.08 | bpc    4.254\n",
      "| epoch  27 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.95 | ppl    19.06 | bpc    4.252\n",
      "| epoch  27 |   350/  559 batches | lr 0.0001 | ms/batch 41.62 | loss  2.95 | ppl    19.05 | bpc    4.252\n",
      "| epoch  27 |   400/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.95 | ppl    19.05 | bpc    4.252\n",
      "| epoch  27 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.94 | ppl    19.01 | bpc    4.248\n",
      "| epoch  27 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.94 | ppl    18.99 | bpc    4.247\n",
      "| epoch  27 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.94 | ppl    18.94 | bpc    4.243\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 31.86s | valid loss  2.94 | valid ppl    18.83 | bpc    4.235\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.946620 --> 2.935608).  Saving model ...\n",
      "| epoch  28 |    50/  559 batches | lr 0.0001 | ms/batch 40.97 | loss  3.00 | ppl    20.14 | bpc    4.332\n",
      "| epoch  28 |   100/  559 batches | lr 0.0001 | ms/batch 41.71 | loss  2.94 | ppl    18.91 | bpc    4.241\n",
      "| epoch  28 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.94 | ppl    18.92 | bpc    4.242\n",
      "| epoch  28 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.94 | ppl    18.97 | bpc    4.246\n",
      "| epoch  28 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.94 | ppl    18.87 | bpc    4.238\n",
      "| epoch  28 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.94 | ppl    18.84 | bpc    4.236\n",
      "| epoch  28 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.94 | ppl    18.83 | bpc    4.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  28 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.94 | ppl    18.83 | bpc    4.235\n",
      "| epoch  28 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.93 | ppl    18.79 | bpc    4.232\n",
      "| epoch  28 |   500/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.93 | ppl    18.79 | bpc    4.232\n",
      "| epoch  28 |   550/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.93 | ppl    18.73 | bpc    4.227\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 31.90s | valid loss  2.92 | valid ppl    18.61 | bpc    4.218\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.935608 --> 2.923865).  Saving model ...\n",
      "| epoch  29 |    50/  559 batches | lr 0.0001 | ms/batch 41.18 | loss  2.99 | ppl    19.90 | bpc    4.315\n",
      "| epoch  29 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.93 | ppl    18.70 | bpc    4.225\n",
      "| epoch  29 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.93 | ppl    18.71 | bpc    4.226\n",
      "| epoch  29 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.93 | ppl    18.76 | bpc    4.230\n",
      "| epoch  29 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.93 | ppl    18.65 | bpc    4.221\n",
      "| epoch  29 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.92 | ppl    18.62 | bpc    4.219\n",
      "| epoch  29 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.92 | ppl    18.61 | bpc    4.218\n",
      "| epoch  29 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.92 | ppl    18.62 | bpc    4.219\n",
      "| epoch  29 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.92 | ppl    18.57 | bpc    4.215\n",
      "| epoch  29 |   500/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.92 | ppl    18.57 | bpc    4.215\n",
      "| epoch  29 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.92 | ppl    18.51 | bpc    4.210\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 31.93s | valid loss  2.91 | valid ppl    18.39 | bpc    4.201\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.923865 --> 2.911978).  Saving model ...\n",
      "| epoch  30 |    50/  559 batches | lr 0.0001 | ms/batch 40.67 | loss  2.98 | ppl    19.67 | bpc    4.298\n",
      "| epoch  30 |   100/  559 batches | lr 0.0001 | ms/batch 41.57 | loss  2.92 | ppl    18.49 | bpc    4.208\n",
      "| epoch  30 |   150/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.92 | ppl    18.49 | bpc    4.209\n",
      "| epoch  30 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.92 | ppl    18.54 | bpc    4.213\n",
      "| epoch  30 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.91 | ppl    18.45 | bpc    4.205\n",
      "| epoch  30 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.91 | ppl    18.41 | bpc    4.202\n",
      "| epoch  30 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.91 | ppl    18.40 | bpc    4.202\n",
      "| epoch  30 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.91 | ppl    18.40 | bpc    4.202\n",
      "| epoch  30 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.91 | ppl    18.36 | bpc    4.199\n",
      "| epoch  30 |   500/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.91 | ppl    18.37 | bpc    4.199\n",
      "| epoch  30 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.91 | ppl    18.30 | bpc    4.193\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 31.88s | valid loss  2.90 | valid ppl    18.18 | bpc    4.184\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.911978 --> 2.900378).  Saving model ...\n",
      "| epoch  31 |    50/  559 batches | lr 0.0001 | ms/batch 40.66 | loss  2.97 | ppl    19.44 | bpc    4.281\n",
      "| epoch  31 |   100/  559 batches | lr 0.0001 | ms/batch 40.87 | loss  2.91 | ppl    18.28 | bpc    4.192\n",
      "| epoch  31 |   150/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  2.91 | ppl    18.29 | bpc    4.193\n",
      "| epoch  31 |   200/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.91 | ppl    18.34 | bpc    4.197\n",
      "| epoch  31 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.90 | ppl    18.25 | bpc    4.190\n",
      "| epoch  31 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.90 | ppl    18.20 | bpc    4.186\n",
      "| epoch  31 |   350/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.90 | ppl    18.20 | bpc    4.185\n",
      "| epoch  31 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.90 | ppl    18.20 | bpc    4.186\n",
      "| epoch  31 |   450/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.90 | ppl    18.16 | bpc    4.182\n",
      "| epoch  31 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.90 | ppl    18.16 | bpc    4.183\n",
      "| epoch  31 |   550/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.90 | ppl    18.10 | bpc    4.178\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 31.83s | valid loss  2.89 | valid ppl    17.98 | bpc    4.168\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.900378 --> 2.889204).  Saving model ...\n",
      "| epoch  32 |    50/  559 batches | lr 0.0001 | ms/batch 41.48 | loss  2.96 | ppl    19.23 | bpc    4.265\n",
      "| epoch  32 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.90 | ppl    18.09 | bpc    4.177\n",
      "| epoch  32 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.90 | ppl    18.09 | bpc    4.177\n",
      "| epoch  32 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.90 | ppl    18.15 | bpc    4.182\n",
      "| epoch  32 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.89 | ppl    18.05 | bpc    4.174\n",
      "| epoch  32 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.89 | ppl    18.00 | bpc    4.170\n",
      "| epoch  32 |   350/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.89 | ppl    17.99 | bpc    4.169\n",
      "| epoch  32 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.89 | ppl    18.02 | bpc    4.171\n",
      "| epoch  32 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.89 | ppl    17.97 | bpc    4.167\n",
      "| epoch  32 |   500/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.89 | ppl    17.97 | bpc    4.168\n",
      "| epoch  32 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.89 | ppl    17.91 | bpc    4.162\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 31.93s | valid loss  2.88 | valid ppl    17.79 | bpc    4.153\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.889204 --> 2.878363).  Saving model ...\n",
      "| epoch  33 |    50/  559 batches | lr 0.0001 | ms/batch 39.87 | loss  2.95 | ppl    19.03 | bpc    4.250\n",
      "| epoch  33 |   100/  559 batches | lr 0.0001 | ms/batch 41.26 | loss  2.88 | ppl    17.90 | bpc    4.162\n",
      "| epoch  33 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.88 | ppl    17.90 | bpc    4.162\n",
      "| epoch  33 |   200/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.89 | ppl    17.95 | bpc    4.166\n",
      "| epoch  33 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.88 | ppl    17.87 | bpc    4.159\n",
      "| epoch  33 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.88 | ppl    17.81 | bpc    4.154\n",
      "| epoch  33 |   350/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.88 | ppl    17.81 | bpc    4.155\n",
      "| epoch  33 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.88 | ppl    17.83 | bpc    4.156\n",
      "| epoch  33 |   450/  559 batches | lr 0.0001 | ms/batch 41.64 | loss  2.88 | ppl    17.78 | bpc    4.152\n",
      "| epoch  33 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.88 | ppl    17.78 | bpc    4.153\n",
      "| epoch  33 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.87 | ppl    17.72 | bpc    4.148\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 31.81s | valid loss  2.87 | valid ppl    17.59 | bpc    4.137\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.878363 --> 2.867610).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  34 |    50/  559 batches | lr 0.0001 | ms/batch 42.55 | loss  2.94 | ppl    18.82 | bpc    4.234\n",
      "| epoch  34 |   100/  559 batches | lr 0.0001 | ms/batch 41.69 | loss  2.87 | ppl    17.71 | bpc    4.146\n",
      "| epoch  34 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.87 | ppl    17.72 | bpc    4.147\n",
      "| epoch  34 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.88 | ppl    17.76 | bpc    4.151\n",
      "| epoch  34 |   250/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.87 | ppl    17.68 | bpc    4.144\n",
      "| epoch  34 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.87 | ppl    17.61 | bpc    4.139\n",
      "| epoch  34 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.87 | ppl    17.62 | bpc    4.139\n",
      "| epoch  34 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.87 | ppl    17.64 | bpc    4.141\n",
      "| epoch  34 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.87 | ppl    17.59 | bpc    4.137\n",
      "| epoch  34 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.87 | ppl    17.60 | bpc    4.138\n",
      "| epoch  34 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.86 | ppl    17.53 | bpc    4.132\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 31.97s | valid loss  2.86 | valid ppl    17.40 | bpc    4.121\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.867610 --> 2.856704).  Saving model ...\n",
      "| epoch  35 |    50/  559 batches | lr 0.0001 | ms/batch 40.29 | loss  2.92 | ppl    18.62 | bpc    4.219\n",
      "| epoch  35 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.86 | ppl    17.52 | bpc    4.131\n",
      "| epoch  35 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.86 | ppl    17.53 | bpc    4.132\n",
      "| epoch  35 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.87 | ppl    17.58 | bpc    4.136\n",
      "| epoch  35 |   250/  559 batches | lr 0.0001 | ms/batch 41.68 | loss  2.86 | ppl    17.49 | bpc    4.128\n",
      "| epoch  35 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.86 | ppl    17.43 | bpc    4.123\n",
      "| epoch  35 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.86 | ppl    17.43 | bpc    4.124\n",
      "| epoch  35 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.86 | ppl    17.45 | bpc    4.125\n",
      "| epoch  35 |   450/  559 batches | lr 0.0001 | ms/batch 41.25 | loss  2.86 | ppl    17.41 | bpc    4.122\n",
      "| epoch  35 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.86 | ppl    17.42 | bpc    4.122\n",
      "| epoch  35 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.85 | ppl    17.34 | bpc    4.116\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 31.83s | valid loss  2.85 | valid ppl    17.21 | bpc    4.105\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.856704 --> 2.845457).  Saving model ...\n",
      "| epoch  36 |    50/  559 batches | lr 0.0001 | ms/batch 40.51 | loss  2.91 | ppl    18.41 | bpc    4.202\n",
      "| epoch  36 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.85 | ppl    17.33 | bpc    4.115\n",
      "| epoch  36 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.85 | ppl    17.34 | bpc    4.116\n",
      "| epoch  36 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.86 | ppl    17.38 | bpc    4.119\n",
      "| epoch  36 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.85 | ppl    17.29 | bpc    4.112\n",
      "| epoch  36 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.85 | ppl    17.23 | bpc    4.107\n",
      "| epoch  36 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.85 | ppl    17.23 | bpc    4.107\n",
      "| epoch  36 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.85 | ppl    17.26 | bpc    4.109\n",
      "| epoch  36 |   450/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.85 | ppl    17.21 | bpc    4.105\n",
      "| epoch  36 |   500/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.85 | ppl    17.21 | bpc    4.105\n",
      "| epoch  36 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.84 | ppl    17.15 | bpc    4.100\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 31.90s | valid loss  2.83 | valid ppl    17.01 | bpc    4.088\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.845457 --> 2.833656).  Saving model ...\n",
      "| epoch  37 |    50/  559 batches | lr 0.0001 | ms/batch 40.74 | loss  2.90 | ppl    18.19 | bpc    4.185\n",
      "| epoch  37 |   100/  559 batches | lr 0.0001 | ms/batch 41.54 | loss  2.84 | ppl    17.13 | bpc    4.098\n",
      "| epoch  37 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.84 | ppl    17.14 | bpc    4.099\n",
      "| epoch  37 |   200/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.84 | ppl    17.18 | bpc    4.103\n",
      "| epoch  37 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.84 | ppl    17.09 | bpc    4.095\n",
      "| epoch  37 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.83 | ppl    17.03 | bpc    4.090\n",
      "| epoch  37 |   350/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.83 | ppl    17.03 | bpc    4.090\n",
      "| epoch  37 |   400/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.84 | ppl    17.05 | bpc    4.091\n",
      "| epoch  37 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.83 | ppl    17.00 | bpc    4.088\n",
      "| epoch  37 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.83 | ppl    17.01 | bpc    4.088\n",
      "| epoch  37 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.83 | ppl    16.94 | bpc    4.082\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 31.90s | valid loss  2.82 | valid ppl    16.80 | bpc    4.070\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.833656 --> 2.821108).  Saving model ...\n",
      "| epoch  38 |    50/  559 batches | lr 0.0001 | ms/batch 39.81 | loss  2.89 | ppl    17.97 | bpc    4.167\n",
      "| epoch  38 |   100/  559 batches | lr 0.0001 | ms/batch 41.15 | loss  2.83 | ppl    16.91 | bpc    4.080\n",
      "| epoch  38 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.83 | ppl    16.92 | bpc    4.081\n",
      "| epoch  38 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.83 | ppl    16.96 | bpc    4.084\n",
      "| epoch  38 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.83 | ppl    16.88 | bpc    4.077\n",
      "| epoch  38 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.82 | ppl    16.81 | bpc    4.071\n",
      "| epoch  38 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.82 | ppl    16.81 | bpc    4.071\n",
      "| epoch  38 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.82 | ppl    16.84 | bpc    4.073\n",
      "| epoch  38 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.82 | ppl    16.80 | bpc    4.070\n",
      "| epoch  38 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.82 | ppl    16.79 | bpc    4.069\n",
      "| epoch  38 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.82 | ppl    16.72 | bpc    4.064\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 31.82s | valid loss  2.81 | valid ppl    16.57 | bpc    4.051\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.821108 --> 2.807595).  Saving model ...\n",
      "| epoch  39 |    50/  559 batches | lr 0.0001 | ms/batch 42.50 | loss  2.87 | ppl    17.72 | bpc    4.147\n",
      "| epoch  39 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.82 | ppl    16.70 | bpc    4.062\n",
      "| epoch  39 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.82 | ppl    16.70 | bpc    4.062\n",
      "| epoch  39 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.82 | ppl    16.73 | bpc    4.065\n",
      "| epoch  39 |   250/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.81 | ppl    16.65 | bpc    4.058\n",
      "| epoch  39 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.81 | ppl    16.58 | bpc    4.051\n",
      "| epoch  39 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.81 | ppl    16.58 | bpc    4.051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  39 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.81 | ppl    16.60 | bpc    4.053\n",
      "| epoch  39 |   450/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.81 | ppl    16.55 | bpc    4.049\n",
      "| epoch  39 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.81 | ppl    16.55 | bpc    4.049\n",
      "| epoch  39 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.80 | ppl    16.48 | bpc    4.043\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 32.00s | valid loss  2.79 | valid ppl    16.33 | bpc    4.029\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.807595 --> 2.792894).  Saving model ...\n",
      "| epoch  40 |    50/  559 batches | lr 0.0001 | ms/batch 40.17 | loss  2.86 | ppl    17.46 | bpc    4.126\n",
      "| epoch  40 |   100/  559 batches | lr 0.0001 | ms/batch 41.42 | loss  2.80 | ppl    16.46 | bpc    4.041\n",
      "| epoch  40 |   150/  559 batches | lr 0.0001 | ms/batch 41.69 | loss  2.80 | ppl    16.46 | bpc    4.040\n",
      "| epoch  40 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.80 | ppl    16.49 | bpc    4.044\n",
      "| epoch  40 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.80 | ppl    16.40 | bpc    4.036\n",
      "| epoch  40 |   300/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.79 | ppl    16.34 | bpc    4.030\n",
      "| epoch  40 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.79 | ppl    16.33 | bpc    4.030\n",
      "| epoch  40 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.79 | ppl    16.35 | bpc    4.031\n",
      "| epoch  40 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.79 | ppl    16.31 | bpc    4.028\n",
      "| epoch  40 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.79 | ppl    16.30 | bpc    4.027\n",
      "| epoch  40 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.79 | ppl    16.23 | bpc    4.021\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 31.85s | valid loss  2.78 | valid ppl    16.07 | bpc    4.006\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.792894 --> 2.776750).  Saving model ...\n",
      "| epoch  41 |    50/  559 batches | lr 0.0001 | ms/batch 40.94 | loss  2.84 | ppl    17.19 | bpc    4.103\n",
      "| epoch  41 |   100/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.78 | ppl    16.19 | bpc    4.017\n",
      "| epoch  41 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.78 | ppl    16.20 | bpc    4.018\n",
      "| epoch  41 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.79 | ppl    16.24 | bpc    4.021\n",
      "| epoch  41 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.78 | ppl    16.15 | bpc    4.013\n",
      "| epoch  41 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.78 | ppl    16.07 | bpc    4.006\n",
      "| epoch  41 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.78 | ppl    16.06 | bpc    4.006\n",
      "| epoch  41 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.78 | ppl    16.08 | bpc    4.007\n",
      "| epoch  41 |   450/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.78 | ppl    16.04 | bpc    4.004\n",
      "| epoch  41 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.77 | ppl    16.03 | bpc    4.003\n",
      "| epoch  41 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.77 | ppl    15.96 | bpc    3.997\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 31.91s | valid loss  2.76 | valid ppl    15.78 | bpc    3.980\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.776750 --> 2.758955).  Saving model ...\n",
      "| epoch  42 |    50/  559 batches | lr 0.0001 | ms/batch 39.81 | loss  2.83 | ppl    16.89 | bpc    4.078\n",
      "| epoch  42 |   100/  559 batches | lr 0.0001 | ms/batch 39.72 | loss  2.77 | ppl    15.93 | bpc    3.993\n",
      "| epoch  42 |   150/  559 batches | lr 0.0001 | ms/batch 41.50 | loss  2.77 | ppl    15.92 | bpc    3.993\n",
      "| epoch  42 |   200/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.77 | ppl    15.95 | bpc    3.995\n",
      "| epoch  42 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.76 | ppl    15.87 | bpc    3.988\n",
      "| epoch  42 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.76 | ppl    15.79 | bpc    3.980\n",
      "| epoch  42 |   350/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  2.76 | ppl    15.78 | bpc    3.980\n",
      "| epoch  42 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.76 | ppl    15.80 | bpc    3.981\n",
      "| epoch  42 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.76 | ppl    15.75 | bpc    3.978\n",
      "| epoch  42 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.76 | ppl    15.74 | bpc    3.976\n",
      "| epoch  42 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.75 | ppl    15.67 | bpc    3.970\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 31.73s | valid loss  2.74 | valid ppl    15.48 | bpc    3.952\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.758955 --> 2.739352).  Saving model ...\n",
      "| epoch  43 |    50/  559 batches | lr 0.0001 | ms/batch 40.19 | loss  2.81 | ppl    16.57 | bpc    4.050\n",
      "| epoch  43 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.75 | ppl    15.62 | bpc    3.966\n",
      "| epoch  43 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.75 | ppl    15.62 | bpc    3.965\n",
      "| epoch  43 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.75 | ppl    15.66 | bpc    3.969\n",
      "| epoch  43 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.74 | ppl    15.55 | bpc    3.959\n",
      "| epoch  43 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.74 | ppl    15.48 | bpc    3.952\n",
      "| epoch  43 |   350/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.74 | ppl    15.46 | bpc    3.951\n",
      "| epoch  43 |   400/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.74 | ppl    15.48 | bpc    3.952\n",
      "| epoch  43 |   450/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  2.74 | ppl    15.44 | bpc    3.949\n",
      "| epoch  43 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.74 | ppl    15.42 | bpc    3.947\n",
      "| epoch  43 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.73 | ppl    15.35 | bpc    3.940\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 31.87s | valid loss  2.72 | valid ppl    15.15 | bpc    3.921\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.739352 --> 2.717913).  Saving model ...\n",
      "| epoch  44 |    50/  559 batches | lr 0.0001 | ms/batch 40.44 | loss  2.79 | ppl    16.21 | bpc    4.019\n",
      "| epoch  44 |   100/  559 batches | lr 0.0001 | ms/batch 41.46 | loss  2.73 | ppl    15.31 | bpc    3.936\n",
      "| epoch  44 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.73 | ppl    15.30 | bpc    3.936\n",
      "| epoch  44 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.73 | ppl    15.33 | bpc    3.938\n",
      "| epoch  44 |   250/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.72 | ppl    15.23 | bpc    3.929\n",
      "| epoch  44 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.72 | ppl    15.15 | bpc    3.921\n",
      "| epoch  44 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.72 | ppl    15.13 | bpc    3.919\n",
      "| epoch  44 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.72 | ppl    15.16 | bpc    3.922\n",
      "| epoch  44 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.72 | ppl    15.11 | bpc    3.918\n",
      "| epoch  44 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.71 | ppl    15.09 | bpc    3.916\n",
      "| epoch  44 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    15.02 | bpc    3.909\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 31.87s | valid loss  2.69 | valid ppl    14.80 | bpc    3.888\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.717913 --> 2.694947).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  45 |    50/  559 batches | lr 0.0001 | ms/batch 39.21 | loss  2.76 | ppl    15.86 | bpc    3.988\n",
      "| epoch  45 |   100/  559 batches | lr 0.0001 | ms/batch 40.93 | loss  2.71 | ppl    14.97 | bpc    3.904\n",
      "| epoch  45 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.71 | ppl    14.97 | bpc    3.904\n",
      "| epoch  45 |   200/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.71 | ppl    15.00 | bpc    3.907\n",
      "| epoch  45 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.70 | ppl    14.89 | bpc    3.897\n",
      "| epoch  45 |   300/  559 batches | lr 0.0001 | ms/batch 41.48 | loss  2.70 | ppl    14.82 | bpc    3.889\n",
      "| epoch  45 |   350/  559 batches | lr 0.0001 | ms/batch 41.56 | loss  2.70 | ppl    14.81 | bpc    3.888\n",
      "| epoch  45 |   400/  559 batches | lr 0.0001 | ms/batch 41.68 | loss  2.70 | ppl    14.82 | bpc    3.890\n",
      "| epoch  45 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.69 | ppl    14.78 | bpc    3.885\n",
      "| epoch  45 |   500/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.69 | ppl    14.76 | bpc    3.883\n",
      "| epoch  45 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.69 | ppl    14.68 | bpc    3.876\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 31.75s | valid loss  2.67 | valid ppl    14.46 | bpc    3.854\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.694947 --> 2.671114).  Saving model ...\n",
      "| epoch  46 |    50/  559 batches | lr 0.0001 | ms/batch 40.36 | loss  2.74 | ppl    15.50 | bpc    3.954\n",
      "| epoch  46 |   100/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  2.68 | ppl    14.63 | bpc    3.871\n",
      "| epoch  46 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.68 | ppl    14.65 | bpc    3.872\n",
      "| epoch  46 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.69 | ppl    14.66 | bpc    3.874\n",
      "| epoch  46 |   250/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.68 | ppl    14.57 | bpc    3.865\n",
      "| epoch  46 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.67 | ppl    14.49 | bpc    3.857\n",
      "| epoch  46 |   350/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.67 | ppl    14.48 | bpc    3.856\n",
      "| epoch  46 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.67 | ppl    14.49 | bpc    3.857\n",
      "| epoch  46 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.67 | ppl    14.45 | bpc    3.853\n",
      "| epoch  46 |   500/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.67 | ppl    14.44 | bpc    3.852\n",
      "| epoch  46 |   550/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.66 | ppl    14.36 | bpc    3.844\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 31.88s | valid loss  2.65 | valid ppl    14.12 | bpc    3.820\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.671114 --> 2.647482).  Saving model ...\n",
      "| epoch  47 |    50/  559 batches | lr 0.0001 | ms/batch 41.25 | loss  2.72 | ppl    15.15 | bpc    3.921\n",
      "| epoch  47 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.66 | ppl    14.32 | bpc    3.840\n",
      "| epoch  47 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.66 | ppl    14.33 | bpc    3.841\n",
      "| epoch  47 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.66 | ppl    14.35 | bpc    3.843\n",
      "| epoch  47 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.66 | ppl    14.25 | bpc    3.833\n",
      "| epoch  47 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.65 | ppl    14.18 | bpc    3.826\n",
      "| epoch  47 |   350/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.65 | ppl    14.18 | bpc    3.826\n",
      "| epoch  47 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.65 | ppl    14.18 | bpc    3.826\n",
      "| epoch  47 |   450/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.65 | ppl    14.15 | bpc    3.823\n",
      "| epoch  47 |   500/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.65 | ppl    14.14 | bpc    3.821\n",
      "| epoch  47 |   550/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.64 | ppl    14.07 | bpc    3.814\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 31.92s | valid loss  2.63 | valid ppl    13.81 | bpc    3.787\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.647482 --> 2.625199).  Saving model ...\n",
      "| epoch  48 |    50/  559 batches | lr 0.0001 | ms/batch 40.31 | loss  2.70 | ppl    14.83 | bpc    3.891\n",
      "| epoch  48 |   100/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.64 | ppl    14.02 | bpc    3.810\n",
      "| epoch  48 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.64 | ppl    14.04 | bpc    3.812\n",
      "| epoch  48 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.64 | ppl    14.06 | bpc    3.813\n",
      "| epoch  48 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.64 | ppl    13.96 | bpc    3.804\n",
      "| epoch  48 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.63 | ppl    13.90 | bpc    3.797\n",
      "| epoch  48 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.63 | ppl    13.89 | bpc    3.796\n",
      "| epoch  48 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.63 | ppl    13.91 | bpc    3.798\n",
      "| epoch  48 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.63 | ppl    13.88 | bpc    3.795\n",
      "| epoch  48 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.63 | ppl    13.87 | bpc    3.793\n",
      "| epoch  48 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.62 | ppl    13.80 | bpc    3.787\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 31.88s | valid loss  2.61 | valid ppl    13.53 | bpc    3.758\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.625199 --> 2.605140).  Saving model ...\n",
      "| epoch  49 |    50/  559 batches | lr 0.0001 | ms/batch 40.98 | loss  2.68 | ppl    14.55 | bpc    3.862\n",
      "| epoch  49 |   100/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.62 | ppl    13.77 | bpc    3.784\n",
      "| epoch  49 |   150/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  2.62 | ppl    13.80 | bpc    3.786\n",
      "| epoch  49 |   200/  559 batches | lr 0.0001 | ms/batch 41.71 | loss  2.63 | ppl    13.81 | bpc    3.788\n",
      "| epoch  49 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.62 | ppl    13.72 | bpc    3.778\n",
      "| epoch  49 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.61 | ppl    13.66 | bpc    3.771\n",
      "| epoch  49 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.61 | ppl    13.66 | bpc    3.772\n",
      "| epoch  49 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.62 | ppl    13.67 | bpc    3.773\n",
      "| epoch  49 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.61 | ppl    13.65 | bpc    3.771\n",
      "| epoch  49 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.61 | ppl    13.64 | bpc    3.770\n",
      "| epoch  49 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.61 | ppl    13.57 | bpc    3.762\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 31.89s | valid loss  2.59 | valid ppl    13.30 | bpc    3.733\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.605140 --> 2.587694).  Saving model ...\n",
      "| epoch  50 |    50/  559 batches | lr 0.0001 | ms/batch 41.29 | loss  2.66 | ppl    14.32 | bpc    3.840\n",
      "| epoch  50 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.61 | ppl    13.56 | bpc    3.761\n",
      "| epoch  50 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.61 | ppl    13.58 | bpc    3.764\n",
      "| epoch  50 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.61 | ppl    13.60 | bpc    3.765\n",
      "| epoch  50 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.60 | ppl    13.53 | bpc    3.758\n",
      "| epoch  50 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.60 | ppl    13.45 | bpc    3.750\n",
      "| epoch  50 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.60 | ppl    13.45 | bpc    3.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  50 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.60 | ppl    13.48 | bpc    3.752\n",
      "| epoch  50 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.60 | ppl    13.45 | bpc    3.750\n",
      "| epoch  50 |   500/  559 batches | lr 0.0001 | ms/batch 41.64 | loss  2.60 | ppl    13.45 | bpc    3.749\n",
      "| epoch  50 |   550/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.59 | ppl    13.38 | bpc    3.742\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 31.92s | valid loss  2.57 | valid ppl    13.10 | bpc    3.712\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.587694 --> 2.572656).  Saving model ...\n",
      "=========================================================================================\n",
      "| End of training | test loss  2.57 | test ppl    13.05 | bpc    3.706\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = lr\n",
    "best_val_loss = None\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.99)\n",
    "opts = 'SGD'\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        train_loss = evaluate(train_data)\n",
    "        \n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f} | bpc {:8.3f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                           val_loss, math.exp(val_loss), val_loss / math.log(2)))\n",
    "        print('-' * 89)\n",
    "        val_losses.append(val_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            if opts == 'SGD' or opts == 'Momentum':\n",
    "                lr /= 4.0\n",
    "                for group in opt.param_groups:\n",
    "                    group['lr'] = lr\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "    test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_losses = [i.item() for i in val_losses]\n",
    "training_losses = [i.item() for i in train_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(50), training_losses)\n",
    "plt.plot(range(50), validation_losses, c='#00ff00')\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(0, 5.0)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Loss')\n",
    "plt.savefig('Char_None'+'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With Gaussian Noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gPNHLTnVSLT",
    "outputId": "9897f2e7-ffd0-487e-e875-0a938a273e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (encoder): Embedding(50, 256)\n",
      "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
      "  (decoder): Linear(in_features=1000, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "interval = 50 # interval to report\n",
    "ntokens = len(corpus.dictionary) # 10000\n",
    "model = RNNModel(ntokens, emsize, nhid, nlayers, dropout)\n",
    "save = 'output/model_test_character_noise.pt'\n",
    "checkpoint = \"output/model_test_character_none.pt\"\n",
    "\n",
    "# Load checkpoint\n",
    "if checkpoint != '':\n",
    "    model = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "\n",
    "print(model)\n",
    "model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sy-oBaJnV_4E",
    "outputId": "574778e1-e6a0-4f93-fde8-a30d1df1ae40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/sashank.sridhar/miniconda3/envs/TripletLoss/lib/python3.9/site-packages/torch/distributions/distribution.py:159: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  559 batches | lr 0.0001 | ms/batch 38.04 | loss  2.92 | ppl    18.59 | bpc    4.217\n",
      "| epoch   1 |   100/  559 batches | lr 0.0001 | ms/batch 36.91 | loss  2.82 | ppl    16.70 | bpc    4.061\n",
      "| epoch   1 |   150/  559 batches | lr 0.0001 | ms/batch 36.89 | loss  2.79 | ppl    16.21 | bpc    4.018\n",
      "| epoch   1 |   200/  559 batches | lr 0.0001 | ms/batch 36.95 | loss  2.76 | ppl    15.83 | bpc    3.985\n",
      "| epoch   1 |   250/  559 batches | lr 0.0001 | ms/batch 37.00 | loss  2.74 | ppl    15.45 | bpc    3.950\n",
      "| epoch   1 |   300/  559 batches | lr 0.0001 | ms/batch 37.04 | loss  2.72 | ppl    15.11 | bpc    3.917\n",
      "| epoch   1 |   350/  559 batches | lr 0.0001 | ms/batch 37.08 | loss  2.70 | ppl    14.94 | bpc    3.901\n",
      "| epoch   1 |   400/  559 batches | lr 0.0001 | ms/batch 37.16 | loss  2.69 | ppl    14.79 | bpc    3.887\n",
      "| epoch   1 |   450/  559 batches | lr 0.0001 | ms/batch 37.15 | loss  2.68 | ppl    14.63 | bpc    3.871\n",
      "| epoch   1 |   500/  559 batches | lr 0.0001 | ms/batch 37.22 | loss  2.68 | ppl    14.52 | bpc    3.860\n",
      "| epoch   1 |   550/  559 batches | lr 0.0001 | ms/batch 37.29 | loss  2.66 | ppl    14.36 | bpc    3.844\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 2.605290).  Saving model ...\n",
      "| end of epoch   1 | time: 28.44s | valid loss  2.61 | valid ppl    13.54 | bpc    3.759\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |    50/  559 batches | lr 0.0001 | ms/batch 38.16 | loss  3.16 | ppl    23.55 | bpc    4.558\n",
      "| epoch   2 |   100/  559 batches | lr 0.0001 | ms/batch 37.46 | loss  3.00 | ppl    20.11 | bpc    4.330\n",
      "| epoch   2 |   150/  559 batches | lr 0.0001 | ms/batch 37.53 | loss  2.96 | ppl    19.27 | bpc    4.268\n",
      "| epoch   2 |   200/  559 batches | lr 0.0001 | ms/batch 37.61 | loss  2.93 | ppl    18.73 | bpc    4.227\n",
      "| epoch   2 |   250/  559 batches | lr 0.0001 | ms/batch 37.70 | loss  2.90 | ppl    18.25 | bpc    4.190\n",
      "| epoch   2 |   300/  559 batches | lr 0.0001 | ms/batch 37.69 | loss  2.88 | ppl    17.77 | bpc    4.151\n",
      "| epoch   2 |   350/  559 batches | lr 0.0001 | ms/batch 37.70 | loss  2.85 | ppl    17.37 | bpc    4.119\n",
      "| epoch   2 |   400/  559 batches | lr 0.0001 | ms/batch 37.75 | loss  2.84 | ppl    17.07 | bpc    4.093\n",
      "| epoch   2 |   450/  559 batches | lr 0.0001 | ms/batch 37.78 | loss  2.81 | ppl    16.67 | bpc    4.059\n",
      "| epoch   2 |   500/  559 batches | lr 0.0001 | ms/batch 37.80 | loss  2.79 | ppl    16.35 | bpc    4.031\n",
      "| epoch   2 |   550/  559 batches | lr 0.0001 | ms/batch 37.75 | loss  2.77 | ppl    15.99 | bpc    3.999\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch   2 | time: 28.80s | valid loss  2.68 | valid ppl    14.55 | bpc    3.863\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |    50/  559 batches | lr 0.0001 | ms/batch 38.85 | loss  3.23 | ppl    25.32 | bpc    4.662\n",
      "| epoch   3 |   100/  559 batches | lr 0.0001 | ms/batch 38.05 | loss  3.11 | ppl    22.44 | bpc    4.488\n",
      "| epoch   3 |   150/  559 batches | lr 0.0001 | ms/batch 38.11 | loss  3.05 | ppl    21.09 | bpc    4.398\n",
      "| epoch   3 |   200/  559 batches | lr 0.0001 | ms/batch 38.14 | loss  3.01 | ppl    20.28 | bpc    4.342\n",
      "| epoch   3 |   250/  559 batches | lr 0.0001 | ms/batch 38.13 | loss  2.97 | ppl    19.46 | bpc    4.282\n",
      "| epoch   3 |   300/  559 batches | lr 0.0001 | ms/batch 38.22 | loss  2.95 | ppl    19.02 | bpc    4.249\n",
      "| epoch   3 |   350/  559 batches | lr 0.0001 | ms/batch 38.18 | loss  2.93 | ppl    18.74 | bpc    4.228\n",
      "| epoch   3 |   400/  559 batches | lr 0.0001 | ms/batch 38.19 | loss  2.91 | ppl    18.44 | bpc    4.205\n",
      "| epoch   3 |   450/  559 batches | lr 0.0001 | ms/batch 38.28 | loss  2.90 | ppl    18.15 | bpc    4.182\n",
      "| epoch   3 |   500/  559 batches | lr 0.0001 | ms/batch 38.32 | loss  2.88 | ppl    17.88 | bpc    4.160\n",
      "| epoch   3 |   550/  559 batches | lr 0.0001 | ms/batch 38.32 | loss  2.87 | ppl    17.60 | bpc    4.138\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| end of epoch   3 | time: 29.43s | valid loss  2.77 | valid ppl    15.92 | bpc    3.992\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |    50/  559 batches | lr 0.0001 | ms/batch 40.25 | loss  3.15 | ppl    23.42 | bpc    4.550\n",
      "| epoch   4 |   100/  559 batches | lr 0.0001 | ms/batch 40.49 | loss  3.06 | ppl    21.25 | bpc    4.409\n",
      "| epoch   4 |   150/  559 batches | lr 0.0001 | ms/batch 40.34 | loss  3.02 | ppl    20.47 | bpc    4.355\n",
      "| epoch   4 |   200/  559 batches | lr 0.0001 | ms/batch 41.34 | loss  2.99 | ppl    19.94 | bpc    4.318\n",
      "| epoch   4 |   250/  559 batches | lr 0.0001 | ms/batch 40.83 | loss  2.96 | ppl    19.37 | bpc    4.276\n",
      "| epoch   4 |   300/  559 batches | lr 0.0001 | ms/batch 40.58 | loss  2.94 | ppl    19.01 | bpc    4.248\n",
      "| epoch   4 |   350/  559 batches | lr 0.0001 | ms/batch 41.02 | loss  2.93 | ppl    18.81 | bpc    4.234\n",
      "| epoch   4 |   400/  559 batches | lr 0.0001 | ms/batch 40.81 | loss  2.92 | ppl    18.62 | bpc    4.219\n",
      "| epoch   4 |   450/  559 batches | lr 0.0001 | ms/batch 40.97 | loss  2.91 | ppl    18.37 | bpc    4.199\n",
      "| epoch   4 |   500/  559 batches | lr 0.0001 | ms/batch 40.68 | loss  2.90 | ppl    18.18 | bpc    4.184\n",
      "| epoch   4 |   550/  559 batches | lr 0.0001 | ms/batch 41.28 | loss  2.89 | ppl    17.95 | bpc    4.166\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| end of epoch   4 | time: 31.20s | valid loss  2.79 | valid ppl    16.31 | bpc    4.028\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |    50/  559 batches | lr 0.0001 | ms/batch 40.71 | loss  3.16 | ppl    23.56 | bpc    4.559\n",
      "| epoch   5 |   100/  559 batches | lr 0.0001 | ms/batch 41.18 | loss  3.06 | ppl    21.42 | bpc    4.421\n",
      "| epoch   5 |   150/  559 batches | lr 0.0001 | ms/batch 40.73 | loss  3.02 | ppl    20.57 | bpc    4.363\n",
      "| epoch   5 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  3.00 | ppl    20.02 | bpc    4.324\n",
      "| epoch   5 |   250/  559 batches | lr 0.0001 | ms/batch 41.13 | loss  2.97 | ppl    19.55 | bpc    4.289\n",
      "| epoch   5 |   300/  559 batches | lr 0.0001 | ms/batch 41.49 | loss  2.96 | ppl    19.25 | bpc    4.267\n",
      "| epoch   5 |   350/  559 batches | lr 0.0001 | ms/batch 41.28 | loss  2.95 | ppl    19.04 | bpc    4.251\n",
      "| epoch   5 |   400/  559 batches | lr 0.0001 | ms/batch 41.26 | loss  2.94 | ppl    18.89 | bpc    4.240\n",
      "| epoch   5 |   450/  559 batches | lr 0.0001 | ms/batch 41.56 | loss  2.93 | ppl    18.69 | bpc    4.225\n",
      "| epoch   5 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.92 | ppl    18.53 | bpc    4.212\n",
      "| epoch   5 |   550/  559 batches | lr 0.0001 | ms/batch 40.69 | loss  2.91 | ppl    18.34 | bpc    4.197\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| end of epoch   5 | time: 31.60s | valid loss  2.81 | valid ppl    16.60 | bpc    4.053\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |    50/  559 batches | lr 0.0001 | ms/batch 40.36 | loss  3.06 | ppl    21.37 | bpc    4.418\n",
      "| epoch   6 |   100/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.99 | ppl    19.95 | bpc    4.318\n",
      "| epoch   6 |   150/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.99 | ppl    19.80 | bpc    4.307\n",
      "| epoch   6 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.98 | ppl    19.67 | bpc    4.298\n",
      "| epoch   6 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.97 | ppl    19.40 | bpc    4.278\n",
      "| epoch   6 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.96 | ppl    19.25 | bpc    4.267\n",
      "| epoch   6 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.95 | ppl    19.05 | bpc    4.252\n",
      "| epoch   6 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.94 | ppl    18.91 | bpc    4.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   450/  559 batches | lr 0.0001 | ms/batch 41.65 | loss  2.93 | ppl    18.78 | bpc    4.231\n",
      "| epoch   6 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.93 | ppl    18.64 | bpc    4.220\n",
      "| epoch   6 |   550/  559 batches | lr 0.0001 | ms/batch 41.70 | loss  2.92 | ppl    18.46 | bpc    4.206\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| end of epoch   6 | time: 31.90s | valid loss  2.82 | valid ppl    16.80 | bpc    4.071\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |    50/  559 batches | lr 0.0001 | ms/batch 40.23 | loss  3.09 | ppl    21.87 | bpc    4.451\n",
      "| epoch   7 |   100/  559 batches | lr 0.0001 | ms/batch 40.49 | loss  3.01 | ppl    20.26 | bpc    4.341\n",
      "| epoch   7 |   150/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.99 | ppl    19.97 | bpc    4.320\n",
      "| epoch   7 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.99 | ppl    19.94 | bpc    4.318\n",
      "| epoch   7 |   250/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.99 | ppl    19.86 | bpc    4.312\n",
      "| epoch   7 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.99 | ppl    19.95 | bpc    4.319\n",
      "| epoch   7 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  3.00 | ppl    20.02 | bpc    4.323\n",
      "| epoch   7 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  3.00 | ppl    20.03 | bpc    4.324\n",
      "| epoch   7 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  3.00 | ppl    20.02 | bpc    4.324\n",
      "| epoch   7 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.99 | ppl    19.91 | bpc    4.316\n",
      "| epoch   7 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.98 | ppl    19.74 | bpc    4.303\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| end of epoch   7 | time: 31.84s | valid loss  2.88 | valid ppl    17.84 | bpc    4.157\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |    50/  559 batches | lr 0.0001 | ms/batch 42.53 | loss  3.06 | ppl    21.25 | bpc    4.409\n",
      "| epoch   8 |   100/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.98 | ppl    19.74 | bpc    4.303\n",
      "| epoch   8 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.98 | ppl    19.72 | bpc    4.301\n",
      "| epoch   8 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.98 | ppl    19.76 | bpc    4.304\n",
      "| epoch   8 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.98 | ppl    19.61 | bpc    4.293\n",
      "| epoch   8 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.97 | ppl    19.56 | bpc    4.290\n",
      "| epoch   8 |   350/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.97 | ppl    19.56 | bpc    4.290\n",
      "| epoch   8 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.97 | ppl    19.57 | bpc    4.291\n",
      "| epoch   8 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.97 | ppl    19.53 | bpc    4.287\n",
      "| epoch   8 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.96 | ppl    19.39 | bpc    4.277\n",
      "| epoch   8 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.96 | ppl    19.24 | bpc    4.266\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| end of epoch   8 | time: 32.02s | valid loss  2.86 | valid ppl    17.46 | bpc    4.126\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |    50/  559 batches | lr 0.0001 | ms/batch 40.45 | loss  3.03 | ppl    20.72 | bpc    4.373\n",
      "| epoch   9 |   100/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.98 | ppl    19.59 | bpc    4.292\n",
      "| epoch   9 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.99 | ppl    19.85 | bpc    4.311\n",
      "| epoch   9 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  3.00 | ppl    20.14 | bpc    4.332\n",
      "| epoch   9 |   250/  559 batches | lr 0.0001 | ms/batch 41.66 | loss  3.00 | ppl    20.08 | bpc    4.327\n",
      "| epoch   9 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  3.00 | ppl    20.05 | bpc    4.325\n",
      "| epoch   9 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.98 | ppl    19.75 | bpc    4.304\n",
      "| epoch   9 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.97 | ppl    19.57 | bpc    4.291\n",
      "| epoch   9 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.96 | ppl    19.32 | bpc    4.272\n",
      "| epoch   9 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.95 | ppl    19.09 | bpc    4.255\n",
      "| epoch   9 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.93 | ppl    18.81 | bpc    4.234\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 25\n",
      "| end of epoch   9 | time: 31.92s | valid loss  2.84 | valid ppl    17.06 | bpc    4.092\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |    50/  559 batches | lr 0.0001 | ms/batch 40.02 | loss  3.03 | ppl    20.75 | bpc    4.375\n",
      "| epoch  10 |   100/  559 batches | lr 0.0001 | ms/batch 41.59 | loss  2.98 | ppl    19.60 | bpc    4.293\n",
      "| epoch  10 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.97 | ppl    19.48 | bpc    4.284\n",
      "| epoch  10 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.99 | ppl    19.93 | bpc    4.317\n",
      "| epoch  10 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  3.00 | ppl    20.18 | bpc    4.335\n",
      "| epoch  10 |   300/  559 batches | lr 0.0001 | ms/batch 41.71 | loss  2.97 | ppl    19.54 | bpc    4.288\n",
      "| epoch  10 |   350/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.96 | ppl    19.37 | bpc    4.276\n",
      "| epoch  10 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.96 | ppl    19.38 | bpc    4.276\n",
      "| epoch  10 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.96 | ppl    19.39 | bpc    4.277\n",
      "| epoch  10 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.96 | ppl    19.34 | bpc    4.274\n",
      "| epoch  10 |   550/  559 batches | lr 0.0001 | ms/batch 41.61 | loss  2.96 | ppl    19.27 | bpc    4.268\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 25\n",
      "| end of epoch  10 | time: 31.89s | valid loss  2.86 | valid ppl    17.49 | bpc    4.128\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |    50/  559 batches | lr 0.0001 | ms/batch 42.48 | loss  3.03 | ppl    20.75 | bpc    4.375\n",
      "| epoch  11 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.98 | ppl    19.68 | bpc    4.298\n",
      "| epoch  11 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.98 | ppl    19.75 | bpc    4.304\n",
      "| epoch  11 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.98 | ppl    19.74 | bpc    4.303\n",
      "| epoch  11 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.97 | ppl    19.43 | bpc    4.280\n",
      "| epoch  11 |   300/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.96 | ppl    19.26 | bpc    4.267\n",
      "| epoch  11 |   350/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.94 | ppl    19.01 | bpc    4.249\n",
      "| epoch  11 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.94 | ppl    18.82 | bpc    4.235\n",
      "| epoch  11 |   450/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.92 | ppl    18.60 | bpc    4.217\n",
      "| epoch  11 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.91 | ppl    18.38 | bpc    4.200\n",
      "| epoch  11 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.90 | ppl    18.18 | bpc    4.184\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 25\n",
      "| end of epoch  11 | time: 32.05s | valid loss  2.80 | valid ppl    16.44 | bpc    4.039\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |    50/  559 batches | lr 0.0001 | ms/batch 40.72 | loss  2.98 | ppl    19.64 | bpc    4.295\n",
      "| epoch  12 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.91 | ppl    18.29 | bpc    4.193\n",
      "| epoch  12 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.90 | ppl    18.13 | bpc    4.181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  12 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.90 | ppl    18.13 | bpc    4.180\n",
      "| epoch  12 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.89 | ppl    18.05 | bpc    4.174\n",
      "| epoch  12 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.89 | ppl    17.94 | bpc    4.166\n",
      "| epoch  12 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.88 | ppl    17.80 | bpc    4.154\n",
      "| epoch  12 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.88 | ppl    17.75 | bpc    4.150\n",
      "| epoch  12 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.88 | ppl    17.75 | bpc    4.150\n",
      "| epoch  12 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.87 | ppl    17.71 | bpc    4.146\n",
      "| epoch  12 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.87 | ppl    17.70 | bpc    4.145\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 11 out of 25\n",
      "| end of epoch  12 | time: 31.95s | valid loss  2.78 | valid ppl    16.18 | bpc    4.017\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |    50/  559 batches | lr 0.0001 | ms/batch 41.49 | loss  2.98 | ppl    19.74 | bpc    4.303\n",
      "| epoch  13 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.95 | ppl    19.15 | bpc    4.259\n",
      "| epoch  13 |   150/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.95 | ppl    19.07 | bpc    4.254\n",
      "| epoch  13 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.95 | ppl    19.15 | bpc    4.259\n",
      "| epoch  13 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.96 | ppl    19.24 | bpc    4.266\n",
      "| epoch  13 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.95 | ppl    19.15 | bpc    4.259\n",
      "| epoch  13 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.95 | ppl    19.15 | bpc    4.259\n",
      "| epoch  13 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.95 | ppl    19.14 | bpc    4.259\n",
      "| epoch  13 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.95 | ppl    19.04 | bpc    4.251\n",
      "| epoch  13 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.94 | ppl    18.84 | bpc    4.236\n",
      "| epoch  13 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.92 | ppl    18.57 | bpc    4.215\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 12 out of 25\n",
      "| end of epoch  13 | time: 31.99s | valid loss  2.82 | valid ppl    16.83 | bpc    4.073\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |    50/  559 batches | lr 0.0001 | ms/batch 40.51 | loss  2.99 | ppl    19.84 | bpc    4.310\n",
      "| epoch  14 |   100/  559 batches | lr 0.0001 | ms/batch 40.45 | loss  2.93 | ppl    18.69 | bpc    4.224\n",
      "| epoch  14 |   150/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.93 | ppl    18.77 | bpc    4.230\n",
      "| epoch  14 |   200/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.94 | ppl    18.95 | bpc    4.244\n",
      "| epoch  14 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.93 | ppl    18.79 | bpc    4.232\n",
      "| epoch  14 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.92 | ppl    18.46 | bpc    4.207\n",
      "| epoch  14 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.90 | ppl    18.22 | bpc    4.188\n",
      "| epoch  14 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.89 | ppl    17.98 | bpc    4.169\n",
      "| epoch  14 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.88 | ppl    17.77 | bpc    4.151\n",
      "| epoch  14 |   500/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.87 | ppl    17.63 | bpc    4.140\n",
      "| epoch  14 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.86 | ppl    17.43 | bpc    4.124\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 13 out of 25\n",
      "| end of epoch  14 | time: 31.86s | valid loss  2.75 | valid ppl    15.63 | bpc    3.966\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |    50/  559 batches | lr 0.0001 | ms/batch 40.61 | loss  2.95 | ppl    19.15 | bpc    4.259\n",
      "| epoch  15 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.88 | ppl    17.79 | bpc    4.153\n",
      "| epoch  15 |   150/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.87 | ppl    17.61 | bpc    4.138\n",
      "| epoch  15 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.86 | ppl    17.46 | bpc    4.126\n",
      "| epoch  15 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.84 | ppl    17.19 | bpc    4.104\n",
      "| epoch  15 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.83 | ppl    16.96 | bpc    4.084\n",
      "| epoch  15 |   350/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.82 | ppl    16.85 | bpc    4.074\n",
      "| epoch  15 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.82 | ppl    16.78 | bpc    4.069\n",
      "| epoch  15 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.82 | ppl    16.71 | bpc    4.063\n",
      "| epoch  15 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.81 | ppl    16.63 | bpc    4.056\n",
      "| epoch  15 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.81 | ppl    16.53 | bpc    4.047\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 14 out of 25\n",
      "| end of epoch  15 | time: 31.95s | valid loss  2.71 | valid ppl    15.01 | bpc    3.908\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |    50/  559 batches | lr 0.0001 | ms/batch 39.80 | loss  2.90 | ppl    18.18 | bpc    4.184\n",
      "| epoch  16 |   100/  559 batches | lr 0.0001 | ms/batch 41.18 | loss  2.87 | ppl    17.59 | bpc    4.136\n",
      "| epoch  16 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.88 | ppl    17.81 | bpc    4.154\n",
      "| epoch  16 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.89 | ppl    18.00 | bpc    4.170\n",
      "| epoch  16 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.90 | ppl    18.11 | bpc    4.178\n",
      "| epoch  16 |   300/  559 batches | lr 0.0001 | ms/batch 41.62 | loss  2.89 | ppl    17.97 | bpc    4.167\n",
      "| epoch  16 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.88 | ppl    17.79 | bpc    4.153\n",
      "| epoch  16 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.88 | ppl    17.75 | bpc    4.150\n",
      "| epoch  16 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.87 | ppl    17.66 | bpc    4.142\n",
      "| epoch  16 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.87 | ppl    17.68 | bpc    4.144\n",
      "| epoch  16 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.88 | ppl    17.76 | bpc    4.150\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 15 out of 25\n",
      "| end of epoch  16 | time: 31.85s | valid loss  2.80 | valid ppl    16.41 | bpc    4.036\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |    50/  559 batches | lr 0.0001 | ms/batch 40.04 | loss  2.94 | ppl    18.94 | bpc    4.243\n",
      "| epoch  17 |   100/  559 batches | lr 0.0001 | ms/batch 41.33 | loss  2.88 | ppl    17.86 | bpc    4.159\n",
      "| epoch  17 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.89 | ppl    17.92 | bpc    4.164\n",
      "| epoch  17 |   200/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.88 | ppl    17.85 | bpc    4.158\n",
      "| epoch  17 |   250/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.87 | ppl    17.59 | bpc    4.136\n",
      "| epoch  17 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.86 | ppl    17.42 | bpc    4.123\n",
      "| epoch  17 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.85 | ppl    17.27 | bpc    4.110\n",
      "| epoch  17 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.84 | ppl    17.14 | bpc    4.099\n",
      "| epoch  17 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.83 | ppl    17.01 | bpc    4.088\n",
      "| epoch  17 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.83 | ppl    16.88 | bpc    4.078\n",
      "| epoch  17 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.81 | ppl    16.68 | bpc    4.060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 16 out of 25\n",
      "| end of epoch  17 | time: 31.90s | valid loss  2.72 | valid ppl    15.18 | bpc    3.924\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |    50/  559 batches | lr 0.0001 | ms/batch 39.91 | loss  2.88 | ppl    17.80 | bpc    4.154\n",
      "| epoch  18 |   100/  559 batches | lr 0.0001 | ms/batch 40.75 | loss  2.82 | ppl    16.75 | bpc    4.066\n",
      "| epoch  18 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.82 | ppl    16.85 | bpc    4.075\n",
      "| epoch  18 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.83 | ppl    16.97 | bpc    4.084\n",
      "| epoch  18 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.83 | ppl    16.92 | bpc    4.081\n",
      "| epoch  18 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.83 | ppl    16.88 | bpc    4.077\n",
      "| epoch  18 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.82 | ppl    16.86 | bpc    4.075\n",
      "| epoch  18 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.82 | ppl    16.82 | bpc    4.072\n",
      "| epoch  18 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.82 | ppl    16.74 | bpc    4.065\n",
      "| epoch  18 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.81 | ppl    16.62 | bpc    4.055\n",
      "| epoch  18 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.80 | ppl    16.44 | bpc    4.039\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 17 out of 25\n",
      "| end of epoch  18 | time: 31.85s | valid loss  2.71 | valid ppl    15.01 | bpc    3.908\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |    50/  559 batches | lr 0.0001 | ms/batch 42.48 | loss  2.86 | ppl    17.46 | bpc    4.126\n",
      "| epoch  19 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.80 | ppl    16.36 | bpc    4.032\n",
      "| epoch  19 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.79 | ppl    16.33 | bpc    4.030\n",
      "| epoch  19 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.79 | ppl    16.31 | bpc    4.028\n",
      "| epoch  19 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.78 | ppl    16.20 | bpc    4.018\n",
      "| epoch  19 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.78 | ppl    16.11 | bpc    4.010\n",
      "| epoch  19 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.78 | ppl    16.06 | bpc    4.006\n",
      "| epoch  19 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.78 | ppl    16.04 | bpc    4.004\n",
      "| epoch  19 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.77 | ppl    16.01 | bpc    4.001\n",
      "| epoch  19 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.77 | ppl    16.00 | bpc    4.000\n",
      "| epoch  19 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.77 | ppl    15.92 | bpc    3.993\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 18 out of 25\n",
      "| end of epoch  19 | time: 32.04s | valid loss  2.68 | valid ppl    14.58 | bpc    3.865\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |    50/  559 batches | lr 0.0001 | ms/batch 41.63 | loss  2.85 | ppl    17.21 | bpc    4.105\n",
      "| epoch  20 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.80 | ppl    16.39 | bpc    4.035\n",
      "| epoch  20 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.81 | ppl    16.66 | bpc    4.058\n",
      "| epoch  20 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.83 | ppl    16.90 | bpc    4.079\n",
      "| epoch  20 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.82 | ppl    16.82 | bpc    4.072\n",
      "| epoch  20 |   300/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.82 | ppl    16.79 | bpc    4.070\n",
      "| epoch  20 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.82 | ppl    16.77 | bpc    4.068\n",
      "| epoch  20 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.82 | ppl    16.74 | bpc    4.065\n",
      "| epoch  20 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.81 | ppl    16.62 | bpc    4.055\n",
      "| epoch  20 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.81 | ppl    16.56 | bpc    4.050\n",
      "| epoch  20 |   550/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.80 | ppl    16.41 | bpc    4.036\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 19 out of 25\n",
      "| end of epoch  20 | time: 31.99s | valid loss  2.70 | valid ppl    14.92 | bpc    3.899\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |    50/  559 batches | lr 0.0001 | ms/batch 40.59 | loss  2.86 | ppl    17.53 | bpc    4.132\n",
      "| epoch  21 |   100/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.80 | ppl    16.47 | bpc    4.042\n",
      "| epoch  21 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.80 | ppl    16.50 | bpc    4.044\n",
      "| epoch  21 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.80 | ppl    16.48 | bpc    4.043\n",
      "| epoch  21 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.80 | ppl    16.37 | bpc    4.033\n",
      "| epoch  21 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.79 | ppl    16.34 | bpc    4.030\n",
      "| epoch  21 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.79 | ppl    16.35 | bpc    4.031\n",
      "| epoch  21 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.80 | ppl    16.45 | bpc    4.040\n",
      "| epoch  21 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.80 | ppl    16.51 | bpc    4.045\n",
      "| epoch  21 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.80 | ppl    16.49 | bpc    4.044\n",
      "| epoch  21 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.80 | ppl    16.39 | bpc    4.035\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 20 out of 25\n",
      "| end of epoch  21 | time: 31.93s | valid loss  2.71 | valid ppl    14.97 | bpc    3.904\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |    50/  559 batches | lr 0.0001 | ms/batch 40.87 | loss  2.88 | ppl    17.73 | bpc    4.148\n",
      "| epoch  22 |   100/  559 batches | lr 0.0001 | ms/batch 41.68 | loss  2.82 | ppl    16.85 | bpc    4.075\n",
      "| epoch  22 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.90 | ppl    18.17 | bpc    4.184\n",
      "| epoch  22 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.96 | ppl    19.20 | bpc    4.263\n",
      "| epoch  22 |   250/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  3.01 | ppl    20.35 | bpc    4.347\n",
      "| epoch  22 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  3.03 | ppl    20.69 | bpc    4.371\n",
      "| epoch  22 |   350/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  3.02 | ppl    20.47 | bpc    4.355\n",
      "| epoch  22 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.99 | ppl    19.95 | bpc    4.319\n",
      "| epoch  22 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.97 | ppl    19.43 | bpc    4.280\n",
      "| epoch  22 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.95 | ppl    19.04 | bpc    4.251\n",
      "| epoch  22 |   550/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.92 | ppl    18.48 | bpc    4.208\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 21 out of 25\n",
      "| end of epoch  22 | time: 31.96s | valid loss  2.79 | valid ppl    16.25 | bpc    4.022\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |    50/  559 batches | lr 0.0001 | ms/batch 42.06 | loss  2.99 | ppl    19.86 | bpc    4.312\n",
      "| epoch  23 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.90 | ppl    18.23 | bpc    4.188\n",
      "| epoch  23 |   150/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.89 | ppl    17.94 | bpc    4.165\n",
      "| epoch  23 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.87 | ppl    17.69 | bpc    4.145\n",
      "| epoch  23 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.85 | ppl    17.28 | bpc    4.111\n",
      "| epoch  23 |   300/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.83 | ppl    16.97 | bpc    4.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  23 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.82 | ppl    16.73 | bpc    4.065\n",
      "| epoch  23 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.81 | ppl    16.57 | bpc    4.050\n",
      "| epoch  23 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.80 | ppl    16.38 | bpc    4.034\n",
      "| epoch  23 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.79 | ppl    16.23 | bpc    4.021\n",
      "| epoch  23 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.78 | ppl    16.04 | bpc    4.004\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 22 out of 25\n",
      "| end of epoch  23 | time: 32.01s | valid loss  2.67 | valid ppl    14.39 | bpc    3.847\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |    50/  559 batches | lr 0.0001 | ms/batch 41.39 | loss  2.84 | ppl    17.18 | bpc    4.102\n",
      "| epoch  24 |   100/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.78 | ppl    16.12 | bpc    4.011\n",
      "| epoch  24 |   150/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.78 | ppl    16.18 | bpc    4.016\n",
      "| epoch  24 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.79 | ppl    16.28 | bpc    4.025\n",
      "| epoch  24 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.78 | ppl    16.17 | bpc    4.015\n",
      "| epoch  24 |   300/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.78 | ppl    16.14 | bpc    4.012\n",
      "| epoch  24 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.78 | ppl    16.18 | bpc    4.016\n",
      "| epoch  24 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.79 | ppl    16.27 | bpc    4.024\n",
      "| epoch  24 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.79 | ppl    16.31 | bpc    4.028\n",
      "| epoch  24 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.80 | ppl    16.53 | bpc    4.047\n",
      "| epoch  24 |   550/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.80 | ppl    16.53 | bpc    4.047\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 23 out of 25\n",
      "| end of epoch  24 | time: 31.99s | valid loss  2.70 | valid ppl    14.94 | bpc    3.901\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |    50/  559 batches | lr 0.0001 | ms/batch 42.58 | loss  2.86 | ppl    17.38 | bpc    4.119\n",
      "| epoch  25 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.79 | ppl    16.29 | bpc    4.026\n",
      "| epoch  25 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.79 | ppl    16.21 | bpc    4.019\n",
      "| epoch  25 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.78 | ppl    16.11 | bpc    4.010\n",
      "| epoch  25 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.76 | ppl    15.84 | bpc    3.986\n",
      "| epoch  25 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.75 | ppl    15.64 | bpc    3.968\n",
      "| epoch  25 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.74 | ppl    15.55 | bpc    3.959\n",
      "| epoch  25 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.74 | ppl    15.48 | bpc    3.952\n",
      "| epoch  25 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.73 | ppl    15.37 | bpc    3.942\n",
      "| epoch  25 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.73 | ppl    15.28 | bpc    3.934\n",
      "| epoch  25 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.72 | ppl    15.12 | bpc    3.918\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 24 out of 25\n",
      "| end of epoch  25 | time: 32.05s | valid loss  2.61 | valid ppl    13.54 | bpc    3.759\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |    50/  559 batches | lr 0.0001 | ms/batch 41.96 | loss  2.78 | ppl    16.08 | bpc    4.008\n",
      "| epoch  26 |   100/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.71 | ppl    15.10 | bpc    3.917\n",
      "| epoch  26 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    15.06 | bpc    3.913\n",
      "| epoch  26 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    15.04 | bpc    3.911\n",
      "| epoch  26 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.70 | ppl    14.90 | bpc    3.897\n",
      "| epoch  26 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.69 | ppl    14.79 | bpc    3.887\n",
      "| epoch  26 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.69 | ppl    14.75 | bpc    3.882\n",
      "| epoch  26 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.69 | ppl    14.72 | bpc    3.880\n",
      "| epoch  26 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.68 | ppl    14.65 | bpc    3.873\n",
      "| epoch  26 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.68 | ppl    14.62 | bpc    3.870\n",
      "| epoch  26 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.67 | ppl    14.46 | bpc    3.854\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.605290 --> 2.557457).  Saving model ...\n",
      "| end of epoch  26 | time: 32.05s | valid loss  2.56 | valid ppl    12.90 | bpc    3.690\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |    50/  559 batches | lr 0.0001 | ms/batch 39.45 | loss  2.74 | ppl    15.45 | bpc    3.950\n",
      "| epoch  27 |   100/  559 batches | lr 0.0001 | ms/batch 40.96 | loss  2.68 | ppl    14.59 | bpc    3.867\n",
      "| epoch  27 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.68 | ppl    14.57 | bpc    3.864\n",
      "| epoch  27 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.68 | ppl    14.53 | bpc    3.861\n",
      "| epoch  27 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.67 | ppl    14.38 | bpc    3.846\n",
      "| epoch  27 |   300/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.66 | ppl    14.26 | bpc    3.834\n",
      "| epoch  27 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.66 | ppl    14.24 | bpc    3.832\n",
      "| epoch  27 |   400/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.66 | ppl    14.27 | bpc    3.835\n",
      "| epoch  27 |   450/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.66 | ppl    14.23 | bpc    3.831\n",
      "| epoch  27 |   500/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.65 | ppl    14.18 | bpc    3.826\n",
      "| epoch  27 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.64 | ppl    14.04 | bpc    3.812\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.557457 --> 2.526626).  Saving model ...\n",
      "| end of epoch  27 | time: 31.89s | valid loss  2.53 | valid ppl    12.51 | bpc    3.645\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |    50/  559 batches | lr 0.0001 | ms/batch 40.92 | loss  2.71 | ppl    15.01 | bpc    3.908\n",
      "| epoch  28 |   100/  559 batches | lr 0.0001 | ms/batch 41.60 | loss  2.65 | ppl    14.21 | bpc    3.829\n",
      "| epoch  28 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.66 | ppl    14.23 | bpc    3.831\n",
      "| epoch  28 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.66 | ppl    14.27 | bpc    3.834\n",
      "| epoch  28 |   250/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.65 | ppl    14.17 | bpc    3.825\n",
      "| epoch  28 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.64 | ppl    14.06 | bpc    3.814\n",
      "| epoch  28 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.64 | ppl    14.08 | bpc    3.815\n",
      "| epoch  28 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.65 | ppl    14.14 | bpc    3.822\n",
      "| epoch  28 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.65 | ppl    14.17 | bpc    3.825\n",
      "| epoch  28 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.65 | ppl    14.14 | bpc    3.822\n",
      "| epoch  28 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.65 | ppl    14.09 | bpc    3.816\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  28 | time: 31.95s | valid loss  2.54 | valid ppl    12.70 | bpc    3.666\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  29 |    50/  559 batches | lr 0.0001 | ms/batch 42.54 | loss  2.71 | ppl    15.05 | bpc    3.912\n",
      "| epoch  29 |   100/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.66 | ppl    14.25 | bpc    3.833\n",
      "| epoch  29 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.66 | ppl    14.34 | bpc    3.842\n",
      "| epoch  29 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.67 | ppl    14.44 | bpc    3.852\n",
      "| epoch  29 |   250/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.67 | ppl    14.45 | bpc    3.853\n",
      "| epoch  29 |   300/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.67 | ppl    14.42 | bpc    3.850\n",
      "| epoch  29 |   350/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.67 | ppl    14.44 | bpc    3.852\n",
      "| epoch  29 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.67 | ppl    14.47 | bpc    3.855\n",
      "| epoch  29 |   450/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.67 | ppl    14.51 | bpc    3.859\n",
      "| epoch  29 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.68 | ppl    14.52 | bpc    3.860\n",
      "| epoch  29 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.67 | ppl    14.47 | bpc    3.855\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| end of epoch  29 | time: 32.06s | valid loss  2.56 | valid ppl    13.00 | bpc    3.700\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |    50/  559 batches | lr 0.0001 | ms/batch 41.90 | loss  2.74 | ppl    15.54 | bpc    3.958\n",
      "| epoch  30 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.70 | ppl    14.87 | bpc    3.894\n",
      "| epoch  30 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.71 | ppl    15.05 | bpc    3.912\n",
      "| epoch  30 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.72 | ppl    15.24 | bpc    3.929\n",
      "| epoch  30 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.72 | ppl    15.21 | bpc    3.927\n",
      "| epoch  30 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.71 | ppl    15.08 | bpc    3.914\n",
      "| epoch  30 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.71 | ppl    15.05 | bpc    3.912\n",
      "| epoch  30 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.71 | ppl    15.04 | bpc    3.910\n",
      "| epoch  30 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    14.98 | bpc    3.905\n",
      "| epoch  30 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.70 | ppl    14.90 | bpc    3.898\n",
      "| epoch  30 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.69 | ppl    14.78 | bpc    3.885\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| end of epoch  30 | time: 32.00s | valid loss  2.58 | valid ppl    13.26 | bpc    3.729\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |    50/  559 batches | lr 0.0001 | ms/batch 40.91 | loss  2.76 | ppl    15.77 | bpc    3.979\n",
      "| epoch  31 |   100/  559 batches | lr 0.0001 | ms/batch 41.31 | loss  2.70 | ppl    14.92 | bpc    3.899\n",
      "| epoch  31 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.71 | ppl    15.04 | bpc    3.911\n",
      "| epoch  31 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.73 | ppl    15.31 | bpc    3.936\n",
      "| epoch  31 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.73 | ppl    15.32 | bpc    3.937\n",
      "| epoch  31 |   300/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.73 | ppl    15.37 | bpc    3.942\n",
      "| epoch  31 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.73 | ppl    15.35 | bpc    3.940\n",
      "| epoch  31 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.73 | ppl    15.35 | bpc    3.940\n",
      "| epoch  31 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.73 | ppl    15.32 | bpc    3.937\n",
      "| epoch  31 |   500/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.73 | ppl    15.29 | bpc    3.934\n",
      "| epoch  31 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.72 | ppl    15.21 | bpc    3.927\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| end of epoch  31 | time: 31.94s | valid loss  2.62 | valid ppl    13.72 | bpc    3.778\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |    50/  559 batches | lr 0.0001 | ms/batch 40.49 | loss  2.79 | ppl    16.33 | bpc    4.030\n",
      "| epoch  32 |   100/  559 batches | lr 0.0001 | ms/batch 41.39 | loss  2.74 | ppl    15.53 | bpc    3.957\n",
      "| epoch  32 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.75 | ppl    15.60 | bpc    3.963\n",
      "| epoch  32 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.75 | ppl    15.63 | bpc    3.966\n",
      "| epoch  32 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.75 | ppl    15.60 | bpc    3.963\n",
      "| epoch  32 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.74 | ppl    15.51 | bpc    3.955\n",
      "| epoch  32 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.74 | ppl    15.53 | bpc    3.957\n",
      "| epoch  32 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.75 | ppl    15.63 | bpc    3.966\n",
      "| epoch  32 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.75 | ppl    15.63 | bpc    3.966\n",
      "| epoch  32 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.75 | ppl    15.58 | bpc    3.962\n",
      "| epoch  32 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.74 | ppl    15.46 | bpc    3.950\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| end of epoch  32 | time: 31.92s | valid loss  2.61 | valid ppl    13.64 | bpc    3.770\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |    50/  559 batches | lr 0.0001 | ms/batch 39.91 | loss  2.79 | ppl    16.35 | bpc    4.031\n",
      "| epoch  33 |   100/  559 batches | lr 0.0001 | ms/batch 41.41 | loss  2.73 | ppl    15.33 | bpc    3.938\n",
      "| epoch  33 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.73 | ppl    15.27 | bpc    3.933\n",
      "| epoch  33 |   200/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.72 | ppl    15.21 | bpc    3.927\n",
      "| epoch  33 |   250/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.71 | ppl    15.03 | bpc    3.909\n",
      "| epoch  33 |   300/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.70 | ppl    14.89 | bpc    3.896\n",
      "| epoch  33 |   350/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.70 | ppl    14.84 | bpc    3.891\n",
      "| epoch  33 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.70 | ppl    14.81 | bpc    3.889\n",
      "| epoch  33 |   450/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.69 | ppl    14.76 | bpc    3.884\n",
      "| epoch  33 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.69 | ppl    14.72 | bpc    3.880\n",
      "| epoch  33 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.68 | ppl    14.59 | bpc    3.867\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| end of epoch  33 | time: 31.90s | valid loss  2.56 | valid ppl    12.97 | bpc    3.697\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |    50/  559 batches | lr 0.0001 | ms/batch 39.96 | loss  2.75 | ppl    15.57 | bpc    3.961\n",
      "| epoch  34 |   100/  559 batches | lr 0.0001 | ms/batch 41.33 | loss  2.69 | ppl    14.69 | bpc    3.877\n",
      "| epoch  34 |   150/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.69 | ppl    14.74 | bpc    3.881\n",
      "| epoch  34 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.69 | ppl    14.78 | bpc    3.886\n",
      "| epoch  34 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.69 | ppl    14.73 | bpc    3.881\n",
      "| epoch  34 |   300/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.72 | ppl    15.15 | bpc    3.921\n",
      "| epoch  34 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.80 | ppl    16.38 | bpc    4.034\n",
      "| epoch  34 |   400/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.89 | ppl    17.94 | bpc    4.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  34 |   450/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.97 | ppl    19.43 | bpc    4.280\n",
      "| epoch  34 |   500/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  3.04 | ppl    20.94 | bpc    4.388\n",
      "| epoch  34 |   550/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  3.04 | ppl    20.91 | bpc    4.386\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| end of epoch  34 | time: 31.90s | valid loss  2.91 | valid ppl    18.45 | bpc    4.205\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |    50/  559 batches | lr 0.0001 | ms/batch 40.40 | loss  3.07 | ppl    21.53 | bpc    4.429\n",
      "| epoch  35 |   100/  559 batches | lr 0.0001 | ms/batch 40.86 | loss  2.99 | ppl    19.79 | bpc    4.307\n",
      "| epoch  35 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.98 | ppl    19.60 | bpc    4.292\n",
      "| epoch  35 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.97 | ppl    19.40 | bpc    4.278\n",
      "| epoch  35 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.94 | ppl    18.89 | bpc    4.239\n",
      "| epoch  35 |   300/  559 batches | lr 0.0001 | ms/batch 41.94 | loss  2.91 | ppl    18.37 | bpc    4.199\n",
      "| epoch  35 |   350/  559 batches | lr 0.0001 | ms/batch 41.89 | loss  2.89 | ppl    17.95 | bpc    4.166\n",
      "| epoch  35 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.87 | ppl    17.62 | bpc    4.139\n",
      "| epoch  35 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.85 | ppl    17.28 | bpc    4.111\n",
      "| epoch  35 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.83 | ppl    17.01 | bpc    4.088\n",
      "| epoch  35 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.81 | ppl    16.63 | bpc    4.056\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 25\n",
      "| end of epoch  35 | time: 31.89s | valid loss  2.68 | valid ppl    14.60 | bpc    3.868\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |    50/  559 batches | lr 0.0001 | ms/batch 41.66 | loss  2.86 | ppl    17.45 | bpc    4.125\n",
      "| epoch  36 |   100/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.79 | ppl    16.25 | bpc    4.022\n",
      "| epoch  36 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.78 | ppl    16.14 | bpc    4.012\n",
      "| epoch  36 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.78 | ppl    16.06 | bpc    4.006\n",
      "| epoch  36 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.76 | ppl    15.83 | bpc    3.985\n",
      "| epoch  36 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.75 | ppl    15.61 | bpc    3.964\n",
      "| epoch  36 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.74 | ppl    15.47 | bpc    3.951\n",
      "| epoch  36 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.73 | ppl    15.40 | bpc    3.945\n",
      "| epoch  36 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.73 | ppl    15.27 | bpc    3.933\n",
      "| epoch  36 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.72 | ppl    15.17 | bpc    3.923\n",
      "| epoch  36 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.71 | ppl    14.97 | bpc    3.904\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 25\n",
      "| end of epoch  36 | time: 31.99s | valid loss  2.59 | valid ppl    13.29 | bpc    3.732\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |    50/  559 batches | lr 0.0001 | ms/batch 42.51 | loss  2.76 | ppl    15.80 | bpc    3.982\n",
      "| epoch  37 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.70 | ppl    14.87 | bpc    3.895\n",
      "| epoch  37 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.70 | ppl    14.86 | bpc    3.893\n",
      "| epoch  37 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.70 | ppl    14.83 | bpc    3.890\n",
      "| epoch  37 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.69 | ppl    14.68 | bpc    3.875\n",
      "| epoch  37 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.68 | ppl    14.52 | bpc    3.860\n",
      "| epoch  37 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.67 | ppl    14.45 | bpc    3.853\n",
      "| epoch  37 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.67 | ppl    14.44 | bpc    3.852\n",
      "| epoch  37 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.67 | ppl    14.37 | bpc    3.845\n",
      "| epoch  37 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.66 | ppl    14.29 | bpc    3.837\n",
      "| epoch  37 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.65 | ppl    14.17 | bpc    3.825\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.526626 --> 2.522299).  Saving model ...\n",
      "| end of epoch  37 | time: 32.07s | valid loss  2.52 | valid ppl    12.46 | bpc    3.639\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |    50/  559 batches | lr 0.0001 | ms/batch 40.29 | loss  2.71 | ppl    15.09 | bpc    3.916\n",
      "| epoch  38 |   100/  559 batches | lr 0.0001 | ms/batch 41.58 | loss  2.66 | ppl    14.28 | bpc    3.836\n",
      "| epoch  38 |   150/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.66 | ppl    14.25 | bpc    3.833\n",
      "| epoch  38 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.66 | ppl    14.27 | bpc    3.835\n",
      "| epoch  38 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.65 | ppl    14.13 | bpc    3.821\n",
      "| epoch  38 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.64 | ppl    14.01 | bpc    3.809\n",
      "| epoch  38 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.64 | ppl    13.99 | bpc    3.806\n",
      "| epoch  38 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.64 | ppl    14.01 | bpc    3.809\n",
      "| epoch  38 |   450/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.64 | ppl    14.01 | bpc    3.808\n",
      "| epoch  38 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.63 | ppl    13.94 | bpc    3.801\n",
      "| epoch  38 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.63 | ppl    13.86 | bpc    3.793\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.522299 --> 2.501104).  Saving model ...\n",
      "| end of epoch  38 | time: 31.95s | valid loss  2.50 | valid ppl    12.20 | bpc    3.608\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |    50/  559 batches | lr 0.0001 | ms/batch 39.98 | loss  2.69 | ppl    14.76 | bpc    3.883\n",
      "| epoch  39 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.64 | ppl    13.98 | bpc    3.806\n",
      "| epoch  39 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.64 | ppl    13.97 | bpc    3.804\n",
      "| epoch  39 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.64 | ppl    13.99 | bpc    3.806\n",
      "| epoch  39 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.63 | ppl    13.89 | bpc    3.796\n",
      "| epoch  39 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.62 | ppl    13.80 | bpc    3.787\n",
      "| epoch  39 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.63 | ppl    13.86 | bpc    3.793\n",
      "| epoch  39 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.63 | ppl    13.87 | bpc    3.794\n",
      "| epoch  39 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.63 | ppl    13.87 | bpc    3.794\n",
      "| epoch  39 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.63 | ppl    13.86 | bpc    3.793\n",
      "| epoch  39 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.62 | ppl    13.80 | bpc    3.787\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  39 | time: 31.90s | valid loss  2.51 | valid ppl    12.29 | bpc    3.620\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |    50/  559 batches | lr 0.0001 | ms/batch 41.14 | loss  2.68 | ppl    14.65 | bpc    3.873\n",
      "| epoch  40 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.63 | ppl    13.87 | bpc    3.794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  40 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.63 | ppl    13.94 | bpc    3.801\n",
      "| epoch  40 |   200/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.63 | ppl    13.90 | bpc    3.797\n",
      "| epoch  40 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.62 | ppl    13.80 | bpc    3.786\n",
      "| epoch  40 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.62 | ppl    13.70 | bpc    3.776\n",
      "| epoch  40 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.62 | ppl    13.70 | bpc    3.777\n",
      "| epoch  40 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.62 | ppl    13.74 | bpc    3.780\n",
      "| epoch  40 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.62 | ppl    13.75 | bpc    3.782\n",
      "| epoch  40 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.62 | ppl    13.73 | bpc    3.780\n",
      "| epoch  40 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.61 | ppl    13.67 | bpc    3.773\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.501104 --> 2.493998).  Saving model ...\n",
      "| end of epoch  40 | time: 31.99s | valid loss  2.49 | valid ppl    12.11 | bpc    3.598\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |    50/  559 batches | lr 0.0001 | ms/batch 41.54 | loss  2.68 | ppl    14.58 | bpc    3.866\n",
      "| epoch  41 |   100/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.63 | ppl    13.88 | bpc    3.795\n",
      "| epoch  41 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.64 | ppl    14.00 | bpc    3.807\n",
      "| epoch  41 |   200/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.64 | ppl    14.08 | bpc    3.816\n",
      "| epoch  41 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.64 | ppl    14.04 | bpc    3.811\n",
      "| epoch  41 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.64 | ppl    14.02 | bpc    3.809\n",
      "| epoch  41 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.65 | ppl    14.13 | bpc    3.820\n",
      "| epoch  41 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.65 | ppl    14.22 | bpc    3.830\n",
      "| epoch  41 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.66 | ppl    14.35 | bpc    3.843\n",
      "| epoch  41 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.67 | ppl    14.39 | bpc    3.847\n",
      "| epoch  41 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.66 | ppl    14.35 | bpc    3.843\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  41 | time: 31.98s | valid loss  2.55 | valid ppl    12.79 | bpc    3.677\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |    50/  559 batches | lr 0.0001 | ms/batch 39.65 | loss  2.73 | ppl    15.35 | bpc    3.940\n",
      "| epoch  42 |   100/  559 batches | lr 0.0001 | ms/batch 41.27 | loss  2.69 | ppl    14.74 | bpc    3.882\n",
      "| epoch  42 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.70 | ppl    14.95 | bpc    3.902\n",
      "| epoch  42 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.73 | ppl    15.28 | bpc    3.934\n",
      "| epoch  42 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.73 | ppl    15.33 | bpc    3.938\n",
      "| epoch  42 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.73 | ppl    15.29 | bpc    3.935\n",
      "| epoch  42 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.73 | ppl    15.30 | bpc    3.935\n",
      "| epoch  42 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.73 | ppl    15.31 | bpc    3.937\n",
      "| epoch  42 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.73 | ppl    15.26 | bpc    3.932\n",
      "| epoch  42 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.72 | ppl    15.11 | bpc    3.917\n",
      "| epoch  42 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.70 | ppl    14.93 | bpc    3.900\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| end of epoch  42 | time: 31.85s | valid loss  2.58 | valid ppl    13.15 | bpc    3.717\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |    50/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.76 | ppl    15.83 | bpc    3.985\n",
      "| epoch  43 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    14.99 | bpc    3.906\n",
      "| epoch  43 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    15.04 | bpc    3.910\n",
      "| epoch  43 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.72 | ppl    15.12 | bpc    3.918\n",
      "| epoch  43 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.71 | ppl    15.08 | bpc    3.914\n",
      "| epoch  43 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.71 | ppl    15.08 | bpc    3.914\n",
      "| epoch  43 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.72 | ppl    15.15 | bpc    3.921\n",
      "| epoch  43 |   400/  559 batches | lr 0.0001 | ms/batch 41.91 | loss  2.72 | ppl    15.18 | bpc    3.924\n",
      "| epoch  43 |   450/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.72 | ppl    15.18 | bpc    3.924\n",
      "| epoch  43 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    15.06 | bpc    3.913\n",
      "| epoch  43 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.70 | ppl    14.88 | bpc    3.895\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| end of epoch  43 | time: 32.00s | valid loss  2.58 | valid ppl    13.16 | bpc    3.719\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |    50/  559 batches | lr 0.0001 | ms/batch 42.59 | loss  2.75 | ppl    15.68 | bpc    3.971\n",
      "| epoch  44 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.69 | ppl    14.78 | bpc    3.885\n",
      "| epoch  44 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.69 | ppl    14.72 | bpc    3.880\n",
      "| epoch  44 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.69 | ppl    14.70 | bpc    3.878\n",
      "| epoch  44 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.67 | ppl    14.51 | bpc    3.859\n",
      "| epoch  44 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.67 | ppl    14.37 | bpc    3.845\n",
      "| epoch  44 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.66 | ppl    14.33 | bpc    3.841\n",
      "| epoch  44 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.66 | ppl    14.29 | bpc    3.837\n",
      "| epoch  44 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.66 | ppl    14.23 | bpc    3.831\n",
      "| epoch  44 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.65 | ppl    14.15 | bpc    3.823\n",
      "| epoch  44 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.64 | ppl    13.99 | bpc    3.807\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| end of epoch  44 | time: 32.03s | valid loss  2.52 | valid ppl    12.45 | bpc    3.639\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |    50/  559 batches | lr 0.0001 | ms/batch 39.90 | loss  2.69 | ppl    14.76 | bpc    3.884\n",
      "| epoch  45 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.64 | ppl    13.95 | bpc    3.802\n",
      "| epoch  45 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.63 | ppl    13.94 | bpc    3.801\n",
      "| epoch  45 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.63 | ppl    13.91 | bpc    3.798\n",
      "| epoch  45 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.62 | ppl    13.80 | bpc    3.787\n",
      "| epoch  45 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.61 | ppl    13.65 | bpc    3.770\n",
      "| epoch  45 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.61 | ppl    13.66 | bpc    3.771\n",
      "| epoch  45 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.61 | ppl    13.64 | bpc    3.770\n",
      "| epoch  45 |   450/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.61 | ppl    13.62 | bpc    3.767\n",
      "| epoch  45 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.61 | ppl    13.56 | bpc    3.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  45 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.60 | ppl    13.45 | bpc    3.749\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.493998 --> 2.475320).  Saving model ...\n",
      "| end of epoch  45 | time: 31.95s | valid loss  2.48 | valid ppl    11.89 | bpc    3.571\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |    50/  559 batches | lr 0.0001 | ms/batch 42.61 | loss  2.66 | ppl    14.26 | bpc    3.834\n",
      "| epoch  46 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.60 | ppl    13.51 | bpc    3.755\n",
      "| epoch  46 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.60 | ppl    13.51 | bpc    3.756\n",
      "| epoch  46 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.60 | ppl    13.49 | bpc    3.754\n",
      "| epoch  46 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.59 | ppl    13.37 | bpc    3.741\n",
      "| epoch  46 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.24 | bpc    3.727\n",
      "| epoch  46 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.58 | ppl    13.26 | bpc    3.729\n",
      "| epoch  46 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.59 | ppl    13.28 | bpc    3.732\n",
      "| epoch  46 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.59 | ppl    13.29 | bpc    3.733\n",
      "| epoch  46 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.58 | ppl    13.25 | bpc    3.728\n",
      "| epoch  46 |   550/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.58 | ppl    13.16 | bpc    3.718\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.475320 --> 2.453020).  Saving model ...\n",
      "| end of epoch  46 | time: 32.08s | valid loss  2.45 | valid ppl    11.62 | bpc    3.539\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |    50/  559 batches | lr 0.0001 | ms/batch 40.17 | loss  2.63 | ppl    13.94 | bpc    3.801\n",
      "| epoch  47 |   100/  559 batches | lr 0.0001 | ms/batch 41.70 | loss  2.58 | ppl    13.23 | bpc    3.725\n",
      "| epoch  47 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.58 | ppl    13.25 | bpc    3.728\n",
      "| epoch  47 |   200/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.59 | ppl    13.30 | bpc    3.733\n",
      "| epoch  47 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.18 | bpc    3.721\n",
      "| epoch  47 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.09 | bpc    3.711\n",
      "| epoch  47 |   350/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.57 | ppl    13.13 | bpc    3.715\n",
      "| epoch  47 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.58 | ppl    13.14 | bpc    3.716\n",
      "| epoch  47 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.58 | ppl    13.17 | bpc    3.719\n",
      "| epoch  47 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.58 | ppl    13.14 | bpc    3.716\n",
      "| epoch  47 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.57 | ppl    13.06 | bpc    3.707\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.453020 --> 2.438316).  Saving model ...\n",
      "| end of epoch  47 | time: 31.93s | valid loss  2.44 | valid ppl    11.45 | bpc    3.518\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |    50/  559 batches | lr 0.0001 | ms/batch 42.64 | loss  2.63 | ppl    13.88 | bpc    3.795\n",
      "| epoch  48 |   100/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.58 | ppl    13.18 | bpc    3.720\n",
      "| epoch  48 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.58 | ppl    13.20 | bpc    3.722\n",
      "| epoch  48 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.18 | bpc    3.720\n",
      "| epoch  48 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.11 | bpc    3.712\n",
      "| epoch  48 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.02 | bpc    3.702\n",
      "| epoch  48 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.05 | bpc    3.706\n",
      "| epoch  48 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.57 | ppl    13.07 | bpc    3.709\n",
      "| epoch  48 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.57 | ppl    13.13 | bpc    3.715\n",
      "| epoch  48 |   500/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.57 | ppl    13.09 | bpc    3.710\n",
      "| epoch  48 |   550/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.56 | ppl    13.00 | bpc    3.700\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  48 | time: 32.04s | valid loss  2.44 | valid ppl    11.46 | bpc    3.518\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |    50/  559 batches | lr 0.0001 | ms/batch 40.82 | loss  2.63 | ppl    13.86 | bpc    3.793\n",
      "| epoch  49 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.58 | ppl    13.18 | bpc    3.720\n",
      "| epoch  49 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.21 | bpc    3.724\n",
      "| epoch  49 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.24 | bpc    3.727\n",
      "| epoch  49 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.58 | ppl    13.18 | bpc    3.721\n",
      "| epoch  49 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.58 | ppl    13.15 | bpc    3.717\n",
      "| epoch  49 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.58 | ppl    13.21 | bpc    3.724\n",
      "| epoch  49 |   400/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.59 | ppl    13.29 | bpc    3.732\n",
      "| epoch  49 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.59 | ppl    13.36 | bpc    3.739\n",
      "| epoch  49 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.59 | ppl    13.33 | bpc    3.737\n",
      "| epoch  49 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.58 | ppl    13.22 | bpc    3.725\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| end of epoch  49 | time: 31.94s | valid loss  2.45 | valid ppl    11.54 | bpc    3.528\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |    50/  559 batches | lr 0.0001 | ms/batch 40.03 | loss  2.64 | ppl    14.03 | bpc    3.810\n",
      "| epoch  50 |   100/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.59 | ppl    13.36 | bpc    3.740\n",
      "| epoch  50 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.60 | ppl    13.45 | bpc    3.750\n",
      "| epoch  50 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.62 | ppl    13.76 | bpc    3.782\n",
      "| epoch  50 |   250/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.65 | ppl    14.13 | bpc    3.821\n",
      "| epoch  50 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.69 | ppl    14.66 | bpc    3.874\n",
      "| epoch  50 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.73 | ppl    15.35 | bpc    3.940\n",
      "| epoch  50 |   400/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.78 | ppl    16.06 | bpc    4.005\n",
      "| epoch  50 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.82 | ppl    16.75 | bpc    4.066\n",
      "| epoch  50 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.86 | ppl    17.42 | bpc    4.123\n",
      "| epoch  50 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.90 | ppl    18.18 | bpc    4.185\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| end of epoch  50 | time: 31.91s | valid loss  2.83 | valid ppl    16.98 | bpc    4.085\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |    50/  559 batches | lr 0.0001 | ms/batch 40.98 | loss  3.02 | ppl    20.50 | bpc    4.358\n",
      "| epoch  51 |   100/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.94 | ppl    18.99 | bpc    4.247\n",
      "| epoch  51 |   150/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.96 | ppl    19.21 | bpc    4.264\n",
      "| epoch  51 |   200/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.98 | ppl    19.64 | bpc    4.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  51 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.95 | ppl    19.18 | bpc    4.261\n",
      "| epoch  51 |   300/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.93 | ppl    18.77 | bpc    4.230\n",
      "| epoch  51 |   350/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.91 | ppl    18.41 | bpc    4.202\n",
      "| epoch  51 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.89 | ppl    17.97 | bpc    4.168\n",
      "| epoch  51 |   450/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.86 | ppl    17.49 | bpc    4.128\n",
      "| epoch  51 |   500/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.84 | ppl    17.12 | bpc    4.098\n",
      "| epoch  51 |   550/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.81 | ppl    16.67 | bpc    4.059\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| end of epoch  51 | time: 31.93s | valid loss  2.65 | valid ppl    14.20 | bpc    3.828\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |    50/  559 batches | lr 0.0001 | ms/batch 40.31 | loss  2.85 | ppl    17.37 | bpc    4.118\n",
      "| epoch  52 |   100/  559 batches | lr 0.0001 | ms/batch 41.47 | loss  2.78 | ppl    16.05 | bpc    4.005\n",
      "| epoch  52 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.76 | ppl    15.86 | bpc    3.988\n",
      "| epoch  52 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.75 | ppl    15.69 | bpc    3.972\n",
      "| epoch  52 |   250/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.73 | ppl    15.41 | bpc    3.946\n",
      "| epoch  52 |   300/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.72 | ppl    15.18 | bpc    3.924\n",
      "| epoch  52 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.71 | ppl    15.06 | bpc    3.913\n",
      "| epoch  52 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    14.99 | bpc    3.906\n",
      "| epoch  52 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.70 | ppl    14.87 | bpc    3.895\n",
      "| epoch  52 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.69 | ppl    14.77 | bpc    3.885\n",
      "| epoch  52 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.68 | ppl    14.56 | bpc    3.864\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| end of epoch  52 | time: 31.89s | valid loss  2.53 | valid ppl    12.55 | bpc    3.650\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |    50/  559 batches | lr 0.0001 | ms/batch 40.03 | loss  2.73 | ppl    15.32 | bpc    3.938\n",
      "| epoch  53 |   100/  559 batches | lr 0.0001 | ms/batch 41.68 | loss  2.67 | ppl    14.41 | bpc    3.849\n",
      "| epoch  53 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.66 | ppl    14.35 | bpc    3.843\n",
      "| epoch  53 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.66 | ppl    14.30 | bpc    3.838\n",
      "| epoch  53 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.65 | ppl    14.12 | bpc    3.819\n",
      "| epoch  53 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.64 | ppl    13.99 | bpc    3.806\n",
      "| epoch  53 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.63 | ppl    13.93 | bpc    3.800\n",
      "| epoch  53 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.63 | ppl    13.90 | bpc    3.797\n",
      "| epoch  53 |   450/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.63 | ppl    13.90 | bpc    3.797\n",
      "| epoch  53 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.63 | ppl    13.81 | bpc    3.788\n",
      "| epoch  53 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.62 | ppl    13.71 | bpc    3.777\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| end of epoch  53 | time: 31.90s | valid loss  2.47 | valid ppl    11.85 | bpc    3.567\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |    50/  559 batches | lr 0.0001 | ms/batch 40.08 | loss  2.67 | ppl    14.47 | bpc    3.855\n",
      "| epoch  54 |   100/  559 batches | lr 0.0001 | ms/batch 41.64 | loss  2.61 | ppl    13.66 | bpc    3.772\n",
      "| epoch  54 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.61 | ppl    13.65 | bpc    3.771\n",
      "| epoch  54 |   200/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.61 | ppl    13.63 | bpc    3.769\n",
      "| epoch  54 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.60 | ppl    13.52 | bpc    3.757\n",
      "| epoch  54 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.59 | ppl    13.39 | bpc    3.743\n",
      "| epoch  54 |   350/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.59 | ppl    13.38 | bpc    3.742\n",
      "| epoch  54 |   400/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.60 | ppl    13.42 | bpc    3.746\n",
      "| epoch  54 |   450/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.60 | ppl    13.41 | bpc    3.746\n",
      "| epoch  54 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.59 | ppl    13.35 | bpc    3.739\n",
      "| epoch  54 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.24 | bpc    3.727\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| end of epoch  54 | time: 31.89s | valid loss  2.45 | valid ppl    11.56 | bpc    3.531\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |    50/  559 batches | lr 0.0001 | ms/batch 41.48 | loss  2.64 | ppl    13.99 | bpc    3.807\n",
      "| epoch  55 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.25 | bpc    3.728\n",
      "| epoch  55 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.59 | ppl    13.28 | bpc    3.731\n",
      "| epoch  55 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.59 | ppl    13.29 | bpc    3.732\n",
      "| epoch  55 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.58 | ppl    13.21 | bpc    3.724\n",
      "| epoch  55 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.06 | bpc    3.707\n",
      "| epoch  55 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.08 | bpc    3.709\n",
      "| epoch  55 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.58 | ppl    13.14 | bpc    3.715\n",
      "| epoch  55 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.17 | bpc    3.719\n",
      "| epoch  55 |   500/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.58 | ppl    13.14 | bpc    3.716\n",
      "| epoch  55 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.05 | bpc    3.706\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.438316 --> 2.428364).  Saving model ...\n",
      "| end of epoch  55 | time: 32.02s | valid loss  2.43 | valid ppl    11.34 | bpc    3.503\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |    50/  559 batches | lr 0.0001 | ms/batch 40.54 | loss  2.62 | ppl    13.77 | bpc    3.784\n",
      "| epoch  56 |   100/  559 batches | lr 0.0001 | ms/batch 41.72 | loss  2.57 | ppl    13.08 | bpc    3.709\n",
      "| epoch  56 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.57 | ppl    13.07 | bpc    3.708\n",
      "| epoch  56 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.08 | bpc    3.710\n",
      "| epoch  56 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.56 | ppl    12.98 | bpc    3.698\n",
      "| epoch  56 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.55 | ppl    12.86 | bpc    3.685\n",
      "| epoch  56 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.56 | ppl    12.87 | bpc    3.686\n",
      "| epoch  56 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.56 | ppl    12.92 | bpc    3.691\n",
      "| epoch  56 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.56 | ppl    12.94 | bpc    3.693\n",
      "| epoch  56 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.56 | ppl    12.90 | bpc    3.690\n",
      "| epoch  56 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.55 | ppl    12.79 | bpc    3.677\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.428364 --> 2.407454).  Saving model ...\n",
      "| end of epoch  56 | time: 31.96s | valid loss  2.41 | valid ppl    11.11 | bpc    3.473\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  57 |    50/  559 batches | lr 0.0001 | ms/batch 42.58 | loss  2.61 | ppl    13.59 | bpc    3.765\n",
      "| epoch  57 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.56 | ppl    12.90 | bpc    3.690\n",
      "| epoch  57 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    12.95 | bpc    3.695\n",
      "| epoch  57 |   200/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.56 | ppl    12.95 | bpc    3.695\n",
      "| epoch  57 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.55 | ppl    12.86 | bpc    3.685\n",
      "| epoch  57 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.55 | ppl    12.74 | bpc    3.672\n",
      "| epoch  57 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.55 | ppl    12.78 | bpc    3.676\n",
      "| epoch  57 |   400/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.55 | ppl    12.81 | bpc    3.679\n",
      "| epoch  57 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.55 | ppl    12.83 | bpc    3.681\n",
      "| epoch  57 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.55 | ppl    12.77 | bpc    3.675\n",
      "| epoch  57 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.54 | ppl    12.71 | bpc    3.668\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.407454 --> 2.399010).  Saving model ...\n",
      "| end of epoch  57 | time: 32.08s | valid loss  2.40 | valid ppl    11.01 | bpc    3.461\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |    50/  559 batches | lr 0.0001 | ms/batch 39.43 | loss  2.60 | ppl    13.44 | bpc    3.748\n",
      "| epoch  58 |   100/  559 batches | lr 0.0001 | ms/batch 41.41 | loss  2.55 | ppl    12.75 | bpc    3.672\n",
      "| epoch  58 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.55 | ppl    12.79 | bpc    3.677\n",
      "| epoch  58 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.55 | ppl    12.80 | bpc    3.678\n",
      "| epoch  58 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.72 | bpc    3.670\n",
      "| epoch  58 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.53 | ppl    12.61 | bpc    3.657\n",
      "| epoch  58 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.53 | ppl    12.61 | bpc    3.657\n",
      "| epoch  58 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.64 | bpc    3.660\n",
      "| epoch  58 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.54 | ppl    12.66 | bpc    3.662\n",
      "| epoch  58 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.54 | ppl    12.63 | bpc    3.659\n",
      "| epoch  58 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.53 | ppl    12.52 | bpc    3.646\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.399010 --> 2.388937).  Saving model ...\n",
      "| end of epoch  58 | time: 31.91s | valid loss  2.39 | valid ppl    10.90 | bpc    3.447\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |    50/  559 batches | lr 0.0001 | ms/batch 39.86 | loss  2.59 | ppl    13.28 | bpc    3.732\n",
      "| epoch  59 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.54 | ppl    12.63 | bpc    3.659\n",
      "| epoch  59 |   150/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.54 | ppl    12.67 | bpc    3.663\n",
      "| epoch  59 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.54 | ppl    12.70 | bpc    3.666\n",
      "| epoch  59 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.62 | bpc    3.657\n",
      "| epoch  59 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.53 | bpc    3.648\n",
      "| epoch  59 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.53 | ppl    12.55 | bpc    3.649\n",
      "| epoch  59 |   400/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.54 | ppl    12.62 | bpc    3.658\n",
      "| epoch  59 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.54 | ppl    12.67 | bpc    3.663\n",
      "| epoch  59 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.63 | bpc    3.659\n",
      "| epoch  59 |   550/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.53 | ppl    12.54 | bpc    3.649\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.388937 --> 2.385533).  Saving model ...\n",
      "| end of epoch  59 | time: 31.95s | valid loss  2.39 | valid ppl    10.86 | bpc    3.442\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |    50/  559 batches | lr 0.0001 | ms/batch 42.40 | loss  2.59 | ppl    13.31 | bpc    3.734\n",
      "| epoch  60 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.63 | bpc    3.659\n",
      "| epoch  60 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.54 | ppl    12.66 | bpc    3.662\n",
      "| epoch  60 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.54 | ppl    12.70 | bpc    3.666\n",
      "| epoch  60 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.64 | bpc    3.660\n",
      "| epoch  60 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.52 | bpc    3.646\n",
      "| epoch  60 |   350/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.53 | ppl    12.58 | bpc    3.653\n",
      "| epoch  60 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.54 | ppl    12.62 | bpc    3.657\n",
      "| epoch  60 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.66 | bpc    3.663\n",
      "| epoch  60 |   500/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.53 | ppl    12.61 | bpc    3.657\n",
      "| epoch  60 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.55 | bpc    3.650\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  60 | time: 32.02s | valid loss  2.39 | valid ppl    10.87 | bpc    3.442\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  61 |    50/  559 batches | lr 0.0001 | ms/batch 39.87 | loss  2.58 | ppl    13.26 | bpc    3.729\n",
      "| epoch  61 |   100/  559 batches | lr 0.0001 | ms/batch 41.21 | loss  2.53 | ppl    12.60 | bpc    3.655\n",
      "| epoch  61 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.53 | ppl    12.62 | bpc    3.657\n",
      "| epoch  61 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.63 | bpc    3.658\n",
      "| epoch  61 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.57 | bpc    3.652\n",
      "| epoch  61 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.52 | ppl    12.47 | bpc    3.641\n",
      "| epoch  61 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.53 | ppl    12.49 | bpc    3.643\n",
      "| epoch  61 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.53 | bpc    3.647\n",
      "| epoch  61 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.53 | ppl    12.57 | bpc    3.652\n",
      "| epoch  61 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.54 | bpc    3.649\n",
      "| epoch  61 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.52 | ppl    12.45 | bpc    3.638\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.385533 --> 2.382624).  Saving model ...\n",
      "| end of epoch  61 | time: 31.91s | valid loss  2.38 | valid ppl    10.83 | bpc    3.437\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |    50/  559 batches | lr 0.0001 | ms/batch 41.61 | loss  2.58 | ppl    13.18 | bpc    3.720\n",
      "| epoch  62 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.56 | bpc    3.651\n",
      "| epoch  62 |   150/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.53 | ppl    12.58 | bpc    3.653\n",
      "| epoch  62 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.53 | ppl    12.60 | bpc    3.655\n",
      "| epoch  62 |   250/  559 batches | lr 0.0001 | ms/batch 41.88 | loss  2.53 | ppl    12.52 | bpc    3.646\n",
      "| epoch  62 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.52 | ppl    12.40 | bpc    3.633\n",
      "| epoch  62 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.52 | ppl    12.44 | bpc    3.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  62 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.53 | ppl    12.49 | bpc    3.643\n",
      "| epoch  62 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.53 | ppl    12.56 | bpc    3.651\n",
      "| epoch  62 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.53 | ppl    12.53 | bpc    3.648\n",
      "| epoch  62 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.52 | ppl    12.48 | bpc    3.641\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  62 | time: 32.00s | valid loss  2.39 | valid ppl    10.91 | bpc    3.447\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |    50/  559 batches | lr 0.0001 | ms/batch 39.88 | loss  2.58 | ppl    13.21 | bpc    3.723\n",
      "| epoch  63 |   100/  559 batches | lr 0.0001 | ms/batch 41.17 | loss  2.53 | ppl    12.57 | bpc    3.652\n",
      "| epoch  63 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.53 | ppl    12.59 | bpc    3.654\n",
      "| epoch  63 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.62 | bpc    3.657\n",
      "| epoch  63 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.53 | ppl    12.57 | bpc    3.651\n",
      "| epoch  63 |   300/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.52 | ppl    12.45 | bpc    3.638\n",
      "| epoch  63 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.53 | ppl    12.50 | bpc    3.644\n",
      "| epoch  63 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.53 | bpc    3.647\n",
      "| epoch  63 |   450/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.53 | ppl    12.57 | bpc    3.652\n",
      "| epoch  63 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.56 | bpc    3.651\n",
      "| epoch  63 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.53 | ppl    12.50 | bpc    3.643\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| end of epoch  63 | time: 31.87s | valid loss  2.40 | valid ppl    11.01 | bpc    3.461\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |    50/  559 batches | lr 0.0001 | ms/batch 40.79 | loss  2.58 | ppl    13.25 | bpc    3.727\n",
      "| epoch  64 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.64 | bpc    3.659\n",
      "| epoch  64 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.65 | bpc    3.661\n",
      "| epoch  64 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.54 | ppl    12.67 | bpc    3.663\n",
      "| epoch  64 |   250/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.53 | ppl    12.61 | bpc    3.657\n",
      "| epoch  64 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.53 | ppl    12.55 | bpc    3.649\n",
      "| epoch  64 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.57 | bpc    3.652\n",
      "| epoch  64 |   400/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.54 | ppl    12.64 | bpc    3.660\n",
      "| epoch  64 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.66 | bpc    3.662\n",
      "| epoch  64 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.64 | bpc    3.660\n",
      "| epoch  64 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.56 | bpc    3.651\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| end of epoch  64 | time: 31.95s | valid loss  2.40 | valid ppl    10.98 | bpc    3.457\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |    50/  559 batches | lr 0.0001 | ms/batch 42.00 | loss  2.59 | ppl    13.27 | bpc    3.730\n",
      "| epoch  65 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.54 | ppl    12.64 | bpc    3.660\n",
      "| epoch  65 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.66 | bpc    3.662\n",
      "| epoch  65 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.54 | ppl    12.74 | bpc    3.671\n",
      "| epoch  65 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.54 | ppl    12.69 | bpc    3.665\n",
      "| epoch  65 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.53 | ppl    12.61 | bpc    3.656\n",
      "| epoch  65 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.68 | bpc    3.664\n",
      "| epoch  65 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.55 | ppl    12.75 | bpc    3.673\n",
      "| epoch  65 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.55 | ppl    12.85 | bpc    3.684\n",
      "| epoch  65 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.55 | ppl    12.83 | bpc    3.681\n",
      "| epoch  65 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.55 | ppl    12.77 | bpc    3.675\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| end of epoch  65 | time: 32.01s | valid loss  2.41 | valid ppl    11.10 | bpc    3.473\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |    50/  559 batches | lr 0.0001 | ms/batch 41.38 | loss  2.61 | ppl    13.57 | bpc    3.763\n",
      "| epoch  66 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    12.97 | bpc    3.697\n",
      "| epoch  66 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.57 | ppl    13.11 | bpc    3.712\n",
      "| epoch  66 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.58 | ppl    13.19 | bpc    3.722\n",
      "| epoch  66 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.58 | ppl    13.18 | bpc    3.720\n",
      "| epoch  66 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.13 | bpc    3.715\n",
      "| epoch  66 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.58 | ppl    13.17 | bpc    3.720\n",
      "| epoch  66 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.22 | bpc    3.725\n",
      "| epoch  66 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.59 | ppl    13.29 | bpc    3.732\n",
      "| epoch  66 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.59 | ppl    13.31 | bpc    3.734\n",
      "| epoch  66 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.58 | ppl    13.25 | bpc    3.728\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| end of epoch  66 | time: 31.99s | valid loss  2.45 | valid ppl    11.59 | bpc    3.534\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |    50/  559 batches | lr 0.0001 | ms/batch 40.66 | loss  2.64 | ppl    14.05 | bpc    3.813\n",
      "| epoch  67 |   100/  559 batches | lr 0.0001 | ms/batch 41.49 | loss  2.59 | ppl    13.35 | bpc    3.739\n",
      "| epoch  67 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.59 | ppl    13.37 | bpc    3.741\n",
      "| epoch  67 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.59 | ppl    13.39 | bpc    3.743\n",
      "| epoch  67 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.59 | ppl    13.30 | bpc    3.733\n",
      "| epoch  67 |   300/  559 batches | lr 0.0001 | ms/batch 41.88 | loss  2.58 | ppl    13.17 | bpc    3.720\n",
      "| epoch  67 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.58 | ppl    13.19 | bpc    3.722\n",
      "| epoch  67 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.25 | bpc    3.728\n",
      "| epoch  67 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.59 | ppl    13.31 | bpc    3.734\n",
      "| epoch  67 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.60 | ppl    13.41 | bpc    3.745\n",
      "| epoch  67 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.61 | ppl    13.64 | bpc    3.770\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| end of epoch  67 | time: 31.94s | valid loss  2.48 | valid ppl    11.92 | bpc    3.575\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |    50/  559 batches | lr 0.0001 | ms/batch 40.96 | loss  2.69 | ppl    14.75 | bpc    3.882\n",
      "| epoch  68 |   100/  559 batches | lr 0.0001 | ms/batch 40.97 | loss  2.67 | ppl    14.45 | bpc    3.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  68 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.71 | ppl    14.98 | bpc    3.905\n",
      "| epoch  68 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.75 | ppl    15.60 | bpc    3.964\n",
      "| epoch  68 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.76 | ppl    15.83 | bpc    3.985\n",
      "| epoch  68 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.76 | ppl    15.79 | bpc    3.981\n",
      "| epoch  68 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.76 | ppl    15.77 | bpc    3.979\n",
      "| epoch  68 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.76 | ppl    15.78 | bpc    3.980\n",
      "| epoch  68 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.76 | ppl    15.78 | bpc    3.980\n",
      "| epoch  68 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.77 | ppl    16.04 | bpc    4.003\n",
      "| epoch  68 |   550/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.78 | ppl    16.08 | bpc    4.007\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| end of epoch  68 | time: 31.91s | valid loss  2.64 | valid ppl    13.96 | bpc    3.803\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |    50/  559 batches | lr 0.0001 | ms/batch 41.09 | loss  2.84 | ppl    17.18 | bpc    4.102\n",
      "| epoch  69 |   100/  559 batches | lr 0.0001 | ms/batch 41.54 | loss  2.79 | ppl    16.23 | bpc    4.021\n",
      "| epoch  69 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.78 | ppl    16.16 | bpc    4.015\n",
      "| epoch  69 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.78 | ppl    16.14 | bpc    4.013\n",
      "| epoch  69 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.77 | ppl    16.02 | bpc    4.002\n",
      "| epoch  69 |   300/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.77 | ppl    15.91 | bpc    3.992\n",
      "| epoch  69 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.76 | ppl    15.76 | bpc    3.978\n",
      "| epoch  69 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.75 | ppl    15.67 | bpc    3.970\n",
      "| epoch  69 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.74 | ppl    15.45 | bpc    3.949\n",
      "| epoch  69 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.73 | ppl    15.26 | bpc    3.932\n",
      "| epoch  69 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.71 | ppl    14.99 | bpc    3.906\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 25\n",
      "| end of epoch  69 | time: 31.95s | valid loss  2.56 | valid ppl    12.97 | bpc    3.698\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |    50/  559 batches | lr 0.0001 | ms/batch 41.40 | loss  2.75 | ppl    15.68 | bpc    3.971\n",
      "| epoch  70 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.69 | ppl    14.72 | bpc    3.880\n",
      "| epoch  70 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.68 | ppl    14.62 | bpc    3.870\n",
      "| epoch  70 |   200/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.68 | ppl    14.53 | bpc    3.860\n",
      "| epoch  70 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.66 | ppl    14.34 | bpc    3.842\n",
      "| epoch  70 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.65 | ppl    14.13 | bpc    3.821\n",
      "| epoch  70 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.64 | ppl    14.07 | bpc    3.814\n",
      "| epoch  70 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.64 | ppl    14.07 | bpc    3.814\n",
      "| epoch  70 |   450/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.64 | ppl    14.00 | bpc    3.807\n",
      "| epoch  70 |   500/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.63 | ppl    13.92 | bpc    3.799\n",
      "| epoch  70 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.63 | ppl    13.81 | bpc    3.788\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 25\n",
      "| end of epoch  70 | time: 31.96s | valid loss  2.48 | valid ppl    11.96 | bpc    3.581\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  71 |    50/  559 batches | lr 0.0001 | ms/batch 41.41 | loss  2.68 | ppl    14.58 | bpc    3.866\n",
      "| epoch  71 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.62 | ppl    13.80 | bpc    3.786\n",
      "| epoch  71 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.62 | ppl    13.77 | bpc    3.784\n",
      "| epoch  71 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.62 | ppl    13.76 | bpc    3.782\n",
      "| epoch  71 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.61 | ppl    13.65 | bpc    3.771\n",
      "| epoch  71 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.60 | ppl    13.49 | bpc    3.754\n",
      "| epoch  71 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.60 | ppl    13.46 | bpc    3.751\n",
      "| epoch  71 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.60 | ppl    13.45 | bpc    3.750\n",
      "| epoch  71 |   450/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.60 | ppl    13.45 | bpc    3.749\n",
      "| epoch  71 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.59 | ppl    13.35 | bpc    3.739\n",
      "| epoch  71 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.58 | ppl    13.23 | bpc    3.726\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 25\n",
      "| end of epoch  71 | time: 31.98s | valid loss  2.45 | valid ppl    11.54 | bpc    3.528\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |    50/  559 batches | lr 0.0001 | ms/batch 40.24 | loss  2.63 | ppl    13.94 | bpc    3.801\n",
      "| epoch  72 |   100/  559 batches | lr 0.0001 | ms/batch 41.36 | loss  2.58 | ppl    13.23 | bpc    3.726\n",
      "| epoch  72 |   150/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.58 | ppl    13.23 | bpc    3.726\n",
      "| epoch  72 |   200/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.58 | ppl    13.25 | bpc    3.728\n",
      "| epoch  72 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.17 | bpc    3.719\n",
      "| epoch  72 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.08 | bpc    3.710\n",
      "| epoch  72 |   350/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.57 | ppl    13.12 | bpc    3.714\n",
      "| epoch  72 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.58 | ppl    13.18 | bpc    3.721\n",
      "| epoch  72 |   450/  559 batches | lr 0.0001 | ms/batch 41.74 | loss  2.58 | ppl    13.19 | bpc    3.722\n",
      "| epoch  72 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.11 | bpc    3.712\n",
      "| epoch  72 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.57 | ppl    13.03 | bpc    3.704\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 11 out of 25\n",
      "| end of epoch  72 | time: 31.88s | valid loss  2.43 | valid ppl    11.32 | bpc    3.501\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 |    50/  559 batches | lr 0.0001 | ms/batch 40.32 | loss  2.62 | ppl    13.80 | bpc    3.786\n",
      "| epoch  73 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.57 | ppl    13.10 | bpc    3.712\n",
      "| epoch  73 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.58 | ppl    13.13 | bpc    3.715\n",
      "| epoch  73 |   200/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.58 | ppl    13.17 | bpc    3.719\n",
      "| epoch  73 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.58 | ppl    13.13 | bpc    3.715\n",
      "| epoch  73 |   300/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.57 | ppl    13.00 | bpc    3.701\n",
      "| epoch  73 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.57 | ppl    13.03 | bpc    3.703\n",
      "| epoch  73 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.57 | ppl    13.06 | bpc    3.707\n",
      "| epoch  73 |   450/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.57 | ppl    13.12 | bpc    3.714\n",
      "| epoch  73 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.07 | bpc    3.709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  73 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    12.96 | bpc    3.696\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 12 out of 25\n",
      "| end of epoch  73 | time: 31.93s | valid loss  2.42 | valid ppl    11.26 | bpc    3.493\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |    50/  559 batches | lr 0.0001 | ms/batch 40.47 | loss  2.62 | ppl    13.70 | bpc    3.776\n",
      "| epoch  74 |   100/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.56 | ppl    13.00 | bpc    3.700\n",
      "| epoch  74 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.00 | bpc    3.701\n",
      "| epoch  74 |   200/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.57 | ppl    13.02 | bpc    3.703\n",
      "| epoch  74 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.56 | ppl    12.94 | bpc    3.694\n",
      "| epoch  74 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.55 | ppl    12.83 | bpc    3.682\n",
      "| epoch  74 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.55 | ppl    12.83 | bpc    3.682\n",
      "| epoch  74 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.56 | ppl    12.89 | bpc    3.688\n",
      "| epoch  74 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.56 | ppl    12.88 | bpc    3.687\n",
      "| epoch  74 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.55 | ppl    12.82 | bpc    3.680\n",
      "| epoch  74 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.73 | bpc    3.670\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 13 out of 25\n",
      "| end of epoch  74 | time: 31.93s | valid loss  2.40 | valid ppl    11.04 | bpc    3.465\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |    50/  559 batches | lr 0.0001 | ms/batch 40.85 | loss  2.60 | ppl    13.43 | bpc    3.747\n",
      "| epoch  75 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.74 | bpc    3.672\n",
      "| epoch  75 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.55 | ppl    12.78 | bpc    3.676\n",
      "| epoch  75 |   200/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.55 | ppl    12.77 | bpc    3.675\n",
      "| epoch  75 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.54 | ppl    12.72 | bpc    3.669\n",
      "| epoch  75 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.53 | ppl    12.58 | bpc    3.653\n",
      "| epoch  75 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.53 | ppl    12.59 | bpc    3.654\n",
      "| epoch  75 |   400/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.54 | ppl    12.64 | bpc    3.660\n",
      "| epoch  75 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.54 | ppl    12.65 | bpc    3.661\n",
      "| epoch  75 |   500/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.53 | ppl    12.60 | bpc    3.655\n",
      "| epoch  75 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.52 | ppl    12.48 | bpc    3.642\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.382624 --> 2.381958).  Saving model ...\n",
      "| end of epoch  75 | time: 31.98s | valid loss  2.38 | valid ppl    10.83 | bpc    3.436\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |    50/  559 batches | lr 0.0001 | ms/batch 39.83 | loss  2.58 | ppl    13.15 | bpc    3.717\n",
      "| epoch  76 |   100/  559 batches | lr 0.0001 | ms/batch 40.47 | loss  2.53 | ppl    12.52 | bpc    3.646\n",
      "| epoch  76 |   150/  559 batches | lr 0.0001 | ms/batch 40.99 | loss  2.53 | ppl    12.54 | bpc    3.648\n",
      "| epoch  76 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.53 | ppl    12.51 | bpc    3.645\n",
      "| epoch  76 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.52 | ppl    12.43 | bpc    3.636\n",
      "| epoch  76 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.51 | ppl    12.32 | bpc    3.623\n",
      "| epoch  76 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.51 | ppl    12.34 | bpc    3.625\n",
      "| epoch  76 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.52 | ppl    12.40 | bpc    3.632\n",
      "| epoch  76 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.52 | ppl    12.41 | bpc    3.633\n",
      "| epoch  76 |   500/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.52 | ppl    12.37 | bpc    3.629\n",
      "| epoch  76 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.51 | ppl    12.27 | bpc    3.617\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.381958 --> 2.361682).  Saving model ...\n",
      "| end of epoch  76 | time: 31.85s | valid loss  2.36 | valid ppl    10.61 | bpc    3.407\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |    50/  559 batches | lr 0.0001 | ms/batch 39.53 | loss  2.56 | ppl    12.97 | bpc    3.697\n",
      "| epoch  77 |   100/  559 batches | lr 0.0001 | ms/batch 41.39 | loss  2.51 | ppl    12.35 | bpc    3.626\n",
      "| epoch  77 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.51 | ppl    12.36 | bpc    3.628\n",
      "| epoch  77 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.52 | ppl    12.37 | bpc    3.629\n",
      "| epoch  77 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.51 | ppl    12.33 | bpc    3.624\n",
      "| epoch  77 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.50 | ppl    12.20 | bpc    3.608\n",
      "| epoch  77 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.50 | ppl    12.22 | bpc    3.612\n",
      "| epoch  77 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.51 | ppl    12.29 | bpc    3.619\n",
      "| epoch  77 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.51 | ppl    12.35 | bpc    3.626\n",
      "| epoch  77 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.51 | ppl    12.31 | bpc    3.622\n",
      "| epoch  77 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.50 | ppl    12.21 | bpc    3.610\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.361682 --> 2.354683).  Saving model ...\n",
      "| end of epoch  77 | time: 31.90s | valid loss  2.35 | valid ppl    10.53 | bpc    3.397\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |    50/  559 batches | lr 0.0001 | ms/batch 42.52 | loss  2.56 | ppl    12.89 | bpc    3.688\n",
      "| epoch  78 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.51 | ppl    12.28 | bpc    3.618\n",
      "| epoch  78 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.51 | ppl    12.32 | bpc    3.623\n",
      "| epoch  78 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.51 | ppl    12.33 | bpc    3.624\n",
      "| epoch  78 |   250/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.51 | ppl    12.26 | bpc    3.616\n",
      "| epoch  78 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.50 | ppl    12.15 | bpc    3.603\n",
      "| epoch  78 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.50 | ppl    12.15 | bpc    3.603\n",
      "| epoch  78 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.50 | ppl    12.21 | bpc    3.610\n",
      "| epoch  78 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.51 | ppl    12.28 | bpc    3.618\n",
      "| epoch  78 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.51 | ppl    12.24 | bpc    3.614\n",
      "| epoch  78 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.50 | ppl    12.13 | bpc    3.601\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.354683 --> 2.345141).  Saving model ...\n",
      "| end of epoch  78 | time: 32.09s | valid loss  2.35 | valid ppl    10.43 | bpc    3.383\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |    50/  559 batches | lr 0.0001 | ms/batch 42.01 | loss  2.55 | ppl    12.84 | bpc    3.683\n",
      "| epoch  79 |   100/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.51 | ppl    12.25 | bpc    3.614\n",
      "| epoch  79 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.51 | ppl    12.30 | bpc    3.620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  79 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.51 | ppl    12.32 | bpc    3.623\n",
      "| epoch  79 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.51 | ppl    12.28 | bpc    3.619\n",
      "| epoch  79 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.50 | ppl    12.18 | bpc    3.606\n",
      "| epoch  79 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.50 | ppl    12.20 | bpc    3.608\n",
      "| epoch  79 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.51 | ppl    12.27 | bpc    3.617\n",
      "| epoch  79 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.51 | ppl    12.33 | bpc    3.624\n",
      "| epoch  79 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.51 | ppl    12.29 | bpc    3.619\n",
      "| epoch  79 |   550/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.51 | ppl    12.25 | bpc    3.615\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  79 | time: 32.01s | valid loss  2.35 | valid ppl    10.52 | bpc    3.395\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |    50/  559 batches | lr 0.0001 | ms/batch 40.13 | loss  2.57 | ppl    13.01 | bpc    3.702\n",
      "| epoch  80 |   100/  559 batches | lr 0.0001 | ms/batch 41.67 | loss  2.52 | ppl    12.46 | bpc    3.639\n",
      "| epoch  80 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.51 | bpc    3.644\n",
      "| epoch  80 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.53 | ppl    12.59 | bpc    3.654\n",
      "| epoch  80 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.58 | bpc    3.653\n",
      "| epoch  80 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.53 | ppl    12.56 | bpc    3.651\n",
      "| epoch  80 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.67 | bpc    3.663\n",
      "| epoch  80 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.55 | ppl    12.76 | bpc    3.674\n",
      "| epoch  80 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.56 | ppl    12.92 | bpc    3.691\n",
      "| epoch  80 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.56 | ppl    12.95 | bpc    3.694\n",
      "| epoch  80 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.56 | ppl    12.92 | bpc    3.691\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| end of epoch  80 | time: 31.92s | valid loss  2.40 | valid ppl    10.99 | bpc    3.458\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  81 |    50/  559 batches | lr 0.0001 | ms/batch 42.65 | loss  2.62 | ppl    13.68 | bpc    3.774\n",
      "| epoch  81 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.57 | ppl    13.04 | bpc    3.704\n",
      "| epoch  81 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.57 | ppl    13.03 | bpc    3.704\n",
      "| epoch  81 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.05 | bpc    3.706\n",
      "| epoch  81 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.57 | ppl    13.04 | bpc    3.704\n",
      "| epoch  81 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.56 | ppl    12.91 | bpc    3.690\n",
      "| epoch  81 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    12.94 | bpc    3.693\n",
      "| epoch  81 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.56 | ppl    13.00 | bpc    3.700\n",
      "| epoch  81 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.04 | bpc    3.705\n",
      "| epoch  81 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.56 | ppl    12.98 | bpc    3.698\n",
      "| epoch  81 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    12.90 | bpc    3.689\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| end of epoch  81 | time: 32.05s | valid loss  2.40 | valid ppl    11.04 | bpc    3.465\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |    50/  559 batches | lr 0.0001 | ms/batch 40.20 | loss  2.61 | ppl    13.62 | bpc    3.767\n",
      "| epoch  82 |   100/  559 batches | lr 0.0001 | ms/batch 41.71 | loss  2.56 | ppl    12.95 | bpc    3.695\n",
      "| epoch  82 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    13.00 | bpc    3.700\n",
      "| epoch  82 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.57 | ppl    13.03 | bpc    3.703\n",
      "| epoch  82 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.56 | ppl    12.94 | bpc    3.693\n",
      "| epoch  82 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.55 | ppl    12.80 | bpc    3.678\n",
      "| epoch  82 |   350/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.55 | ppl    12.77 | bpc    3.675\n",
      "| epoch  82 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.55 | ppl    12.81 | bpc    3.680\n",
      "| epoch  82 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.55 | ppl    12.80 | bpc    3.679\n",
      "| epoch  82 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.55 | ppl    12.77 | bpc    3.675\n",
      "| epoch  82 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.54 | ppl    12.64 | bpc    3.659\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| end of epoch  82 | time: 31.92s | valid loss  2.39 | valid ppl    10.93 | bpc    3.450\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |    50/  559 batches | lr 0.0001 | ms/batch 40.20 | loss  2.59 | ppl    13.33 | bpc    3.737\n",
      "| epoch  83 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.54 | ppl    12.67 | bpc    3.664\n",
      "| epoch  83 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.54 | ppl    12.67 | bpc    3.663\n",
      "| epoch  83 |   200/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.54 | ppl    12.68 | bpc    3.665\n",
      "| epoch  83 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.53 | ppl    12.61 | bpc    3.656\n",
      "| epoch  83 |   300/  559 batches | lr 0.0001 | ms/batch 41.87 | loss  2.53 | ppl    12.53 | bpc    3.647\n",
      "| epoch  83 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.52 | bpc    3.646\n",
      "| epoch  83 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.53 | ppl    12.55 | bpc    3.650\n",
      "| epoch  83 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.54 | ppl    12.62 | bpc    3.657\n",
      "| epoch  83 |   500/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.53 | ppl    12.55 | bpc    3.649\n",
      "| epoch  83 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.52 | ppl    12.46 | bpc    3.639\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| end of epoch  83 | time: 31.93s | valid loss  2.37 | valid ppl    10.75 | bpc    3.426\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |    50/  559 batches | lr 0.0001 | ms/batch 40.25 | loss  2.58 | ppl    13.16 | bpc    3.718\n",
      "| epoch  84 |   100/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.52 | bpc    3.646\n",
      "| epoch  84 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.53 | ppl    12.50 | bpc    3.644\n",
      "| epoch  84 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.52 | ppl    12.49 | bpc    3.642\n",
      "| epoch  84 |   250/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.52 | ppl    12.41 | bpc    3.634\n",
      "| epoch  84 |   300/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.51 | ppl    12.29 | bpc    3.620\n",
      "| epoch  84 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.51 | ppl    12.30 | bpc    3.620\n",
      "| epoch  84 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.51 | ppl    12.34 | bpc    3.626\n",
      "| epoch  84 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.52 | ppl    12.39 | bpc    3.631\n",
      "| epoch  84 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.51 | ppl    12.30 | bpc    3.621\n",
      "| epoch  84 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.50 | ppl    12.17 | bpc    3.605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| end of epoch  84 | time: 31.92s | valid loss  2.35 | valid ppl    10.47 | bpc    3.389\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 |    50/  559 batches | lr 0.0001 | ms/batch 40.69 | loss  2.55 | ppl    12.85 | bpc    3.683\n",
      "| epoch  85 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.50 | ppl    12.23 | bpc    3.612\n",
      "| epoch  85 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.51 | ppl    12.25 | bpc    3.615\n",
      "| epoch  85 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.50 | ppl    12.23 | bpc    3.612\n",
      "| epoch  85 |   250/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.50 | ppl    12.18 | bpc    3.606\n",
      "| epoch  85 |   300/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.49 | ppl    12.06 | bpc    3.592\n",
      "| epoch  85 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.49 | ppl    12.12 | bpc    3.599\n",
      "| epoch  85 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.49 | ppl    12.12 | bpc    3.599\n",
      "| epoch  85 |   450/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.50 | ppl    12.17 | bpc    3.605\n",
      "| epoch  85 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.49 | ppl    12.10 | bpc    3.597\n",
      "| epoch  85 |   550/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.49 | ppl    12.01 | bpc    3.587\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.345141 --> 2.335071).  Saving model ...\n",
      "| end of epoch  85 | time: 32.01s | valid loss  2.34 | valid ppl    10.33 | bpc    3.369\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |    50/  559 batches | lr 0.0001 | ms/batch 39.45 | loss  2.54 | ppl    12.70 | bpc    3.666\n",
      "| epoch  86 |   100/  559 batches | lr 0.0001 | ms/batch 41.43 | loss  2.49 | ppl    12.09 | bpc    3.596\n",
      "| epoch  86 |   150/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.49 | ppl    12.12 | bpc    3.599\n",
      "| epoch  86 |   200/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.49 | ppl    12.12 | bpc    3.599\n",
      "| epoch  86 |   250/  559 batches | lr 0.0001 | ms/batch 41.73 | loss  2.49 | ppl    12.06 | bpc    3.593\n",
      "| epoch  86 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.48 | ppl    11.95 | bpc    3.579\n",
      "| epoch  86 |   350/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.48 | ppl    11.96 | bpc    3.581\n",
      "| epoch  86 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.48 | ppl    11.99 | bpc    3.583\n",
      "| epoch  86 |   450/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.49 | ppl    12.03 | bpc    3.589\n",
      "| epoch  86 |   500/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.48 | ppl    12.00 | bpc    3.585\n",
      "| epoch  86 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.48 | ppl    11.90 | bpc    3.572\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.335071 --> 2.321047).  Saving model ...\n",
      "| end of epoch  86 | time: 31.89s | valid loss  2.32 | valid ppl    10.19 | bpc    3.349\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |    50/  559 batches | lr 0.0001 | ms/batch 39.93 | loss  2.53 | ppl    12.60 | bpc    3.655\n",
      "| epoch  87 |   100/  559 batches | lr 0.0001 | ms/batch 41.43 | loss  2.48 | ppl    12.00 | bpc    3.585\n",
      "| epoch  87 |   150/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.49 | ppl    12.03 | bpc    3.589\n",
      "| epoch  87 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.49 | ppl    12.03 | bpc    3.589\n",
      "| epoch  87 |   250/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.48 | ppl    12.00 | bpc    3.585\n",
      "| epoch  87 |   300/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.47 | ppl    11.88 | bpc    3.570\n",
      "| epoch  87 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.48 | ppl    11.91 | bpc    3.574\n",
      "| epoch  87 |   400/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.48 | ppl    11.96 | bpc    3.580\n",
      "| epoch  87 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.49 | ppl    12.00 | bpc    3.585\n",
      "| epoch  87 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.48 | ppl    11.94 | bpc    3.578\n",
      "| epoch  87 |   550/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.47 | ppl    11.86 | bpc    3.568\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.321047 --> 2.312335).  Saving model ...\n",
      "| end of epoch  87 | time: 31.94s | valid loss  2.31 | valid ppl    10.10 | bpc    3.336\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |    50/  559 batches | lr 0.0001 | ms/batch 40.26 | loss  2.53 | ppl    12.54 | bpc    3.649\n",
      "| epoch  88 |   100/  559 batches | lr 0.0001 | ms/batch 40.89 | loss  2.48 | ppl    11.96 | bpc    3.581\n",
      "| epoch  88 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.48 | ppl    11.99 | bpc    3.583\n",
      "| epoch  88 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.49 | ppl    12.00 | bpc    3.585\n",
      "| epoch  88 |   250/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.48 | ppl    11.93 | bpc    3.576\n",
      "| epoch  88 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.47 | ppl    11.80 | bpc    3.561\n",
      "| epoch  88 |   350/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.47 | ppl    11.82 | bpc    3.563\n",
      "| epoch  88 |   400/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.47 | ppl    11.86 | bpc    3.568\n",
      "| epoch  88 |   450/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.48 | ppl    11.91 | bpc    3.574\n",
      "| epoch  88 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.47 | ppl    11.84 | bpc    3.566\n",
      "| epoch  88 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.76 | bpc    3.556\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.312335 --> 2.307129).  Saving model ...\n",
      "| end of epoch  88 | time: 31.93s | valid loss  2.31 | valid ppl    10.05 | bpc    3.328\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |    50/  559 batches | lr 0.0001 | ms/batch 39.17 | loss  2.52 | ppl    12.41 | bpc    3.634\n",
      "| epoch  89 |   100/  559 batches | lr 0.0001 | ms/batch 40.74 | loss  2.47 | ppl    11.85 | bpc    3.567\n",
      "| epoch  89 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.47 | ppl    11.83 | bpc    3.565\n",
      "| epoch  89 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.47 | ppl    11.85 | bpc    3.567\n",
      "| epoch  89 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.47 | ppl    11.79 | bpc    3.559\n",
      "| epoch  89 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.66 | bpc    3.543\n",
      "| epoch  89 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.46 | ppl    11.68 | bpc    3.546\n",
      "| epoch  89 |   400/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.46 | ppl    11.72 | bpc    3.551\n",
      "| epoch  89 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.47 | ppl    11.79 | bpc    3.559\n",
      "| epoch  89 |   500/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.46 | ppl    11.70 | bpc    3.549\n",
      "| epoch  89 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.45 | ppl    11.65 | bpc    3.542\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.307129 --> 2.294201).  Saving model ...\n",
      "| end of epoch  89 | time: 31.86s | valid loss  2.29 | valid ppl     9.92 | bpc    3.310\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |    50/  559 batches | lr 0.0001 | ms/batch 42.51 | loss  2.51 | ppl    12.29 | bpc    3.619\n",
      "| epoch  90 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.46 | ppl    11.73 | bpc    3.553\n",
      "| epoch  90 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.46 | ppl    11.75 | bpc    3.555\n",
      "| epoch  90 |   200/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.46 | ppl    11.76 | bpc    3.556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  90 |   250/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.46 | ppl    11.72 | bpc    3.551\n",
      "| epoch  90 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.45 | ppl    11.60 | bpc    3.537\n",
      "| epoch  90 |   350/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.45 | ppl    11.63 | bpc    3.539\n",
      "| epoch  90 |   400/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.46 | ppl    11.65 | bpc    3.542\n",
      "| epoch  90 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.73 | bpc    3.552\n",
      "| epoch  90 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.46 | ppl    11.66 | bpc    3.543\n",
      "| epoch  90 |   550/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.45 | ppl    11.59 | bpc    3.535\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.294201 --> 2.285452).  Saving model ...\n",
      "| end of epoch  90 | time: 32.08s | valid loss  2.29 | valid ppl     9.83 | bpc    3.297\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  91 |    50/  559 batches | lr 0.0001 | ms/batch 40.26 | loss  2.50 | ppl    12.22 | bpc    3.611\n",
      "| epoch  91 |   100/  559 batches | lr 0.0001 | ms/batch 41.55 | loss  2.46 | ppl    11.65 | bpc    3.542\n",
      "| epoch  91 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.46 | ppl    11.69 | bpc    3.547\n",
      "| epoch  91 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.46 | ppl    11.70 | bpc    3.548\n",
      "| epoch  91 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.45 | ppl    11.64 | bpc    3.541\n",
      "| epoch  91 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.45 | ppl    11.56 | bpc    3.531\n",
      "| epoch  91 |   350/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.45 | ppl    11.57 | bpc    3.532\n",
      "| epoch  91 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.45 | ppl    11.63 | bpc    3.540\n",
      "| epoch  91 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.70 | bpc    3.549\n",
      "| epoch  91 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.46 | ppl    11.66 | bpc    3.543\n",
      "| epoch  91 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.45 | ppl    11.58 | bpc    3.534\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.285452 --> 2.278203).  Saving model ...\n",
      "| end of epoch  91 | time: 31.96s | valid loss  2.28 | valid ppl     9.76 | bpc    3.287\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |    50/  559 batches | lr 0.0001 | ms/batch 42.44 | loss  2.51 | ppl    12.25 | bpc    3.615\n",
      "| epoch  92 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.46 | ppl    11.70 | bpc    3.549\n",
      "| epoch  92 |   150/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.46 | ppl    11.74 | bpc    3.553\n",
      "| epoch  92 |   200/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.47 | ppl    11.77 | bpc    3.557\n",
      "| epoch  92 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.71 | bpc    3.550\n",
      "| epoch  92 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.45 | ppl    11.60 | bpc    3.536\n",
      "| epoch  92 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.45 | ppl    11.63 | bpc    3.540\n",
      "| epoch  92 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.67 | bpc    3.545\n",
      "| epoch  92 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.72 | bpc    3.551\n",
      "| epoch  92 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.67 | bpc    3.545\n",
      "| epoch  92 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.45 | ppl    11.60 | bpc    3.536\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch  92 | time: 32.05s | valid loss  2.28 | valid ppl     9.82 | bpc    3.296\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |    50/  559 batches | lr 0.0001 | ms/batch 41.06 | loss  2.51 | ppl    12.26 | bpc    3.616\n",
      "| epoch  93 |   100/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.46 | ppl    11.71 | bpc    3.549\n",
      "| epoch  93 |   150/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.46 | ppl    11.73 | bpc    3.552\n",
      "| epoch  93 |   200/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.46 | ppl    11.73 | bpc    3.552\n",
      "| epoch  93 |   250/  559 batches | lr 0.0001 | ms/batch 41.76 | loss  2.46 | ppl    11.68 | bpc    3.546\n",
      "| epoch  93 |   300/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.45 | ppl    11.57 | bpc    3.533\n",
      "| epoch  93 |   350/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.45 | ppl    11.61 | bpc    3.537\n",
      "| epoch  93 |   400/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.46 | ppl    11.67 | bpc    3.545\n",
      "| epoch  93 |   450/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.46 | ppl    11.73 | bpc    3.552\n",
      "| epoch  93 |   500/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.46 | ppl    11.68 | bpc    3.546\n",
      "| epoch  93 |   550/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.45 | ppl    11.61 | bpc    3.537\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.278203 --> 2.275597).  Saving model ...\n",
      "| end of epoch  93 | time: 32.01s | valid loss  2.28 | valid ppl     9.73 | bpc    3.283\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |    50/  559 batches | lr 0.0001 | ms/batch 41.13 | loss  2.51 | ppl    12.25 | bpc    3.615\n",
      "| epoch  94 |   100/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.46 | ppl    11.69 | bpc    3.548\n",
      "| epoch  94 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.46 | ppl    11.70 | bpc    3.549\n",
      "| epoch  94 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.46 | ppl    11.73 | bpc    3.552\n",
      "| epoch  94 |   250/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.45 | ppl    11.64 | bpc    3.541\n",
      "| epoch  94 |   300/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.45 | ppl    11.55 | bpc    3.530\n",
      "| epoch  94 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.45 | ppl    11.56 | bpc    3.531\n",
      "| epoch  94 |   400/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.45 | ppl    11.61 | bpc    3.538\n",
      "| epoch  94 |   450/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.46 | ppl    11.65 | bpc    3.542\n",
      "| epoch  94 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.45 | ppl    11.64 | bpc    3.541\n",
      "| epoch  94 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.45 | ppl    11.54 | bpc    3.529\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.275597 --> 2.268887).  Saving model ...\n",
      "| end of epoch  94 | time: 32.03s | valid loss  2.27 | valid ppl     9.67 | bpc    3.273\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |    50/  559 batches | lr 0.0001 | ms/batch 39.62 | loss  2.50 | ppl    12.19 | bpc    3.608\n",
      "| epoch  95 |   100/  559 batches | lr 0.0001 | ms/batch 40.18 | loss  2.45 | ppl    11.62 | bpc    3.538\n",
      "| epoch  95 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.46 | ppl    11.66 | bpc    3.544\n",
      "| epoch  95 |   200/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.46 | ppl    11.66 | bpc    3.543\n",
      "| epoch  95 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.45 | ppl    11.59 | bpc    3.535\n",
      "| epoch  95 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.44 | ppl    11.49 | bpc    3.522\n",
      "| epoch  95 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.44 | ppl    11.52 | bpc    3.526\n",
      "| epoch  95 |   400/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.45 | ppl    11.56 | bpc    3.531\n",
      "| epoch  95 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.45 | ppl    11.63 | bpc    3.540\n",
      "| epoch  95 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.45 | ppl    11.57 | bpc    3.532\n",
      "| epoch  95 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.44 | ppl    11.49 | bpc    3.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.268887 --> 2.268609).  Saving model ...\n",
      "| end of epoch  95 | time: 31.86s | valid loss  2.27 | valid ppl     9.67 | bpc    3.273\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |    50/  559 batches | lr 0.0001 | ms/batch 39.76 | loss  2.49 | ppl    12.11 | bpc    3.598\n",
      "| epoch  96 |   100/  559 batches | lr 0.0001 | ms/batch 41.69 | loss  2.45 | ppl    11.57 | bpc    3.533\n",
      "| epoch  96 |   150/  559 batches | lr 0.0001 | ms/batch 41.75 | loss  2.45 | ppl    11.59 | bpc    3.535\n",
      "| epoch  96 |   200/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.45 | ppl    11.59 | bpc    3.535\n",
      "| epoch  96 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.44 | ppl    11.51 | bpc    3.525\n",
      "| epoch  96 |   300/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.43 | ppl    11.40 | bpc    3.511\n",
      "| epoch  96 |   350/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.44 | ppl    11.42 | bpc    3.514\n",
      "| epoch  96 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.44 | ppl    11.45 | bpc    3.517\n",
      "| epoch  96 |   450/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.44 | ppl    11.51 | bpc    3.524\n",
      "| epoch  96 |   500/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.44 | ppl    11.47 | bpc    3.519\n",
      "| epoch  96 |   550/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.43 | ppl    11.38 | bpc    3.509\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.268609 --> 2.259929).  Saving model ...\n",
      "| end of epoch  96 | time: 31.94s | valid loss  2.26 | valid ppl     9.58 | bpc    3.260\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 |    50/  559 batches | lr 0.0001 | ms/batch 41.04 | loss  2.49 | ppl    12.02 | bpc    3.588\n",
      "| epoch  97 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.44 | ppl    11.47 | bpc    3.520\n",
      "| epoch  97 |   150/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.44 | ppl    11.52 | bpc    3.526\n",
      "| epoch  97 |   200/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.44 | ppl    11.51 | bpc    3.525\n",
      "| epoch  97 |   250/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.44 | ppl    11.47 | bpc    3.520\n",
      "| epoch  97 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.43 | ppl    11.37 | bpc    3.507\n",
      "| epoch  97 |   350/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.43 | ppl    11.38 | bpc    3.508\n",
      "| epoch  97 |   400/  559 batches | lr 0.0001 | ms/batch 41.85 | loss  2.44 | ppl    11.43 | bpc    3.515\n",
      "| epoch  97 |   450/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.44 | ppl    11.48 | bpc    3.521\n",
      "| epoch  97 |   500/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.44 | ppl    11.43 | bpc    3.515\n",
      "| epoch  97 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.43 | ppl    11.34 | bpc    3.503\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.259929 --> 2.253270).  Saving model ...\n",
      "| end of epoch  97 | time: 32.04s | valid loss  2.25 | valid ppl     9.52 | bpc    3.251\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |    50/  559 batches | lr 0.0001 | ms/batch 40.88 | loss  2.48 | ppl    11.97 | bpc    3.581\n",
      "| epoch  98 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.44 | ppl    11.44 | bpc    3.516\n",
      "| epoch  98 |   150/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.44 | ppl    11.46 | bpc    3.519\n",
      "| epoch  98 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.44 | ppl    11.45 | bpc    3.517\n",
      "| epoch  98 |   250/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.43 | ppl    11.39 | bpc    3.509\n",
      "| epoch  98 |   300/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.42 | ppl    11.30 | bpc    3.498\n",
      "| epoch  98 |   350/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.43 | ppl    11.31 | bpc    3.499\n",
      "| epoch  98 |   400/  559 batches | lr 0.0001 | ms/batch 41.77 | loss  2.43 | ppl    11.35 | bpc    3.504\n",
      "| epoch  98 |   450/  559 batches | lr 0.0001 | ms/batch 41.83 | loss  2.43 | ppl    11.41 | bpc    3.512\n",
      "| epoch  98 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.43 | ppl    11.35 | bpc    3.505\n",
      "| epoch  98 |   550/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.42 | ppl    11.28 | bpc    3.496\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.253270 --> 2.244436).  Saving model ...\n",
      "| end of epoch  98 | time: 31.99s | valid loss  2.24 | valid ppl     9.44 | bpc    3.238\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |    50/  559 batches | lr 0.0001 | ms/batch 39.77 | loss  2.48 | ppl    11.91 | bpc    3.574\n",
      "| epoch  99 |   100/  559 batches | lr 0.0001 | ms/batch 41.69 | loss  2.43 | ppl    11.38 | bpc    3.508\n",
      "| epoch  99 |   150/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.43 | ppl    11.39 | bpc    3.510\n",
      "| epoch  99 |   200/  559 batches | lr 0.0001 | ms/batch 41.86 | loss  2.43 | ppl    11.38 | bpc    3.509\n",
      "| epoch  99 |   250/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.43 | ppl    11.36 | bpc    3.506\n",
      "| epoch  99 |   300/  559 batches | lr 0.0001 | ms/batch 41.84 | loss  2.42 | ppl    11.27 | bpc    3.494\n",
      "| epoch  99 |   350/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.42 | ppl    11.26 | bpc    3.494\n",
      "| epoch  99 |   400/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.43 | ppl    11.32 | bpc    3.501\n",
      "| epoch  99 |   450/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.43 | ppl    11.39 | bpc    3.510\n",
      "| epoch  99 |   500/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.43 | ppl    11.33 | bpc    3.502\n",
      "| epoch  99 |   550/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.42 | ppl    11.27 | bpc    3.495\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.244436 --> 2.243426).  Saving model ...\n",
      "| end of epoch  99 | time: 31.95s | valid loss  2.24 | valid ppl     9.43 | bpc    3.237\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |    50/  559 batches | lr 0.0001 | ms/batch 40.06 | loss  2.48 | ppl    11.89 | bpc    3.572\n",
      "| epoch 100 |   100/  559 batches | lr 0.0001 | ms/batch 41.40 | loss  2.43 | ppl    11.37 | bpc    3.508\n",
      "| epoch 100 |   150/  559 batches | lr 0.0001 | ms/batch 41.79 | loss  2.43 | ppl    11.41 | bpc    3.512\n",
      "| epoch 100 |   200/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.44 | ppl    11.43 | bpc    3.515\n",
      "| epoch 100 |   250/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.43 | ppl    11.37 | bpc    3.507\n",
      "| epoch 100 |   300/  559 batches | lr 0.0001 | ms/batch 41.78 | loss  2.42 | ppl    11.27 | bpc    3.494\n",
      "| epoch 100 |   350/  559 batches | lr 0.0001 | ms/batch 41.82 | loss  2.42 | ppl    11.28 | bpc    3.495\n",
      "| epoch 100 |   400/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.43 | ppl    11.33 | bpc    3.502\n",
      "| epoch 100 |   450/  559 batches | lr 0.0001 | ms/batch 41.81 | loss  2.43 | ppl    11.38 | bpc    3.508\n",
      "| epoch 100 |   500/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.43 | ppl    11.34 | bpc    3.504\n",
      "| epoch 100 |   550/  559 batches | lr 0.0001 | ms/batch 41.80 | loss  2.42 | ppl    11.28 | bpc    3.496\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| end of epoch 100 | time: 31.90s | valid loss  2.25 | valid ppl     9.47 | bpc    3.243\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test loss  2.22 | test ppl     9.22 | bpc    3.205\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "best_val_loss = None\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.99)\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "opts = 'SGD'\n",
    "epochs = 100\n",
    "early_stopping = EarlyStopping(patience=25, verbose=True)\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.to(device)\n",
    "\n",
    "        param_vector = parameters_to_vector(model.rnn.parameters())\n",
    "        param_vector.to(device)\n",
    "        n_params = len(param_vector)\n",
    "        noise = torch.distributions.Normal(loc=torch.tensor(0.), scale=torch.tensor(0.075)).sample_n(n_params)\n",
    "        param_vector.add_(noise.to(device))\n",
    "        \n",
    "        vector_to_parameters(param_vector, model.rnn.parameters())\n",
    "        model.to(device)\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        train_loss = evaluate(train_data)\n",
    "        val_losses.append(val_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        print('-' * 89)\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f} | bpc {:8.3f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                           val_loss, math.exp(val_loss), val_loss / math.log(2)))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "    test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_losses = [i.item() for i in val_losses]\n",
    "training_losses = [i.item() for i in train_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(range(100), training_losses, c='#00ff00')\n",
    "plt.plot(range(100), validation_losses)\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 5.0)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Loss')\n",
    "plt.savefig('Char_Noise'+'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adaptive Weight Noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-k5ABGNob_x",
    "outputId": "0a465905-2366-465b-8099-5987d4e7b1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (encoder): Embedding(50, 256)\n",
      "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
      "  (decoder): Linear(in_features=1000, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "interval = 50 # interval to report\n",
    "ntokens = len(corpus.dictionary) # 10000\n",
    "model = RNNModel(ntokens, emsize, nhid, nlayers, dropout)\n",
    "save = 'output/model_test_character_adaptive.pt'\n",
    "checkpoint = \"output/model_test_character_noise.pt\"\n",
    "\n",
    "# Load checkpoint\n",
    "if checkpoint != '':\n",
    "    model = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): Embedding(50, 256)\n",
       "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
       "  (decoder): Linear(in_features=1000, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "dW2e51KCAm1Q"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # choose a optimizer\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    # train_data size(batchcnt, bsz)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        # print(hidden.to(device))\n",
    "        output, hidden = model(data.to(device), hidden)\n",
    "        loss = criterion(output.to(device), targets.to(device))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), clip)\n",
    "        opt.step()\n",
    "\n",
    "        l2_lambda = 0.01\n",
    "        l2_reg = torch.tensor(0.).to(device)\n",
    "        for param in model.rnn.parameters():\n",
    "            l2_reg += torch.norm(param.to(device))\n",
    "\n",
    "        total_loss += loss.data\n",
    "        total_loss += l2_lambda * l2_reg\n",
    "\n",
    "        if batch % interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "                epoch, batch, len(train_data) // bptt, lr,\n",
    "                elapsed * 1000 / interval, cur_loss, math.exp(cur_loss), cur_loss / math.log(2)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AamuIRSowPk",
    "outputId": "4e7dd938-4897-405e-f340-90ef36a281f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  559 batches | lr 0.0001 | ms/batch 38.24 | loss 29.73 | ppl 8154984876036.43 | bpc   42.891\n",
      "| epoch   1 |   100/  559 batches | lr 0.0001 | ms/batch 37.13 | loss 29.15 | ppl 4556627983698.00 | bpc   42.051\n",
      "| epoch   1 |   150/  559 batches | lr 0.0001 | ms/batch 37.22 | loss 29.15 | ppl 4571636064217.23 | bpc   42.056\n",
      "| epoch   1 |   200/  559 batches | lr 0.0001 | ms/batch 37.27 | loss 29.15 | ppl 4588207303604.57 | bpc   42.061\n",
      "| epoch   1 |   250/  559 batches | lr 0.0001 | ms/batch 37.31 | loss 29.15 | ppl 4576329672629.55 | bpc   42.057\n",
      "| epoch   1 |   300/  559 batches | lr 0.0001 | ms/batch 37.35 | loss 29.15 | ppl 4551806987473.66 | bpc   42.050\n",
      "| epoch   1 |   350/  559 batches | lr 0.0001 | ms/batch 37.39 | loss 29.15 | ppl 4567356693798.47 | bpc   42.054\n",
      "| epoch   1 |   400/  559 batches | lr 0.0001 | ms/batch 37.50 | loss 29.16 | ppl 4599387575973.59 | bpc   42.065\n",
      "| epoch   1 |   450/  559 batches | lr 0.0001 | ms/batch 37.45 | loss 29.17 | ppl 4638671573942.19 | bpc   42.077\n",
      "| epoch   1 |   500/  559 batches | lr 0.0001 | ms/batch 37.57 | loss 29.16 | ppl 4632791673741.24 | bpc   42.075\n",
      "| epoch   1 |   550/  559 batches | lr 0.0001 | ms/batch 37.57 | loss 29.16 | ppl 4611113967686.88 | bpc   42.068\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 28.63s | valid loss  2.24 | valid ppl     9.43 | bpc    3.238\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 2.244371).  Saving model ...\n",
      "| epoch   2 |    50/  559 batches | lr 0.0001 | ms/batch 38.58 | loss 29.86 | ppl 9252430967159.10 | bpc   43.073\n",
      "| epoch   2 |   100/  559 batches | lr 0.0001 | ms/batch 37.91 | loss 29.28 | ppl 5178218415113.61 | bpc   42.236\n",
      "| epoch   2 |   150/  559 batches | lr 0.0001 | ms/batch 37.87 | loss 29.28 | ppl 5196621642220.85 | bpc   42.241\n",
      "| epoch   2 |   200/  559 batches | lr 0.0001 | ms/batch 37.96 | loss 29.28 | ppl 5211669629752.81 | bpc   42.245\n",
      "| epoch   2 |   250/  559 batches | lr 0.0001 | ms/batch 37.92 | loss 29.28 | ppl 5193539996088.60 | bpc   42.240\n",
      "| epoch   2 |   300/  559 batches | lr 0.0001 | ms/batch 38.00 | loss 29.27 | ppl 5153703479207.44 | bpc   42.229\n",
      "| epoch   2 |   350/  559 batches | lr 0.0001 | ms/batch 38.01 | loss 29.28 | ppl 5177922123556.23 | bpc   42.236\n",
      "| epoch   2 |   400/  559 batches | lr 0.0001 | ms/batch 38.02 | loss 29.28 | ppl 5209632231553.40 | bpc   42.244\n",
      "| epoch   2 |   450/  559 batches | lr 0.0001 | ms/batch 38.14 | loss 29.29 | ppl 5230481047610.00 | bpc   42.250\n",
      "| epoch   2 |   500/  559 batches | lr 0.0001 | ms/batch 38.13 | loss 29.29 | ppl 5231269238710.18 | bpc   42.250\n",
      "| epoch   2 |   550/  559 batches | lr 0.0001 | ms/batch 38.21 | loss 29.28 | ppl 5210963904102.24 | bpc   42.245\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 29.07s | valid loss  2.24 | valid ppl     9.37 | bpc    3.228\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.244371 --> 2.237764).  Saving model ...\n",
      "| epoch   3 |    50/  559 batches | lr 0.0001 | ms/batch 39.04 | loss 29.98 | ppl 10470369052885.65 | bpc   43.251\n",
      "| epoch   3 |   100/  559 batches | lr 0.0001 | ms/batch 38.34 | loss 29.40 | ppl 5838630309656.94 | bpc   42.409\n",
      "| epoch   3 |   150/  559 batches | lr 0.0001 | ms/batch 38.41 | loss 29.40 | ppl 5857793859788.39 | bpc   42.413\n",
      "| epoch   3 |   200/  559 batches | lr 0.0001 | ms/batch 38.86 | loss 29.40 | ppl 5879083223391.35 | bpc   42.419\n",
      "| epoch   3 |   250/  559 batches | lr 0.0001 | ms/batch 39.63 | loss 29.40 | ppl 5865262083656.62 | bpc   42.415\n",
      "| epoch   3 |   300/  559 batches | lr 0.0001 | ms/batch 39.85 | loss 29.39 | ppl 5821794266737.07 | bpc   42.405\n",
      "| epoch   3 |   350/  559 batches | lr 0.0001 | ms/batch 39.76 | loss 29.40 | ppl 5840780011887.97 | bpc   42.409\n",
      "| epoch   3 |   400/  559 batches | lr 0.0001 | ms/batch 41.28 | loss 29.40 | ppl 5868093102871.81 | bpc   42.416\n",
      "| epoch   3 |   450/  559 batches | lr 0.0001 | ms/batch 40.97 | loss 29.41 | ppl 5909640550141.85 | bpc   42.426\n",
      "| epoch   3 |   500/  559 batches | lr 0.0001 | ms/batch 40.91 | loss 29.41 | ppl 5903084034446.05 | bpc   42.425\n",
      "| epoch   3 |   550/  559 batches | lr 0.0001 | ms/batch 41.48 | loss 29.40 | ppl 5873322328644.65 | bpc   42.417\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 30.81s | valid loss  2.23 | valid ppl     9.33 | bpc    3.222\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.237764 --> 2.233275).  Saving model ...\n",
      "| epoch   4 |    50/  559 batches | lr 0.0001 | ms/batch 40.57 | loss 30.10 | ppl 11808380739213.37 | bpc   43.425\n",
      "| epoch   4 |   100/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 29.51 | ppl 6578235564073.73 | bpc   42.581\n",
      "| epoch   4 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 29.52 | ppl 6614041388365.69 | bpc   42.589\n",
      "| epoch   4 |   200/  559 batches | lr 0.0001 | ms/batch 41.79 | loss 29.52 | ppl 6621627520551.82 | bpc   42.590\n",
      "| epoch   4 |   250/  559 batches | lr 0.0001 | ms/batch 41.54 | loss 29.52 | ppl 6599549712346.64 | bpc   42.586\n",
      "| epoch   4 |   300/  559 batches | lr 0.0001 | ms/batch 41.24 | loss 29.51 | ppl 6568117932945.92 | bpc   42.579\n",
      "| epoch   4 |   350/  559 batches | lr 0.0001 | ms/batch 41.76 | loss 29.52 | ppl 6593233740221.38 | bpc   42.584\n",
      "| epoch   4 |   400/  559 batches | lr 0.0001 | ms/batch 41.86 | loss 29.52 | ppl 6633358309391.86 | bpc   42.593\n",
      "| epoch   4 |   450/  559 batches | lr 0.0001 | ms/batch 39.99 | loss 29.53 | ppl 6684160365041.97 | bpc   42.604\n",
      "| epoch   4 |   500/  559 batches | lr 0.0001 | ms/batch 41.55 | loss 29.53 | ppl 6672810631409.37 | bpc   42.601\n",
      "| epoch   4 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.53 | ppl 6646859197248.38 | bpc   42.596\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 31.86s | valid loss  2.23 | valid ppl     9.33 | bpc    3.221\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.233275 --> 2.232838).  Saving model ...\n",
      "| epoch   5 |    50/  559 batches | lr 0.0001 | ms/batch 39.99 | loss 30.23 | ppl 13416707791996.72 | bpc   43.609\n",
      "| epoch   5 |   100/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 29.64 | ppl 7453918409586.60 | bpc   42.761\n",
      "| epoch   5 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 29.64 | ppl 7475759563372.58 | bpc   42.765\n",
      "| epoch   5 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 29.65 | ppl 7496377766189.71 | bpc   42.769\n",
      "| epoch   5 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 29.64 | ppl 7476415500617.47 | bpc   42.765\n",
      "| epoch   5 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 29.64 | ppl 7439587028409.90 | bpc   42.758\n",
      "| epoch   5 |   350/  559 batches | lr 0.0001 | ms/batch 42.07 | loss 29.64 | ppl 7458881871563.54 | bpc   42.762\n",
      "| epoch   5 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 29.65 | ppl 7513870551777.68 | bpc   42.773\n",
      "| epoch   5 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.66 | ppl 7569871009637.23 | bpc   42.783\n",
      "| epoch   5 |   500/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 29.66 | ppl 7568759335772.39 | bpc   42.783\n",
      "| epoch   5 |   550/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 29.65 | ppl 7520021311712.67 | bpc   42.774\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 32.14s | valid loss  2.24 | valid ppl     9.35 | bpc    3.225\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch   6 |    50/  559 batches | lr 0.0001 | ms/batch 43.05 | loss 30.35 | ppl 15133744088341.61 | bpc   43.783\n",
      "| epoch   6 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.76 | ppl 8388821979585.67 | bpc   42.932\n",
      "| epoch   6 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.76 | ppl 8418105718514.94 | bpc   42.937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   6 |   200/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 29.76 | ppl 8421719152865.82 | bpc   42.937\n",
      "| epoch   6 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 29.76 | ppl 8409696440029.57 | bpc   42.935\n",
      "| epoch   6 |   300/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.75 | ppl 8333340840419.02 | bpc   42.922\n",
      "| epoch   6 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.76 | ppl 8368190864005.85 | bpc   42.928\n",
      "| epoch   6 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 29.76 | ppl 8421478208994.88 | bpc   42.937\n",
      "| epoch   6 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 29.77 | ppl 8481346859225.07 | bpc   42.947\n",
      "| epoch   6 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.76 | ppl 8440324744517.50 | bpc   42.940\n",
      "| epoch   6 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.76 | ppl 8415617365683.05 | bpc   42.936\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 32.29s | valid loss  2.23 | valid ppl     9.28 | bpc    3.214\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.232838 --> 2.228115).  Saving model ...\n",
      "| epoch   7 |    50/  559 batches | lr 0.0001 | ms/batch 40.85 | loss 30.46 | ppl 17005754564410.59 | bpc   43.951\n",
      "| epoch   7 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 29.87 | ppl 9383913462008.45 | bpc   43.093\n",
      "| epoch   7 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 29.87 | ppl 9417982106038.57 | bpc   43.099\n",
      "| epoch   7 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 29.88 | ppl 9434181022281.41 | bpc   43.101\n",
      "| epoch   7 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.87 | ppl 9408448382460.25 | bpc   43.097\n",
      "| epoch   7 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.87 | ppl 9357550431565.24 | bpc   43.089\n",
      "| epoch   7 |   350/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.87 | ppl 9382159583269.02 | bpc   43.093\n",
      "| epoch   7 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 29.88 | ppl 9435980621126.53 | bpc   43.101\n",
      "| epoch   7 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.88 | ppl 9501375876506.77 | bpc   43.111\n",
      "| epoch   7 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.88 | ppl 9489802693824.52 | bpc   43.110\n",
      "| epoch   7 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 29.88 | ppl 9436484570315.94 | bpc   43.101\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 32.19s | valid loss  2.22 | valid ppl     9.22 | bpc    3.205\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.228115 --> 2.221214).  Saving model ...\n",
      "| epoch   8 |    50/  559 batches | lr 0.0001 | ms/batch 40.92 | loss 30.58 | ppl 19158231562731.22 | bpc   44.123\n",
      "| epoch   8 |   100/  559 batches | lr 0.0001 | ms/batch 41.55 | loss 29.99 | ppl 10584338237155.61 | bpc   43.267\n",
      "| epoch   8 |   150/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 29.99 | ppl 10603776943634.90 | bpc   43.270\n",
      "| epoch   8 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 29.99 | ppl 10627872146625.02 | bpc   43.273\n",
      "| epoch   8 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 29.99 | ppl 10614056273345.81 | bpc   43.271\n",
      "| epoch   8 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 29.99 | ppl 10544501671182.00 | bpc   43.262\n",
      "| epoch   8 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 29.99 | ppl 10570558794721.89 | bpc   43.265\n",
      "| epoch   8 |   400/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 30.00 | ppl 10636876308221.02 | bpc   43.274\n",
      "| epoch   8 |   450/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 30.00 | ppl 10726049609592.78 | bpc   43.286\n",
      "| epoch   8 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.00 | ppl 10676695299120.08 | bpc   43.280\n",
      "| epoch   8 |   550/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 30.00 | ppl 10633772661685.81 | bpc   43.274\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 32.15s | valid loss  2.22 | valid ppl     9.22 | bpc    3.204\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.221214 --> 2.221001).  Saving model ...\n",
      "| epoch   9 |    50/  559 batches | lr 0.0001 | ms/batch 40.84 | loss 30.70 | ppl 21599916309052.82 | bpc   44.296\n",
      "| epoch   9 |   100/  559 batches | lr 0.0001 | ms/batch 42.18 | loss 30.11 | ppl 11893937613798.24 | bpc   43.435\n",
      "| epoch   9 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.11 | ppl 11923238438542.75 | bpc   43.439\n",
      "| epoch   9 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 30.11 | ppl 11936003401115.75 | bpc   43.440\n",
      "| epoch   9 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 30.11 | ppl 11940830794438.21 | bpc   43.441\n",
      "| epoch   9 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.10 | ppl 11856044617432.36 | bpc   43.431\n",
      "| epoch   9 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.11 | ppl 11890807373558.81 | bpc   43.435\n",
      "| epoch   9 |   400/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 30.12 | ppl 11991179015026.02 | bpc   43.447\n",
      "| epoch   9 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.12 | ppl 12043163615170.65 | bpc   43.453\n",
      "| epoch   9 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 30.12 | ppl 12009490068818.67 | bpc   43.449\n",
      "| epoch   9 |   550/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 30.11 | ppl 11974014920512.87 | bpc   43.445\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 32.20s | valid loss  2.22 | valid ppl     9.22 | bpc    3.205\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  10 |    50/  559 batches | lr 0.0001 | ms/batch 43.09 | loss 30.83 | ppl 24482121524458.84 | bpc   44.477\n",
      "| epoch  10 |   100/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 30.23 | ppl 13459588809739.92 | bpc   43.614\n",
      "| epoch  10 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 30.23 | ppl 13504924954159.51 | bpc   43.619\n",
      "| epoch  10 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.24 | ppl 13528411437978.44 | bpc   43.621\n",
      "| epoch  10 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.23 | ppl 13515283882286.88 | bpc   43.620\n",
      "| epoch  10 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.23 | ppl 13407242706707.14 | bpc   43.608\n",
      "| epoch  10 |   350/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 30.23 | ppl 13480682138147.69 | bpc   43.616\n",
      "| epoch  10 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.24 | ppl 13555816562739.68 | bpc   43.624\n",
      "| epoch  10 |   450/  559 batches | lr 0.0001 | ms/batch 42.20 | loss 30.25 | ppl 13665524169147.24 | bpc   43.636\n",
      "| epoch  10 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.24 | ppl 13642007804785.71 | bpc   43.633\n",
      "| epoch  10 |   550/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 30.24 | ppl 13592529525163.03 | bpc   43.628\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 32.28s | valid loss  2.23 | valid ppl     9.26 | bpc    3.212\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  11 |    50/  559 batches | lr 0.0001 | ms/batch 39.53 | loss 30.96 | ppl 27797068757100.11 | bpc   44.660\n",
      "| epoch  11 |   100/  559 batches | lr 0.0001 | ms/batch 40.73 | loss 30.35 | ppl 15227441143687.55 | bpc   43.792\n",
      "| epoch  11 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 30.36 | ppl 15283686893817.19 | bpc   43.797\n",
      "| epoch  11 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.36 | ppl 15300107901751.08 | bpc   43.799\n",
      "| epoch  11 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.36 | ppl 15298094432095.11 | bpc   43.798\n",
      "| epoch  11 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.35 | ppl 15202135791504.51 | bpc   43.789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.36 | ppl 15285931710242.78 | bpc   43.797\n",
      "| epoch  11 |   400/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 30.36 | ppl 15383446207433.62 | bpc   43.806\n",
      "| epoch  11 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.37 | ppl 15465173488065.68 | bpc   43.814\n",
      "| epoch  11 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.37 | ppl 15444156081042.98 | bpc   43.812\n",
      "| epoch  11 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.36 | ppl 15378869599509.65 | bpc   43.806\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 32.05s | valid loss  2.22 | valid ppl     9.24 | bpc    3.208\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  12 |    50/  559 batches | lr 0.0001 | ms/batch 43.10 | loss 31.08 | ppl 31449399850419.43 | bpc   44.838\n",
      "| epoch  12 |   100/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 30.48 | ppl 17236859702901.01 | bpc   43.971\n",
      "| epoch  12 |   150/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 30.48 | ppl 17270755989609.58 | bpc   43.973\n",
      "| epoch  12 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.48 | ppl 17353570822346.00 | bpc   43.980\n",
      "| epoch  12 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 30.48 | ppl 17320007522186.81 | bpc   43.978\n",
      "| epoch  12 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.48 | ppl 17217834600310.40 | bpc   43.969\n",
      "| epoch  12 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.48 | ppl 17317992486559.30 | bpc   43.977\n",
      "| epoch  12 |   400/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 30.49 | ppl 17413384823529.07 | bpc   43.985\n",
      "| epoch  12 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.50 | ppl 17544403906965.81 | bpc   43.996\n",
      "| epoch  12 |   500/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.50 | ppl 17532729103262.00 | bpc   43.995\n",
      "| epoch  12 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.49 | ppl 17451156146777.98 | bpc   43.988\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 32.32s | valid loss  2.23 | valid ppl     9.31 | bpc    3.218\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| epoch  13 |    50/  559 batches | lr 0.0001 | ms/batch 40.37 | loss 31.21 | ppl 35865820867335.73 | bpc   45.028\n",
      "| epoch  13 |   100/  559 batches | lr 0.0001 | ms/batch 42.15 | loss 30.60 | ppl 19518997983686.37 | bpc   44.150\n",
      "| epoch  13 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.61 | ppl 19626064863233.01 | bpc   44.158\n",
      "| epoch  13 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.61 | ppl 19664021907373.48 | bpc   44.161\n",
      "| epoch  13 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.61 | ppl 19674751591193.82 | bpc   44.161\n",
      "| epoch  13 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.60 | ppl 19546418162635.65 | bpc   44.152\n",
      "| epoch  13 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.61 | ppl 19647825926058.64 | bpc   44.159\n",
      "| epoch  13 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.62 | ppl 19806043002850.85 | bpc   44.171\n",
      "| epoch  13 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.62 | ppl 19928971599473.32 | bpc   44.180\n",
      "| epoch  13 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.62 | ppl 19891034269392.19 | bpc   44.177\n",
      "| epoch  13 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.62 | ppl 19829667724636.44 | bpc   44.173\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 32.17s | valid loss  2.23 | valid ppl     9.28 | bpc    3.214\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| epoch  14 |    50/  559 batches | lr 0.0001 | ms/batch 39.87 | loss 31.34 | ppl 40749346645238.74 | bpc   45.212\n",
      "| epoch  14 |   100/  559 batches | lr 0.0001 | ms/batch 41.85 | loss 30.73 | ppl 22164883641748.70 | bpc   44.333\n",
      "| epoch  14 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.74 | ppl 22288759458970.09 | bpc   44.341\n",
      "| epoch  14 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.74 | ppl 22356371547973.10 | bpc   44.346\n",
      "| epoch  14 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.74 | ppl 22308876914045.97 | bpc   44.343\n",
      "| epoch  14 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.73 | ppl 22189459705713.23 | bpc   44.335\n",
      "| epoch  14 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.73 | ppl 22276136841394.20 | bpc   44.341\n",
      "| epoch  14 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.74 | ppl 22413242097461.29 | bpc   44.349\n",
      "| epoch  14 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.75 | ppl 22565863407880.39 | bpc   44.359\n",
      "| epoch  14 |   500/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.75 | ppl 22571459427566.65 | bpc   44.360\n",
      "| epoch  14 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.74 | ppl 22477758824729.59 | bpc   44.354\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 32.14s | valid loss  2.23 | valid ppl     9.28 | bpc    3.214\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| epoch  15 |    50/  559 batches | lr 0.0001 | ms/batch 40.05 | loss 31.47 | ppl 46279454119902.66 | bpc   45.395\n",
      "| epoch  15 |   100/  559 batches | lr 0.0001 | ms/batch 41.82 | loss 30.85 | ppl 25049078066211.25 | bpc   44.510\n",
      "| epoch  15 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.86 | ppl 25150858881057.50 | bpc   44.516\n",
      "| epoch  15 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.86 | ppl 25288818010955.63 | bpc   44.524\n",
      "| epoch  15 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.86 | ppl 25129280987274.20 | bpc   44.514\n",
      "| epoch  15 |   300/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.85 | ppl 25036515780878.04 | bpc   44.509\n",
      "| epoch  15 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.85 | ppl 25091731714144.73 | bpc   44.512\n",
      "| epoch  15 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.86 | ppl 25249007605868.13 | bpc   44.521\n",
      "| epoch  15 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 30.87 | ppl 25416284564483.71 | bpc   44.531\n",
      "| epoch  15 |   500/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 30.86 | ppl 25371240251344.71 | bpc   44.528\n",
      "| epoch  15 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.86 | ppl 25256569647693.96 | bpc   44.522\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 32.14s | valid loss  2.22 | valid ppl     9.25 | bpc    3.209\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| epoch  16 |    50/  559 batches | lr 0.0001 | ms/batch 40.10 | loss 31.58 | ppl 51977840933190.41 | bpc   45.563\n",
      "| epoch  16 |   100/  559 batches | lr 0.0001 | ms/batch 41.53 | loss 30.97 | ppl 28139487685939.95 | bpc   44.678\n",
      "| epoch  16 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 30.97 | ppl 28198857582329.73 | bpc   44.681\n",
      "| epoch  16 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 30.97 | ppl 28257328686346.80 | bpc   44.684\n",
      "| epoch  16 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.97 | ppl 28297186340618.26 | bpc   44.686\n",
      "| epoch  16 |   300/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 30.96 | ppl 28033471380015.59 | bpc   44.672\n",
      "| epoch  16 |   350/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 30.97 | ppl 28193587139780.33 | bpc   44.680\n",
      "| epoch  16 |   400/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 30.98 | ppl 28339694672859.37 | bpc   44.688\n",
      "| epoch  16 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 30.98 | ppl 28552705957841.90 | bpc   44.699\n",
      "| epoch  16 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 30.98 | ppl 28450992960893.34 | bpc   44.694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  16 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 30.98 | ppl 28385948271996.80 | bpc   44.690\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 32.15s | valid loss  2.22 | valid ppl     9.20 | bpc    3.202\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.221001 --> 2.219491).  Saving model ...\n",
      "| epoch  17 |    50/  559 batches | lr 0.0001 | ms/batch 40.52 | loss 31.70 | ppl 58693609780092.65 | bpc   45.738\n",
      "| epoch  17 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.08 | ppl 31615515509542.40 | bpc   44.846\n",
      "| epoch  17 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.09 | ppl 31722853627340.87 | bpc   44.851\n",
      "| epoch  17 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 31.09 | ppl 31788207412545.24 | bpc   44.854\n",
      "| epoch  17 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.09 | ppl 31732536151340.84 | bpc   44.851\n",
      "| epoch  17 |   300/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 31.08 | ppl 31434587052417.45 | bpc   44.837\n",
      "| epoch  17 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.09 | ppl 31641697330225.67 | bpc   44.847\n",
      "| epoch  17 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.09 | ppl 31767781265611.59 | bpc   44.853\n",
      "| epoch  17 |   450/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 31.10 | ppl 32031659704230.27 | bpc   44.865\n",
      "| epoch  17 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.10 | ppl 31953735634394.61 | bpc   44.861\n",
      "| epoch  17 |   550/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 31.09 | ppl 31832681159538.54 | bpc   44.856\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 32.17s | valid loss  2.22 | valid ppl     9.17 | bpc    3.197\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.219491 --> 2.216156).  Saving model ...\n",
      "| epoch  18 |    50/  559 batches | lr 0.0001 | ms/batch 43.08 | loss 31.82 | ppl 65655035079894.88 | bpc   45.900\n",
      "| epoch  18 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 31.20 | ppl 35323379780755.98 | bpc   45.006\n",
      "| epoch  18 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.20 | ppl 35498242458693.00 | bpc   45.013\n",
      "| epoch  18 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.20 | ppl 35567507035590.69 | bpc   45.016\n",
      "| epoch  18 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.20 | ppl 35545940572457.76 | bpc   45.015\n",
      "| epoch  18 |   300/  559 batches | lr 0.0001 | ms/batch 42.35 | loss 31.20 | ppl 35323110285783.51 | bpc   45.006\n",
      "| epoch  18 |   350/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 31.20 | ppl 35493300153507.38 | bpc   45.013\n",
      "| epoch  18 |   400/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 31.21 | ppl 35689624020100.52 | bpc   45.021\n",
      "| epoch  18 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 31.21 | ppl 35976814230009.30 | bpc   45.032\n",
      "| epoch  18 |   500/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 31.21 | ppl 35890935621589.23 | bpc   45.029\n",
      "| epoch  18 |   550/  559 batches | lr 0.0001 | ms/batch 42.34 | loss 31.21 | ppl 35763559219978.01 | bpc   45.024\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 32.32s | valid loss  2.22 | valid ppl     9.21 | bpc    3.203\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  19 |    50/  559 batches | lr 0.0001 | ms/batch 40.79 | loss 31.94 | ppl 74241257364571.98 | bpc   46.077\n",
      "| epoch  19 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.32 | ppl 39936190623534.75 | bpc   45.183\n",
      "| epoch  19 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.32 | ppl 40029839763341.51 | bpc   45.186\n",
      "| epoch  19 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 31.32 | ppl 40172257812888.54 | bpc   45.191\n",
      "| epoch  19 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.32 | ppl 40191724643280.06 | bpc   45.192\n",
      "| epoch  19 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.32 | ppl 39884427077136.99 | bpc   45.181\n",
      "| epoch  19 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 31.32 | ppl 40062378447309.66 | bpc   45.187\n",
      "| epoch  19 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.33 | ppl 40332103030606.70 | bpc   45.197\n",
      "| epoch  19 |   450/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 31.33 | ppl 40589628385106.83 | bpc   45.206\n",
      "| epoch  19 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.33 | ppl 40515374557943.81 | bpc   45.204\n",
      "| epoch  19 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.33 | ppl 40370816071144.07 | bpc   45.198\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 32.19s | valid loss  2.22 | valid ppl     9.18 | bpc    3.198\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  20 |    50/  559 batches | lr 0.0001 | ms/batch 41.63 | loss 32.06 | ppl 83996014423640.97 | bpc   46.255\n",
      "| epoch  20 |   100/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.44 | ppl 45064482492512.71 | bpc   45.357\n",
      "| epoch  20 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.44 | ppl 45223087622786.38 | bpc   45.362\n",
      "| epoch  20 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.45 | ppl 45340461847276.09 | bpc   45.366\n",
      "| epoch  20 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 31.44 | ppl 45252251616243.83 | bpc   45.363\n",
      "| epoch  20 |   300/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 31.44 | ppl 44933165064836.87 | bpc   45.353\n",
      "| epoch  20 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.44 | ppl 45128563501384.88 | bpc   45.359\n",
      "| epoch  20 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.45 | ppl 45347640261105.20 | bpc   45.366\n",
      "| epoch  20 |   450/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 31.45 | ppl 45645808798173.58 | bpc   45.376\n",
      "| epoch  20 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.45 | ppl 45647898345303.27 | bpc   45.376\n",
      "| epoch  20 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.45 | ppl 45460048250114.63 | bpc   45.370\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 32.24s | valid loss  2.22 | valid ppl     9.18 | bpc    3.199\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  21 |    50/  559 batches | lr 0.0001 | ms/batch 41.62 | loss 32.18 | ppl 94861700450120.62 | bpc   46.431\n",
      "| epoch  21 |   100/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.55 | ppl 50593194166735.52 | bpc   45.524\n",
      "| epoch  21 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.56 | ppl 50801092698901.09 | bpc   45.530\n",
      "| epoch  21 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.56 | ppl 50923910493190.90 | bpc   45.533\n",
      "| epoch  21 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 31.56 | ppl 50834241734491.91 | bpc   45.531\n",
      "| epoch  21 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.55 | ppl 50416139794254.15 | bpc   45.519\n",
      "| epoch  21 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.56 | ppl 50639051895302.98 | bpc   45.525\n",
      "| epoch  21 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.56 | ppl 50956070558468.01 | bpc   45.534\n",
      "| epoch  21 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.57 | ppl 51341424786770.59 | bpc   45.545\n",
      "| epoch  21 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.57 | ppl 51154823984606.29 | bpc   45.540\n",
      "| epoch  21 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.56 | ppl 51022592580422.88 | bpc   45.536\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 32.24s | valid loss  2.21 | valid ppl     9.15 | bpc    3.195\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.216156 --> 2.214268).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  22 |    50/  559 batches | lr 0.0001 | ms/batch 40.40 | loss 32.30 | ppl 106650587664343.92 | bpc   46.600\n",
      "| epoch  22 |   100/  559 batches | lr 0.0001 | ms/batch 42.17 | loss 31.67 | ppl 56908851088529.23 | bpc   45.694\n",
      "| epoch  22 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 31.67 | ppl 56995101127414.42 | bpc   45.696\n",
      "| epoch  22 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 31.68 | ppl 57157962825380.11 | bpc   45.700\n",
      "| epoch  22 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.67 | ppl 57034249996730.34 | bpc   45.697\n",
      "| epoch  22 |   300/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 31.67 | ppl 56670984729956.05 | bpc   45.688\n",
      "| epoch  22 |   350/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 31.67 | ppl 56902989959330.06 | bpc   45.694\n",
      "| epoch  22 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.68 | ppl 57326647398358.46 | bpc   45.704\n",
      "| epoch  22 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.68 | ppl 57626149131658.51 | bpc   45.712\n",
      "| epoch  22 |   500/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 31.68 | ppl 57510526726678.66 | bpc   45.709\n",
      "| epoch  22 |   550/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 31.68 | ppl 57246992542573.09 | bpc   45.702\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 32.15s | valid loss  2.21 | valid ppl     9.13 | bpc    3.190\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.214268 --> 2.211163).  Saving model ...\n",
      "| epoch  23 |    50/  559 batches | lr 0.0001 | ms/batch 39.75 | loss 32.42 | ppl 119686094803269.86 | bpc   46.766\n",
      "| epoch  23 |   100/  559 batches | lr 0.0001 | ms/batch 40.56 | loss 31.79 | ppl 63725773166343.20 | bpc   45.857\n",
      "| epoch  23 |   150/  559 batches | lr 0.0001 | ms/batch 41.95 | loss 31.79 | ppl 63886539554207.64 | bpc   45.861\n",
      "| epoch  23 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 31.79 | ppl 64048933145811.40 | bpc   45.864\n",
      "| epoch  23 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 31.79 | ppl 63944812280213.51 | bpc   45.862\n",
      "| epoch  23 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.78 | ppl 63588451377441.62 | bpc   45.854\n",
      "| epoch  23 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 31.79 | ppl 63771612964793.98 | bpc   45.858\n",
      "| epoch  23 |   400/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 31.79 | ppl 64207575539810.19 | bpc   45.868\n",
      "| epoch  23 |   450/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 31.80 | ppl 64603623128042.03 | bpc   45.877\n",
      "| epoch  23 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.80 | ppl 64425935897499.40 | bpc   45.873\n",
      "| epoch  23 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 31.79 | ppl 64095005402615.99 | bpc   45.865\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 32.05s | valid loss  2.21 | valid ppl     9.12 | bpc    3.189\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.211163 --> 2.210277).  Saving model ...\n",
      "| epoch  24 |    50/  559 batches | lr 0.0001 | ms/batch 39.90 | loss 32.53 | ppl 133776950009676.17 | bpc   46.927\n",
      "| epoch  24 |   100/  559 batches | lr 0.0001 | ms/batch 41.96 | loss 31.89 | ppl 70966869189486.86 | bpc   46.012\n",
      "| epoch  24 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.90 | ppl 71282004757706.25 | bpc   46.019\n",
      "| epoch  24 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 31.90 | ppl 71378465346055.94 | bpc   46.021\n",
      "| epoch  24 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 31.90 | ppl 71251964010415.31 | bpc   46.018\n",
      "| epoch  24 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.89 | ppl 70711906686552.97 | bpc   46.007\n",
      "| epoch  24 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 31.89 | ppl 71005863164067.30 | bpc   46.013\n",
      "| epoch  24 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.90 | ppl 71268681958731.70 | bpc   46.018\n",
      "| epoch  24 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 31.90 | ppl 71787930038220.41 | bpc   46.029\n",
      "| epoch  24 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 31.90 | ppl 71493326734048.11 | bpc   46.023\n",
      "| epoch  24 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 31.90 | ppl 71292338438873.81 | bpc   46.019\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 32.14s | valid loss  2.21 | valid ppl     9.07 | bpc    3.182\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.210277 --> 2.205486).  Saving model ...\n",
      "| epoch  25 |    50/  559 batches | lr 0.0001 | ms/batch 39.85 | loss 32.64 | ppl 149519331465498.44 | bpc   47.087\n",
      "| epoch  25 |   100/  559 batches | lr 0.0001 | ms/batch 41.73 | loss 32.00 | ppl 79300745556005.83 | bpc   46.172\n",
      "| epoch  25 |   150/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.01 | ppl 79456690481816.03 | bpc   46.175\n",
      "| epoch  25 |   200/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 32.01 | ppl 79635418991830.52 | bpc   46.178\n",
      "| epoch  25 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.01 | ppl 79446991770753.09 | bpc   46.175\n",
      "| epoch  25 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.00 | ppl 78757344629269.17 | bpc   46.162\n",
      "| epoch  25 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.00 | ppl 79083238390567.38 | bpc   46.168\n",
      "| epoch  25 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.01 | ppl 79529468564674.97 | bpc   46.177\n",
      "| epoch  25 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.01 | ppl 80122961363662.95 | bpc   46.187\n",
      "| epoch  25 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.01 | ppl 79892226732395.52 | bpc   46.183\n",
      "| epoch  25 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.01 | ppl 79582881521987.25 | bpc   46.178\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 32.13s | valid loss  2.20 | valid ppl     9.05 | bpc    3.178\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.205486 --> 2.202640).  Saving model ...\n",
      "| epoch  26 |    50/  559 batches | lr 0.0001 | ms/batch 40.16 | loss 32.75 | ppl 166932632740474.06 | bpc   47.246\n",
      "| epoch  26 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.11 | ppl 88078123206951.12 | bpc   46.324\n",
      "| epoch  26 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.11 | ppl 88346315821687.52 | bpc   46.328\n",
      "| epoch  26 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.12 | ppl 88636624186358.62 | bpc   46.333\n",
      "| epoch  26 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.11 | ppl 88411383560105.58 | bpc   46.329\n",
      "| epoch  26 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.10 | ppl 87696928290719.83 | bpc   46.318\n",
      "| epoch  26 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.11 | ppl 87913976570300.98 | bpc   46.321\n",
      "| epoch  26 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.11 | ppl 88414081702580.69 | bpc   46.329\n",
      "| epoch  26 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.12 | ppl 89051792785850.69 | bpc   46.340\n",
      "| epoch  26 |   500/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 32.12 | ppl 88782474586034.83 | bpc   46.335\n",
      "| epoch  26 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 32.11 | ppl 88324412598099.61 | bpc   46.328\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 32.16s | valid loss  2.20 | valid ppl     9.07 | bpc    3.181\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  27 |    50/  559 batches | lr 0.0001 | ms/batch 42.53 | loss 32.85 | ppl 185540410987978.03 | bpc   47.399\n",
      "| epoch  27 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.22 | ppl 97999209651418.55 | bpc   46.478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  27 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.22 | ppl 98141745224716.19 | bpc   46.480\n",
      "| epoch  27 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.22 | ppl 98308486275483.59 | bpc   46.482\n",
      "| epoch  27 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.22 | ppl 98047446532936.78 | bpc   46.479\n",
      "| epoch  27 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.21 | ppl 97410694739493.14 | bpc   46.469\n",
      "| epoch  27 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.21 | ppl 97827395276204.48 | bpc   46.475\n",
      "| epoch  27 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.22 | ppl 98162338342538.06 | bpc   46.480\n",
      "| epoch  27 |   450/  559 batches | lr 0.0001 | ms/batch 42.07 | loss 32.23 | ppl 98945822312071.42 | bpc   46.492\n",
      "| epoch  27 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.22 | ppl 98478515896226.97 | bpc   46.485\n",
      "| epoch  27 |   550/  559 batches | lr 0.0001 | ms/batch 41.97 | loss 32.22 | ppl 98088971691051.36 | bpc   46.479\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 32.25s | valid loss  2.20 | valid ppl     9.03 | bpc    3.175\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.202640 --> 2.200591).  Saving model ...\n",
      "| epoch  28 |    50/  559 batches | lr 0.0001 | ms/batch 39.77 | loss 32.96 | ppl 206510500205210.84 | bpc   47.553\n",
      "| epoch  28 |   100/  559 batches | lr 0.0001 | ms/batch 41.75 | loss 32.32 | ppl 108606076415216.59 | bpc   46.626\n",
      "| epoch  28 |   150/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.32 | ppl 108851203517125.09 | bpc   46.629\n",
      "| epoch  28 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 32.32 | ppl 109073996841972.36 | bpc   46.632\n",
      "| epoch  28 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.32 | ppl 108835010580544.16 | bpc   46.629\n",
      "| epoch  28 |   300/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 32.31 | ppl 108021834313370.48 | bpc   46.618\n",
      "| epoch  28 |   350/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 32.32 | ppl 108539808752122.64 | bpc   46.625\n",
      "| epoch  28 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.32 | ppl 109207641703609.16 | bpc   46.634\n",
      "| epoch  28 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.33 | ppl 109673551743436.50 | bpc   46.640\n",
      "| epoch  28 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.33 | ppl 109327269681557.86 | bpc   46.636\n",
      "| epoch  28 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.32 | ppl 108852033989069.94 | bpc   46.629\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 32.12s | valid loss  2.20 | valid ppl     9.02 | bpc    3.173\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.200591 --> 2.199034).  Saving model ...\n",
      "| epoch  29 |    50/  559 batches | lr 0.0001 | ms/batch 40.26 | loss 33.07 | ppl 229358424386485.97 | bpc   47.705\n",
      "| epoch  29 |   100/  559 batches | lr 0.0001 | ms/batch 42.16 | loss 32.43 | ppl 120820525614809.70 | bpc   46.780\n",
      "| epoch  29 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.43 | ppl 121052115941034.36 | bpc   46.783\n",
      "| epoch  29 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.43 | ppl 121054424848932.14 | bpc   46.783\n",
      "| epoch  29 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.42 | ppl 120612841247444.11 | bpc   46.777\n",
      "| epoch  29 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.42 | ppl 120171493197783.41 | bpc   46.772\n",
      "| epoch  29 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.42 | ppl 120578798543384.52 | bpc   46.777\n",
      "| epoch  29 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.43 | ppl 120934420014743.92 | bpc   46.781\n",
      "| epoch  29 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.43 | ppl 121864788864015.81 | bpc   46.792\n",
      "| epoch  29 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.43 | ppl 121410985931685.94 | bpc   46.787\n",
      "| epoch  29 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.43 | ppl 120988407461232.92 | bpc   46.782\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 32.16s | valid loss  2.20 | valid ppl     9.04 | bpc    3.176\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  30 |    50/  559 batches | lr 0.0001 | ms/batch 43.04 | loss 33.18 | ppl 255975200986755.66 | bpc   47.863\n",
      "| epoch  30 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.53 | ppl 134066102362484.17 | bpc   46.930\n",
      "| epoch  30 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.53 | ppl 134627793801588.52 | bpc   46.936\n",
      "| epoch  30 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.53 | ppl 134558993774218.58 | bpc   46.935\n",
      "| epoch  30 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.53 | ppl 134287218635286.67 | bpc   46.932\n",
      "| epoch  30 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.52 | ppl 133336760577476.11 | bpc   46.922\n",
      "| epoch  30 |   350/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.53 | ppl 133954147804354.42 | bpc   46.929\n",
      "| epoch  30 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.53 | ppl 134608793264279.06 | bpc   46.936\n",
      "| epoch  30 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.54 | ppl 135515579439308.86 | bpc   46.945\n",
      "| epoch  30 |   500/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.54 | ppl 135071730109355.03 | bpc   46.941\n",
      "| epoch  30 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.53 | ppl 134554887422271.94 | bpc   46.935\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 32.30s | valid loss  2.20 | valid ppl     9.05 | bpc    3.179\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  31 |    50/  559 batches | lr 0.0001 | ms/batch 41.58 | loss 33.28 | ppl 284517129037385.44 | bpc   48.016\n",
      "| epoch  31 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.64 | ppl 149360852378962.50 | bpc   47.086\n",
      "| epoch  31 |   150/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.64 | ppl 149478270393723.91 | bpc   47.087\n",
      "| epoch  31 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.64 | ppl 149645436602039.94 | bpc   47.089\n",
      "| epoch  31 |   250/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.64 | ppl 149604340899211.25 | bpc   47.088\n",
      "| epoch  31 |   300/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.63 | ppl 148325205598724.53 | bpc   47.076\n",
      "| epoch  31 |   350/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.63 | ppl 148840992663966.25 | bpc   47.081\n",
      "| epoch  31 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.64 | ppl 149744797828843.47 | bpc   47.090\n",
      "| epoch  31 |   450/  559 batches | lr 0.0001 | ms/batch 42.18 | loss 32.65 | ppl 150756997542714.09 | bpc   47.099\n",
      "| epoch  31 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.64 | ppl 150350381532432.16 | bpc   47.095\n",
      "| epoch  31 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.64 | ppl 149684259575722.25 | bpc   47.089\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 32.22s | valid loss  2.20 | valid ppl     9.06 | bpc    3.179\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  32 |    50/  559 batches | lr 0.0001 | ms/batch 40.52 | loss 33.39 | ppl 318444784499762.62 | bpc   48.178\n",
      "| epoch  32 |   100/  559 batches | lr 0.0001 | ms/batch 42.00 | loss 32.74 | ppl 165938380618135.88 | bpc   47.238\n",
      "| epoch  32 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.75 | ppl 166542096641547.72 | bpc   47.243\n",
      "| epoch  32 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.75 | ppl 166652676873143.69 | bpc   47.244\n",
      "| epoch  32 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.75 | ppl 166332577011498.88 | bpc   47.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  32 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.74 | ppl 165058314118117.47 | bpc   47.230\n",
      "| epoch  32 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.74 | ppl 165524911531242.44 | bpc   47.234\n",
      "| epoch  32 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.75 | ppl 166554803279874.72 | bpc   47.243\n",
      "| epoch  32 |   450/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.75 | ppl 167637139581599.03 | bpc   47.252\n",
      "| epoch  32 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.75 | ppl 167047932880808.94 | bpc   47.247\n",
      "| epoch  32 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.75 | ppl 166816139471823.06 | bpc   47.245\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 32.16s | valid loss  2.20 | valid ppl     9.06 | bpc    3.179\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| epoch  33 |    50/  559 batches | lr 0.0001 | ms/batch 41.55 | loss 33.50 | ppl 354102146496552.88 | bpc   48.331\n",
      "| epoch  33 |   100/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.85 | ppl 184396638773340.31 | bpc   47.390\n",
      "| epoch  33 |   150/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.85 | ppl 185413054227733.00 | bpc   47.398\n",
      "| epoch  33 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.86 | ppl 185781212483114.50 | bpc   47.401\n",
      "| epoch  33 |   250/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 32.85 | ppl 185493703355117.31 | bpc   47.398\n",
      "| epoch  33 |   300/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.85 | ppl 184179410863964.06 | bpc   47.388\n",
      "| epoch  33 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 32.85 | ppl 184559199795515.84 | bpc   47.391\n",
      "| epoch  33 |   400/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.86 | ppl 185742238122251.12 | bpc   47.400\n",
      "| epoch  33 |   450/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 32.86 | ppl 187039140763235.28 | bpc   47.410\n",
      "| epoch  33 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.86 | ppl 186163594266044.34 | bpc   47.404\n",
      "| epoch  33 |   550/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 32.86 | ppl 185706105566349.84 | bpc   47.400\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 32.22s | valid loss  2.20 | valid ppl     9.04 | bpc    3.177\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| epoch  34 |    50/  559 batches | lr 0.0001 | ms/batch 40.94 | loss 33.61 | ppl 394863764037231.56 | bpc   48.488\n",
      "| epoch  34 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 32.95 | ppl 205041038370845.00 | bpc   47.543\n",
      "| epoch  34 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.96 | ppl 205710885064285.06 | bpc   47.548\n",
      "| epoch  34 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.96 | ppl 205941723561924.69 | bpc   47.549\n",
      "| epoch  34 |   250/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 32.96 | ppl 205805858676323.78 | bpc   47.548\n",
      "| epoch  34 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.95 | ppl 204179339020664.22 | bpc   47.537\n",
      "| epoch  34 |   350/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.95 | ppl 204781522471161.88 | bpc   47.541\n",
      "| epoch  34 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 32.96 | ppl 205973935899425.25 | bpc   47.549\n",
      "| epoch  34 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 32.97 | ppl 207339322785886.19 | bpc   47.559\n",
      "| epoch  34 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 32.96 | ppl 206768263377680.81 | bpc   47.555\n",
      "| epoch  34 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 32.96 | ppl 206139791291390.38 | bpc   47.551\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 32.20s | valid loss  2.20 | valid ppl     9.06 | bpc    3.180\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| epoch  35 |    50/  559 batches | lr 0.0001 | ms/batch 42.04 | loss 33.72 | ppl 440710777384378.44 | bpc   48.647\n",
      "| epoch  35 |   100/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.06 | ppl 228269103105763.62 | bpc   47.698\n",
      "| epoch  35 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.07 | ppl 229246460305533.72 | bpc   47.704\n",
      "| epoch  35 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.07 | ppl 229345300767643.97 | bpc   47.705\n",
      "| epoch  35 |   250/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.06 | ppl 229023569740716.09 | bpc   47.702\n",
      "| epoch  35 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.06 | ppl 227786332810831.41 | bpc   47.695\n",
      "| epoch  35 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.06 | ppl 228379718643841.72 | bpc   47.698\n",
      "| epoch  35 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.07 | ppl 229465191049222.50 | bpc   47.705\n",
      "| epoch  35 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.07 | ppl 230869137561896.56 | bpc   47.714\n",
      "| epoch  35 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.07 | ppl 230050663966876.91 | bpc   47.709\n",
      "| epoch  35 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.07 | ppl 229471318512690.56 | bpc   47.705\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 32.27s | valid loss  2.20 | valid ppl     9.05 | bpc    3.178\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| epoch  36 |    50/  559 batches | lr 0.0001 | ms/batch 40.29 | loss 33.82 | ppl 489399221647383.69 | bpc   48.798\n",
      "| epoch  36 |   100/  559 batches | lr 0.0001 | ms/batch 42.12 | loss 33.17 | ppl 253465369847956.22 | bpc   47.849\n",
      "| epoch  36 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.17 | ppl 254511769029325.94 | bpc   47.855\n",
      "| epoch  36 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.17 | ppl 254281773184882.94 | bpc   47.853\n",
      "| epoch  36 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.17 | ppl 253809817821314.03 | bpc   47.851\n",
      "| epoch  36 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.16 | ppl 251685793852305.47 | bpc   47.839\n",
      "| epoch  36 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.16 | ppl 252677611327544.34 | bpc   47.844\n",
      "| epoch  36 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.17 | ppl 253972528833807.78 | bpc   47.852\n",
      "| epoch  36 |   450/  559 batches | lr 0.0001 | ms/batch 42.37 | loss 33.17 | ppl 255583936692686.84 | bpc   47.861\n",
      "| epoch  36 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.17 | ppl 254823614117446.59 | bpc   47.856\n",
      "| epoch  36 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.17 | ppl 253422830097389.28 | bpc   47.849\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 32.17s | valid loss  2.20 | valid ppl     9.02 | bpc    3.174\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 25\n",
      "| epoch  37 |    50/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.93 | ppl 543607616763968.31 | bpc   48.950\n",
      "| epoch  37 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.27 | ppl 280464282811782.69 | bpc   47.995\n",
      "| epoch  37 |   150/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.27 | ppl 281811284386105.19 | bpc   48.002\n",
      "| epoch  37 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.27 | ppl 282040357706795.75 | bpc   48.003\n",
      "| epoch  37 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.27 | ppl 281879019083347.25 | bpc   48.002\n",
      "| epoch  37 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.26 | ppl 279606478571124.19 | bpc   47.990\n",
      "| epoch  37 |   350/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.27 | ppl 280449304803083.78 | bpc   47.995\n",
      "| epoch  37 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.27 | ppl 282031750649478.94 | bpc   48.003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  37 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.28 | ppl 283465206778034.88 | bpc   48.010\n",
      "| epoch  37 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.28 | ppl 282949879473966.44 | bpc   48.008\n",
      "| epoch  37 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.27 | ppl 281823109906308.44 | bpc   48.002\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 32.29s | valid loss  2.20 | valid ppl     9.02 | bpc    3.172\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.199034 --> 2.198988).  Saving model ...\n",
      "| epoch  38 |    50/  559 batches | lr 0.0001 | ms/batch 40.11 | loss 34.03 | ppl 602276815071442.50 | bpc   49.097\n",
      "| epoch  38 |   100/  559 batches | lr 0.0001 | ms/batch 42.18 | loss 33.37 | ppl 310490666501995.75 | bpc   48.142\n",
      "| epoch  38 |   150/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.37 | ppl 310952937163782.56 | bpc   48.144\n",
      "| epoch  38 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.37 | ppl 311862888532164.69 | bpc   48.148\n",
      "| epoch  38 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.37 | ppl 311198575737388.50 | bpc   48.145\n",
      "| epoch  38 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.37 | ppl 309333274128703.62 | bpc   48.136\n",
      "| epoch  38 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.37 | ppl 310223101150889.38 | bpc   48.140\n",
      "| epoch  38 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.37 | ppl 311635745752089.69 | bpc   48.147\n",
      "| epoch  38 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.38 | ppl 313140817913754.19 | bpc   48.154\n",
      "| epoch  38 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.38 | ppl 312819652158150.75 | bpc   48.152\n",
      "| epoch  38 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.37 | ppl 310947006263748.50 | bpc   48.144\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 32.17s | valid loss  2.20 | valid ppl     9.03 | bpc    3.175\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  39 |    50/  559 batches | lr 0.0001 | ms/batch 41.01 | loss 34.13 | ppl 665655893041247.38 | bpc   49.242\n",
      "| epoch  39 |   100/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.47 | ppl 342455584845146.81 | bpc   48.283\n",
      "| epoch  39 |   150/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 33.47 | ppl 343759198702827.88 | bpc   48.288\n",
      "| epoch  39 |   200/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 33.47 | ppl 343578281782897.38 | bpc   48.288\n",
      "| epoch  39 |   250/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.47 | ppl 343291369923432.81 | bpc   48.286\n",
      "| epoch  39 |   300/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 33.46 | ppl 340434097245060.81 | bpc   48.274\n",
      "| epoch  39 |   350/  559 batches | lr 0.0001 | ms/batch 42.36 | loss 33.47 | ppl 342049546425697.06 | bpc   48.281\n",
      "| epoch  39 |   400/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.47 | ppl 343537654124075.69 | bpc   48.287\n",
      "| epoch  39 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.48 | ppl 345920491774782.25 | bpc   48.297\n",
      "| epoch  39 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.47 | ppl 344991436340098.44 | bpc   48.294\n",
      "| epoch  39 |   550/  559 batches | lr 0.0001 | ms/batch 42.34 | loss 33.47 | ppl 343773623715503.12 | bpc   48.288\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 32.24s | valid loss  2.20 | valid ppl     9.04 | bpc    3.176\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  40 |    50/  559 batches | lr 0.0001 | ms/batch 40.59 | loss 34.24 | ppl 740205799828205.88 | bpc   49.395\n",
      "| epoch  40 |   100/  559 batches | lr 0.0001 | ms/batch 42.06 | loss 33.57 | ppl 379801962521392.50 | bpc   48.432\n",
      "| epoch  40 |   150/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.57 | ppl 380871252282066.56 | bpc   48.436\n",
      "| epoch  40 |   200/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 33.57 | ppl 381045641216437.06 | bpc   48.437\n",
      "| epoch  40 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.57 | ppl 380487877508513.12 | bpc   48.435\n",
      "| epoch  40 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.56 | ppl 377441938017089.81 | bpc   48.423\n",
      "| epoch  40 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.57 | ppl 378816590085275.62 | bpc   48.428\n",
      "| epoch  40 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.57 | ppl 380421116847100.75 | bpc   48.435\n",
      "| epoch  40 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.58 | ppl 383532061633974.12 | bpc   48.446\n",
      "| epoch  40 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.58 | ppl 382356105879977.69 | bpc   48.442\n",
      "| epoch  40 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.57 | ppl 380495134808053.56 | bpc   48.435\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 32.18s | valid loss  2.20 | valid ppl     9.05 | bpc    3.178\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  41 |    50/  559 batches | lr 0.0001 | ms/batch 40.65 | loss 34.34 | ppl 818227448682912.00 | bpc   49.539\n",
      "| epoch  41 |   100/  559 batches | lr 0.0001 | ms/batch 41.55 | loss 33.67 | ppl 419110247116094.25 | bpc   48.574\n",
      "| epoch  41 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.67 | ppl 420044974683475.00 | bpc   48.578\n",
      "| epoch  41 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.67 | ppl 420583707590914.00 | bpc   48.579\n",
      "| epoch  41 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.67 | ppl 420485850606168.00 | bpc   48.579\n",
      "| epoch  41 |   300/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 33.66 | ppl 417339354647198.44 | bpc   48.568\n",
      "| epoch  41 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.67 | ppl 418982364333357.25 | bpc   48.574\n",
      "| epoch  41 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.67 | ppl 421174541225659.75 | bpc   48.581\n",
      "| epoch  41 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.68 | ppl 422787488545148.75 | bpc   48.587\n",
      "| epoch  41 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.68 | ppl 421948050924612.56 | bpc   48.584\n",
      "| epoch  41 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.67 | ppl 419449325293855.06 | bpc   48.575\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 32.15s | valid loss  2.20 | valid ppl     9.05 | bpc    3.178\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| epoch  42 |    50/  559 batches | lr 0.0001 | ms/batch 41.99 | loss 34.44 | ppl 907393196072507.50 | bpc   49.689\n",
      "| epoch  42 |   100/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 33.77 | ppl 463785354306841.81 | bpc   48.720\n",
      "| epoch  42 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.77 | ppl 465256118043318.12 | bpc   48.725\n",
      "| epoch  42 |   200/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.77 | ppl 465314690500901.38 | bpc   48.725\n",
      "| epoch  42 |   250/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.77 | ppl 464178283222284.19 | bpc   48.722\n",
      "| epoch  42 |   300/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 33.76 | ppl 460834906374087.62 | bpc   48.711\n",
      "| epoch  42 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.77 | ppl 463079980166943.50 | bpc   48.718\n",
      "| epoch  42 |   400/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 33.77 | ppl 465799527381601.12 | bpc   48.727\n",
      "| epoch  42 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 33.78 | ppl 468724539944558.25 | bpc   48.736\n",
      "| epoch  42 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.78 | ppl 466610491701766.38 | bpc   48.729\n",
      "| epoch  42 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.77 | ppl 464998841573695.81 | bpc   48.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 32.28s | valid loss  2.20 | valid ppl     9.06 | bpc    3.179\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| epoch  43 |    50/  559 batches | lr 0.0001 | ms/batch 40.31 | loss 34.54 | ppl 1003760718727007.50 | bpc   49.834\n",
      "| epoch  43 |   100/  559 batches | lr 0.0001 | ms/batch 42.10 | loss 33.87 | ppl 512068813373238.25 | bpc   48.863\n",
      "| epoch  43 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.87 | ppl 514224015750287.25 | bpc   48.869\n",
      "| epoch  43 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.87 | ppl 514757850288655.88 | bpc   48.871\n",
      "| epoch  43 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.87 | ppl 513604520781464.12 | bpc   48.868\n",
      "| epoch  43 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.87 | ppl 509897356844888.19 | bpc   48.857\n",
      "| epoch  43 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 33.87 | ppl 510713007120041.31 | bpc   48.860\n",
      "| epoch  43 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.87 | ppl 514096526975158.50 | bpc   48.869\n",
      "| epoch  43 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.88 | ppl 516614873144012.19 | bpc   48.876\n",
      "| epoch  43 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.88 | ppl 515953132264344.50 | bpc   48.874\n",
      "| epoch  43 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.87 | ppl 512352132910255.81 | bpc   48.864\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 32.16s | valid loss  2.21 | valid ppl     9.07 | bpc    3.182\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| epoch  44 |    50/  559 batches | lr 0.0001 | ms/batch 40.39 | loss 34.64 | ppl 1111515431160623.25 | bpc   49.981\n",
      "| epoch  44 |   100/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.97 | ppl 566106226836562.25 | bpc   49.008\n",
      "| epoch  44 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.97 | ppl 568762173539553.62 | bpc   49.015\n",
      "| epoch  44 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.97 | ppl 568423807969714.00 | bpc   49.014\n",
      "| epoch  44 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 33.97 | ppl 566791209982674.12 | bpc   49.010\n",
      "| epoch  44 |   300/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.96 | ppl 561595769842076.69 | bpc   48.997\n",
      "| epoch  44 |   350/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 33.97 | ppl 565534242166404.00 | bpc   49.007\n",
      "| epoch  44 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 33.97 | ppl 566901489690584.62 | bpc   49.010\n",
      "| epoch  44 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 33.98 | ppl 571395704604460.88 | bpc   49.021\n",
      "| epoch  44 |   500/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 33.97 | ppl 568629839950934.75 | bpc   49.014\n",
      "| epoch  44 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 33.97 | ppl 566451856123610.88 | bpc   49.009\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 32.18s | valid loss  2.20 | valid ppl     9.04 | bpc    3.177\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| epoch  45 |    50/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.75 | ppl 1229955324318835.75 | bpc   50.128\n",
      "| epoch  45 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.07 | ppl 623965243789480.50 | bpc   49.148\n",
      "| epoch  45 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 34.07 | ppl 626323745880117.38 | bpc   49.154\n",
      "| epoch  45 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.07 | ppl 627289741189059.50 | bpc   49.156\n",
      "| epoch  45 |   250/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 34.07 | ppl 625380708530521.75 | bpc   49.152\n",
      "| epoch  45 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.06 | ppl 620149535072723.62 | bpc   49.140\n",
      "| epoch  45 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.06 | ppl 622322664813421.62 | bpc   49.145\n",
      "| epoch  45 |   400/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 34.07 | ppl 626703749553033.75 | bpc   49.155\n",
      "| epoch  45 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.08 | ppl 630773902069649.25 | bpc   49.164\n",
      "| epoch  45 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.07 | ppl 627385465310463.38 | bpc   49.156\n",
      "| epoch  45 |   550/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 34.07 | ppl 625428423112241.62 | bpc   49.152\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 32.26s | valid loss  2.20 | valid ppl     9.00 | bpc    3.170\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.198988 --> 2.197507).  Saving model ...\n",
      "| epoch  46 |    50/  559 batches | lr 0.0001 | ms/batch 40.33 | loss 34.85 | ppl 1359588818649742.75 | bpc   50.272\n",
      "| epoch  46 |   100/  559 batches | lr 0.0001 | ms/batch 42.05 | loss 34.17 | ppl 690840476200784.50 | bpc   49.295\n",
      "| epoch  46 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.17 | ppl 692122442956075.75 | bpc   49.298\n",
      "| epoch  46 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.17 | ppl 693361822738345.38 | bpc   49.301\n",
      "| epoch  46 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.17 | ppl 691805686950428.50 | bpc   49.297\n",
      "| epoch  46 |   300/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 34.16 | ppl 687126748299187.50 | bpc   49.288\n",
      "| epoch  46 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.17 | ppl 688830001997200.88 | bpc   49.291\n",
      "| epoch  46 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 34.17 | ppl 691845273521933.88 | bpc   49.297\n",
      "| epoch  46 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.18 | ppl 696737052364988.25 | bpc   49.308\n",
      "| epoch  46 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.18 | ppl 695714534655938.88 | bpc   49.305\n",
      "| epoch  46 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.17 | ppl 693033924580344.38 | bpc   49.300\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 32.16s | valid loss  2.19 | valid ppl     8.97 | bpc    3.165\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.197507 --> 2.193919).  Saving model ...\n",
      "| epoch  47 |    50/  559 batches | lr 0.0001 | ms/batch 39.85 | loss 34.95 | ppl 1505346776151282.25 | bpc   50.419\n",
      "| epoch  47 |   100/  559 batches | lr 0.0001 | ms/batch 41.76 | loss 34.27 | ppl 762538025314529.12 | bpc   49.438\n",
      "| epoch  47 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.27 | ppl 763781117145219.62 | bpc   49.440\n",
      "| epoch  47 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.27 | ppl 764209535533696.75 | bpc   49.441\n",
      "| epoch  47 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.27 | ppl 763667495441535.75 | bpc   49.440\n",
      "| epoch  47 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.26 | ppl 758334726732877.88 | bpc   49.430\n",
      "| epoch  47 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.26 | ppl 760269592944998.38 | bpc   49.434\n",
      "| epoch  47 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.27 | ppl 763813167348785.12 | bpc   49.440\n",
      "| epoch  47 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.28 | ppl 768237296749404.75 | bpc   49.449\n",
      "| epoch  47 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.27 | ppl 767095215356584.12 | bpc   49.446\n",
      "| epoch  47 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.27 | ppl 763693714334370.62 | bpc   49.440\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 32.12s | valid loss  2.19 | valid ppl     8.95 | bpc    3.161\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.193919 --> 2.191106).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  48 |    50/  559 batches | lr 0.0001 | ms/batch 39.81 | loss 35.05 | ppl 1668009525676174.75 | bpc   50.567\n",
      "| epoch  48 |   100/  559 batches | lr 0.0001 | ms/batch 41.71 | loss 34.37 | ppl 842328599474267.12 | bpc   49.581\n",
      "| epoch  48 |   150/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 34.37 | ppl 844870878868673.88 | bpc   49.586\n",
      "| epoch  48 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.37 | ppl 845564092328517.50 | bpc   49.587\n",
      "| epoch  48 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.37 | ppl 845431854257707.75 | bpc   49.587\n",
      "| epoch  48 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 34.36 | ppl 838743859483282.75 | bpc   49.575\n",
      "| epoch  48 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 34.36 | ppl 838417568468625.12 | bpc   49.575\n",
      "| epoch  48 |   400/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 34.37 | ppl 844957902369217.62 | bpc   49.586\n",
      "| epoch  48 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.38 | ppl 849579756853319.62 | bpc   49.594\n",
      "| epoch  48 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.37 | ppl 846945764344163.75 | bpc   49.589\n",
      "| epoch  48 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.37 | ppl 842865379612263.12 | bpc   49.582\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 32.13s | valid loss  2.20 | valid ppl     8.99 | bpc    3.169\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  49 |    50/  559 batches | lr 0.0001 | ms/batch 40.15 | loss 35.15 | ppl 1841528081277824.25 | bpc   50.710\n",
      "| epoch  49 |   100/  559 batches | lr 0.0001 | ms/batch 41.54 | loss 34.47 | ppl 929567187401424.25 | bpc   49.724\n",
      "| epoch  49 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.47 | ppl 931665247824911.12 | bpc   49.727\n",
      "| epoch  49 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.47 | ppl 933728861987987.75 | bpc   49.730\n",
      "| epoch  49 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.47 | ppl 931611939037002.00 | bpc   49.727\n",
      "| epoch  49 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 34.46 | ppl 925745366714566.62 | bpc   49.718\n",
      "| epoch  49 |   350/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 34.46 | ppl 927194389284404.50 | bpc   49.720\n",
      "| epoch  49 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.47 | ppl 930979574236311.88 | bpc   49.726\n",
      "| epoch  49 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.47 | ppl 937479925910413.50 | bpc   49.736\n",
      "| epoch  49 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.47 | ppl 933646942044244.75 | bpc   49.730\n",
      "| epoch  49 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.47 | ppl 932276740001738.75 | bpc   49.728\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 32.12s | valid loss  2.20 | valid ppl     8.99 | bpc    3.168\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  50 |    50/  559 batches | lr 0.0001 | ms/batch 39.95 | loss 35.25 | ppl 2031508019761076.00 | bpc   50.851\n",
      "| epoch  50 |   100/  559 batches | lr 0.0001 | ms/batch 41.50 | loss 34.56 | ppl 1024007248380980.38 | bpc   49.863\n",
      "| epoch  50 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.56 | ppl 1025168070304329.00 | bpc   49.865\n",
      "| epoch  50 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.56 | ppl 1026028786708398.75 | bpc   49.866\n",
      "| epoch  50 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.56 | ppl 1025430121081907.25 | bpc   49.865\n",
      "| epoch  50 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.56 | ppl 1017089267006037.25 | bpc   49.853\n",
      "| epoch  50 |   350/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.56 | ppl 1017842243795660.50 | bpc   49.854\n",
      "| epoch  50 |   400/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 34.56 | ppl 1024347150936646.25 | bpc   49.864\n",
      "| epoch  50 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.57 | ppl 1029777391536699.75 | bpc   49.871\n",
      "| epoch  50 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.57 | ppl 1028179818416201.88 | bpc   49.869\n",
      "| epoch  50 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.56 | ppl 1023249710859682.75 | bpc   49.862\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 32.12s | valid loss  2.20 | valid ppl     9.01 | bpc    3.172\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  51 |    50/  559 batches | lr 0.0001 | ms/batch 40.68 | loss 35.35 | ppl 2244860416221609.25 | bpc   50.996\n",
      "| epoch  51 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.66 | ppl 1127585976198078.75 | bpc   50.002\n",
      "| epoch  51 |   150/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 34.66 | ppl 1128567121816364.50 | bpc   50.003\n",
      "| epoch  51 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.66 | ppl 1130846841323386.50 | bpc   50.006\n",
      "| epoch  51 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.66 | ppl 1129566356841492.75 | bpc   50.005\n",
      "| epoch  51 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.65 | ppl 1122020840073117.62 | bpc   49.995\n",
      "| epoch  51 |   350/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 34.66 | ppl 1123828526359974.38 | bpc   49.997\n",
      "| epoch  51 |   400/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 34.66 | ppl 1130739000506883.25 | bpc   50.006\n",
      "| epoch  51 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 34.67 | ppl 1135835984230475.50 | bpc   50.013\n",
      "| epoch  51 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.66 | ppl 1131217892282678.75 | bpc   50.007\n",
      "| epoch  51 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.66 | ppl 1128097958893975.50 | bpc   50.003\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 32.20s | valid loss  2.20 | valid ppl     9.00 | bpc    3.170\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| epoch  52 |    50/  559 batches | lr 0.0001 | ms/batch 40.74 | loss 35.44 | ppl 2474759429936962.50 | bpc   51.136\n",
      "| epoch  52 |   100/  559 batches | lr 0.0001 | ms/batch 41.90 | loss 34.76 | ppl 1243248440113223.75 | bpc   50.143\n",
      "| epoch  52 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 34.76 | ppl 1246791470890204.75 | bpc   50.147\n",
      "| epoch  52 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 34.76 | ppl 1246820008008873.75 | bpc   50.147\n",
      "| epoch  52 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.76 | ppl 1243746514581363.00 | bpc   50.144\n",
      "| epoch  52 |   300/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 34.75 | ppl 1233719289601959.00 | bpc   50.132\n",
      "| epoch  52 |   350/  559 batches | lr 0.0001 | ms/batch 42.18 | loss 34.75 | ppl 1238581003615442.75 | bpc   50.138\n",
      "| epoch  52 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.76 | ppl 1244016981421560.50 | bpc   50.144\n",
      "| epoch  52 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.76 | ppl 1252163170305106.50 | bpc   50.153\n",
      "| epoch  52 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.76 | ppl 1247719261666302.25 | bpc   50.148\n",
      "| epoch  52 |   550/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 34.76 | ppl 1243656372035996.50 | bpc   50.144\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 32.15s | valid loss  2.19 | valid ppl     8.96 | bpc    3.164\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| epoch  53 |    50/  559 batches | lr 0.0001 | ms/batch 41.33 | loss 35.55 | ppl 2741232387026068.00 | bpc   51.284\n",
      "| epoch  53 |   100/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.85 | ppl 1370555411102320.50 | bpc   50.284\n",
      "| epoch  53 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.86 | ppl 1374125722605509.50 | bpc   50.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  53 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 34.86 | ppl 1376355325780711.50 | bpc   50.290\n",
      "| epoch  53 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.86 | ppl 1373669755266221.50 | bpc   50.287\n",
      "| epoch  53 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.85 | ppl 1363785910780885.00 | bpc   50.277\n",
      "| epoch  53 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.85 | ppl 1365509002853157.00 | bpc   50.278\n",
      "| epoch  53 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.86 | ppl 1372056741686326.75 | bpc   50.285\n",
      "| epoch  53 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.86 | ppl 1382195602413645.50 | bpc   50.296\n",
      "| epoch  53 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.86 | ppl 1377048550313726.00 | bpc   50.291\n",
      "| epoch  53 |   550/  559 batches | lr 0.0001 | ms/batch 42.36 | loss 34.85 | ppl 1368977387547158.25 | bpc   50.282\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 32.22s | valid loss  2.19 | valid ppl     8.97 | bpc    3.165\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| epoch  54 |    50/  559 batches | lr 0.0001 | ms/batch 43.17 | loss 35.64 | ppl 3016931997881861.00 | bpc   51.422\n",
      "| epoch  54 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.95 | ppl 1505771776859753.75 | bpc   50.419\n",
      "| epoch  54 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 34.95 | ppl 1511745934750516.50 | bpc   50.425\n",
      "| epoch  54 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 34.95 | ppl 1513863852021905.50 | bpc   50.427\n",
      "| epoch  54 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.95 | ppl 1508232244073194.50 | bpc   50.422\n",
      "| epoch  54 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.94 | ppl 1497705816386075.25 | bpc   50.412\n",
      "| epoch  54 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 34.95 | ppl 1504313491340522.75 | bpc   50.418\n",
      "| epoch  54 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.95 | ppl 1510368284969324.75 | bpc   50.424\n",
      "| epoch  54 |   450/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 34.96 | ppl 1518380799426952.25 | bpc   50.431\n",
      "| epoch  54 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 34.95 | ppl 1515678267212987.50 | bpc   50.429\n",
      "| epoch  54 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 34.95 | ppl 1510518093940324.00 | bpc   50.424\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 32.31s | valid loss  2.19 | valid ppl     8.97 | bpc    3.164\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| epoch  55 |    50/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.74 | ppl 3330762633164084.50 | bpc   51.565\n",
      "| epoch  55 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.05 | ppl 1660720828739251.00 | bpc   50.561\n",
      "| epoch  55 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.05 | ppl 1665421813802856.25 | bpc   50.565\n",
      "| epoch  55 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.05 | ppl 1663320271360912.00 | bpc   50.563\n",
      "| epoch  55 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.05 | ppl 1660505447702033.50 | bpc   50.561\n",
      "| epoch  55 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.04 | ppl 1650514721211828.50 | bpc   50.552\n",
      "| epoch  55 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.04 | ppl 1652574867840330.00 | bpc   50.554\n",
      "| epoch  55 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.05 | ppl 1663212408782438.75 | bpc   50.563\n",
      "| epoch  55 |   450/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 35.05 | ppl 1674058909757883.50 | bpc   50.572\n",
      "| epoch  55 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.05 | ppl 1666680198826230.75 | bpc   50.566\n",
      "| epoch  55 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.05 | ppl 1660207761086290.00 | bpc   50.560\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 32.27s | valid loss  2.19 | valid ppl     8.92 | bpc    3.158\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.191106 --> 2.188691).  Saving model ...\n",
      "| epoch  56 |    50/  559 batches | lr 0.0001 | ms/batch 39.81 | loss 35.84 | ppl 3686550944258038.50 | bpc   51.711\n",
      "| epoch  56 |   100/  559 batches | lr 0.0001 | ms/batch 41.48 | loss 35.14 | ppl 1833096521449799.25 | bpc   50.703\n",
      "| epoch  56 |   150/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 35.15 | ppl 1838565970082649.50 | bpc   50.708\n",
      "| epoch  56 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.15 | ppl 1837892790385497.50 | bpc   50.707\n",
      "| epoch  56 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.15 | ppl 1836757358513746.75 | bpc   50.706\n",
      "| epoch  56 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.14 | ppl 1823784986069309.75 | bpc   50.696\n",
      "| epoch  56 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.14 | ppl 1829198740107589.00 | bpc   50.700\n",
      "| epoch  56 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.15 | ppl 1840081526063735.50 | bpc   50.709\n",
      "| epoch  56 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.15 | ppl 1845656301508541.00 | bpc   50.713\n",
      "| epoch  56 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.15 | ppl 1843095294266097.75 | bpc   50.711\n",
      "| epoch  56 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.15 | ppl 1836778378653844.00 | bpc   50.706\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 32.12s | valid loss  2.19 | valid ppl     8.97 | bpc    3.165\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  57 |    50/  559 batches | lr 0.0001 | ms/batch 42.09 | loss 35.94 | ppl 4076625755753309.00 | bpc   51.856\n",
      "| epoch  57 |   100/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.24 | ppl 2018676648022606.25 | bpc   50.842\n",
      "| epoch  57 |   150/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.24 | ppl 2026013256681979.50 | bpc   50.848\n",
      "| epoch  57 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.25 | ppl 2029896744762029.25 | bpc   50.850\n",
      "| epoch  57 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.25 | ppl 2027969543243503.75 | bpc   50.849\n",
      "| epoch  57 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.24 | ppl 2007717689337189.25 | bpc   50.834\n",
      "| epoch  57 |   350/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 35.24 | ppl 2016167799602641.00 | bpc   50.841\n",
      "| epoch  57 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.25 | ppl 2026554332826350.25 | bpc   50.848\n",
      "| epoch  57 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 35.25 | ppl 2040081605849225.50 | bpc   50.858\n",
      "| epoch  57 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.25 | ppl 2036691345921045.25 | bpc   50.855\n",
      "| epoch  57 |   550/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 35.24 | ppl 2025271444306055.75 | bpc   50.847\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 32.26s | valid loss  2.19 | valid ppl     8.98 | bpc    3.166\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  58 |    50/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.04 | ppl 4499847835611290.50 | bpc   51.999\n",
      "| epoch  58 |   100/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.34 | ppl 2227509732542872.00 | bpc   50.984\n",
      "| epoch  58 |   150/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.34 | ppl 2233261303338329.50 | bpc   50.988\n",
      "| epoch  58 |   200/  559 batches | lr 0.0001 | ms/batch 42.34 | loss 35.34 | ppl 2234565123803318.00 | bpc   50.989\n",
      "| epoch  58 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.34 | ppl 2227994129895392.75 | bpc   50.985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  58 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.33 | ppl 2211018390006668.75 | bpc   50.974\n",
      "| epoch  58 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.34 | ppl 2219231811374555.00 | bpc   50.979\n",
      "| epoch  58 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.34 | ppl 2229065276811655.00 | bpc   50.985\n",
      "| epoch  58 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.35 | ppl 2242566580904983.50 | bpc   50.994\n",
      "| epoch  58 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.34 | ppl 2238754422920073.75 | bpc   50.992\n",
      "| epoch  58 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.34 | ppl 2227280317924844.75 | bpc   50.984\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 32.27s | valid loss  2.20 | valid ppl     9.00 | bpc    3.170\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  59 |    50/  559 batches | lr 0.0001 | ms/batch 40.70 | loss 36.14 | ppl 4948567834533570.00 | bpc   52.136\n",
      "| epoch  59 |   100/  559 batches | lr 0.0001 | ms/batch 42.12 | loss 35.43 | ppl 2448634943779945.50 | bpc   51.121\n",
      "| epoch  59 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.44 | ppl 2458922032589120.50 | bpc   51.127\n",
      "| epoch  59 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.44 | ppl 2457637302414932.00 | bpc   51.126\n",
      "| epoch  59 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.44 | ppl 2451410733823923.50 | bpc   51.123\n",
      "| epoch  59 |   300/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 35.43 | ppl 2431508047421294.00 | bpc   51.111\n",
      "| epoch  59 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.43 | ppl 2439284020736636.50 | bpc   51.115\n",
      "| epoch  59 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.44 | ppl 2453618655534328.50 | bpc   51.124\n",
      "| epoch  59 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.44 | ppl 2470034277171285.50 | bpc   51.133\n",
      "| epoch  59 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.44 | ppl 2457056112324193.00 | bpc   51.126\n",
      "| epoch  59 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.43 | ppl 2450083196056467.00 | bpc   51.122\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 32.19s | valid loss  2.19 | valid ppl     8.96 | bpc    3.163\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| epoch  60 |    50/  559 batches | lr 0.0001 | ms/batch 39.93 | loss 36.24 | ppl 5463750063246011.00 | bpc   52.279\n",
      "| epoch  60 |   100/  559 batches | lr 0.0001 | ms/batch 41.42 | loss 35.53 | ppl 2695328072647348.00 | bpc   51.259\n",
      "| epoch  60 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.54 | ppl 2708200758542789.50 | bpc   51.266\n",
      "| epoch  60 |   200/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 35.54 | ppl 2709316732741670.50 | bpc   51.267\n",
      "| epoch  60 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.53 | ppl 2698630571480838.00 | bpc   51.261\n",
      "| epoch  60 |   300/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 35.52 | ppl 2678293676606075.00 | bpc   51.250\n",
      "| epoch  60 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.53 | ppl 2687566183690643.50 | bpc   51.255\n",
      "| epoch  60 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.53 | ppl 2703906484897790.00 | bpc   51.264\n",
      "| epoch  60 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.54 | ppl 2720398021500682.50 | bpc   51.273\n",
      "| epoch  60 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.54 | ppl 2711374222992044.50 | bpc   51.268\n",
      "| epoch  60 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.53 | ppl 2699310091290295.50 | bpc   51.262\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 32.13s | valid loss  2.20 | valid ppl     9.02 | bpc    3.173\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| epoch  61 |    50/  559 batches | lr 0.0001 | ms/batch 42.41 | loss 36.33 | ppl 6005427099682383.00 | bpc   52.415\n",
      "| epoch  61 |   100/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.62 | ppl 2961707148421773.00 | bpc   51.395\n",
      "| epoch  61 |   150/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 35.63 | ppl 2969920876742468.50 | bpc   51.399\n",
      "| epoch  61 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.63 | ppl 2969445082198741.00 | bpc   51.399\n",
      "| epoch  61 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.63 | ppl 2965369968744760.00 | bpc   51.397\n",
      "| epoch  61 |   300/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 35.62 | ppl 2936641836167377.50 | bpc   51.383\n",
      "| epoch  61 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.62 | ppl 2952806415086653.00 | bpc   51.391\n",
      "| epoch  61 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.62 | ppl 2962724144445181.50 | bpc   51.396\n",
      "| epoch  61 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 35.63 | ppl 2974319918886590.50 | bpc   51.401\n",
      "| epoch  61 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.63 | ppl 2970124812026808.50 | bpc   51.399\n",
      "| epoch  61 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.62 | ppl 2960995458925796.00 | bpc   51.395\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 32.28s | valid loss  2.20 | valid ppl     9.03 | bpc    3.174\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| epoch  62 |    50/  559 batches | lr 0.0001 | ms/batch 41.23 | loss 36.42 | ppl 6586519282143385.00 | bpc   52.548\n",
      "| epoch  62 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 35.71 | ppl 3232931910069351.00 | bpc   51.522\n",
      "| epoch  62 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.72 | ppl 3246600642469801.50 | bpc   51.528\n",
      "| epoch  62 |   200/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 35.72 | ppl 3243468799968192.00 | bpc   51.526\n",
      "| epoch  62 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.71 | ppl 3239375970580608.50 | bpc   51.525\n",
      "| epoch  62 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.71 | ppl 3214375391793681.00 | bpc   51.513\n",
      "| epoch  62 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.71 | ppl 3228396676515696.50 | bpc   51.520\n",
      "| epoch  62 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.71 | ppl 3240339978607318.50 | bpc   51.525\n",
      "| epoch  62 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.72 | ppl 3259779976666083.00 | bpc   51.534\n",
      "| epoch  62 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.72 | ppl 3250293410985265.50 | bpc   51.529\n",
      "| epoch  62 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.71 | ppl 3240513036053195.00 | bpc   51.525\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 32.22s | valid loss  2.20 | valid ppl     9.01 | bpc    3.172\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| epoch  63 |    50/  559 batches | lr 0.0001 | ms/batch 40.27 | loss 36.52 | ppl 7216016745613407.00 | bpc   52.680\n",
      "| epoch  63 |   100/  559 batches | lr 0.0001 | ms/batch 40.53 | loss 35.80 | ppl 3544023297663909.50 | bpc   51.654\n",
      "| epoch  63 |   150/  559 batches | lr 0.0001 | ms/batch 42.14 | loss 35.81 | ppl 3557975647331380.50 | bpc   51.660\n",
      "| epoch  63 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.81 | ppl 3556279476765466.00 | bpc   51.659\n",
      "| epoch  63 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.81 | ppl 3547932551800775.00 | bpc   51.656\n",
      "| epoch  63 |   300/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 35.80 | ppl 3521275907203916.50 | bpc   51.645\n",
      "| epoch  63 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.80 | ppl 3530731699395114.00 | bpc   51.649\n",
      "| epoch  63 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.81 | ppl 3551033258029165.00 | bpc   51.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  63 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.81 | ppl 3571860293352589.00 | bpc   51.666\n",
      "| epoch  63 |   500/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.81 | ppl 3560840618780383.00 | bpc   51.661\n",
      "| epoch  63 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.80 | ppl 3546511736065403.00 | bpc   51.655\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 32.09s | valid loss  2.20 | valid ppl     8.99 | bpc    3.168\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 25\n",
      "| epoch  64 |    50/  559 batches | lr 0.0001 | ms/batch 42.95 | loss 36.61 | ppl 7950861895094005.00 | bpc   52.820\n",
      "| epoch  64 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.90 | ppl 3892125409154791.00 | bpc   51.789\n",
      "| epoch  64 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.90 | ppl 3904944829950284.00 | bpc   51.794\n",
      "| epoch  64 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.90 | ppl 3911340524050674.50 | bpc   51.797\n",
      "| epoch  64 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.90 | ppl 3898574465729426.50 | bpc   51.792\n",
      "| epoch  64 |   300/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 35.89 | ppl 3866140713017114.00 | bpc   51.780\n",
      "| epoch  64 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.90 | ppl 3883819806766537.50 | bpc   51.786\n",
      "| epoch  64 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 35.90 | ppl 3900701724922096.00 | bpc   51.793\n",
      "| epoch  64 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 35.90 | ppl 3918763086323101.50 | bpc   51.799\n",
      "| epoch  64 |   500/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 35.90 | ppl 3911653868781360.00 | bpc   51.797\n",
      "| epoch  64 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 35.90 | ppl 3897964766274431.00 | bpc   51.792\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 32.31s | valid loss  2.19 | valid ppl     8.96 | bpc    3.164\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 25\n",
      "| epoch  65 |    50/  559 batches | lr 0.0001 | ms/batch 41.67 | loss 36.71 | ppl 8734045822714878.00 | bpc   52.956\n",
      "| epoch  65 |   100/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 35.99 | ppl 4277387562061904.50 | bpc   51.926\n",
      "| epoch  65 |   150/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 35.99 | ppl 4288644720045193.50 | bpc   51.929\n",
      "| epoch  65 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.99 | ppl 4283543473400904.50 | bpc   51.928\n",
      "| epoch  65 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.99 | ppl 4279280745784427.00 | bpc   51.926\n",
      "| epoch  65 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.98 | ppl 4245169339801258.50 | bpc   51.915\n",
      "| epoch  65 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 35.99 | ppl 4259184069671603.50 | bpc   51.919\n",
      "| epoch  65 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 35.99 | ppl 4282416132684719.00 | bpc   51.927\n",
      "| epoch  65 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.00 | ppl 4305528545490998.50 | bpc   51.935\n",
      "| epoch  65 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.00 | ppl 4291917944779924.50 | bpc   51.931\n",
      "| epoch  65 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 35.99 | ppl 4276734934309236.00 | bpc   51.925\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 32.23s | valid loss  2.20 | valid ppl     9.00 | bpc    3.170\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 25\n",
      "| epoch  66 |    50/  559 batches | lr 0.0001 | ms/batch 40.57 | loss 36.80 | ppl 9577737342337570.00 | bpc   53.089\n",
      "| epoch  66 |   100/  559 batches | lr 0.0001 | ms/batch 42.19 | loss 36.08 | ppl 4675461543050425.00 | bpc   52.054\n",
      "| epoch  66 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.09 | ppl 4694423324118952.00 | bpc   52.060\n",
      "| epoch  66 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.09 | ppl 4702775782367946.00 | bpc   52.062\n",
      "| epoch  66 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.08 | ppl 4681333096533160.00 | bpc   52.056\n",
      "| epoch  66 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.07 | ppl 4640953039373563.00 | bpc   52.043\n",
      "| epoch  66 |   350/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 36.08 | ppl 4663420297350204.00 | bpc   52.050\n",
      "| epoch  66 |   400/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 36.08 | ppl 4685495829603741.00 | bpc   52.057\n",
      "| epoch  66 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.09 | ppl 4710586015374232.00 | bpc   52.065\n",
      "| epoch  66 |   500/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.09 | ppl 4694996408818737.00 | bpc   52.060\n",
      "| epoch  66 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.08 | ppl 4673945773826312.00 | bpc   52.054\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 32.17s | valid loss  2.19 | valid ppl     8.97 | bpc    3.165\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 11 out of 25\n",
      "| epoch  67 |    50/  559 batches | lr 0.0001 | ms/batch 40.81 | loss 36.89 | ppl 10467010535161066.00 | bpc   53.217\n",
      "| epoch  67 |   100/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 36.17 | ppl 5106295005380618.00 | bpc   52.181\n",
      "| epoch  67 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.17 | ppl 5121511228098519.00 | bpc   52.185\n",
      "| epoch  67 |   200/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 36.17 | ppl 5115263197608686.00 | bpc   52.184\n",
      "| epoch  67 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.17 | ppl 5115048557126192.00 | bpc   52.184\n",
      "| epoch  67 |   300/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 36.16 | ppl 5069438101035885.00 | bpc   52.171\n",
      "| epoch  67 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.17 | ppl 5087745841115286.00 | bpc   52.176\n",
      "| epoch  67 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.17 | ppl 5111108578261264.00 | bpc   52.183\n",
      "| epoch  67 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.18 | ppl 5137556662689846.00 | bpc   52.190\n",
      "| epoch  67 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.17 | ppl 5115536389431090.00 | bpc   52.184\n",
      "| epoch  67 |   550/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 36.17 | ppl 5098100940725413.00 | bpc   52.179\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 32.21s | valid loss  2.19 | valid ppl     8.95 | bpc    3.161\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 12 out of 25\n",
      "| epoch  68 |    50/  559 batches | lr 0.0001 | ms/batch 42.02 | loss 36.98 | ppl 11433703052843074.00 | bpc   53.344\n",
      "| epoch  68 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.26 | ppl 5566902746823306.00 | bpc   52.306\n",
      "| epoch  68 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.26 | ppl 5574595506769889.00 | bpc   52.308\n",
      "| epoch  68 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.26 | ppl 5571661654664262.00 | bpc   52.307\n",
      "| epoch  68 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.25 | ppl 5563039127324617.00 | bpc   52.305\n",
      "| epoch  68 |   300/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 36.25 | ppl 5516021530175407.00 | bpc   52.293\n",
      "| epoch  68 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.25 | ppl 5538920490028379.00 | bpc   52.299\n",
      "| epoch  68 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.26 | ppl 5567582341859613.00 | bpc   52.306\n",
      "| epoch  68 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.26 | ppl 5602886229790493.00 | bpc   52.315\n",
      "| epoch  68 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.26 | ppl 5575786496053992.00 | bpc   52.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  68 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.25 | ppl 5548775502868778.00 | bpc   52.301\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 32.26s | valid loss  2.19 | valid ppl     8.95 | bpc    3.161\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 13 out of 25\n",
      "| epoch  69 |    50/  559 batches | lr 0.0001 | ms/batch 40.57 | loss 37.07 | ppl 12533059415703168.00 | bpc   53.477\n",
      "| epoch  69 |   100/  559 batches | lr 0.0001 | ms/batch 42.00 | loss 36.35 | ppl 6101860671573165.00 | bpc   52.438\n",
      "| epoch  69 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.35 | ppl 6107076892138710.00 | bpc   52.439\n",
      "| epoch  69 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.35 | ppl 6115866047515208.00 | bpc   52.441\n",
      "| epoch  69 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.35 | ppl 6103583394303567.00 | bpc   52.439\n",
      "| epoch  69 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.34 | ppl 6057355681982285.00 | bpc   52.428\n",
      "| epoch  69 |   350/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 36.34 | ppl 6070587303983089.00 | bpc   52.431\n",
      "| epoch  69 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.35 | ppl 6104351792322646.00 | bpc   52.439\n",
      "| epoch  69 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.36 | ppl 6150844308085486.00 | bpc   52.450\n",
      "| epoch  69 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.35 | ppl 6127285151519673.00 | bpc   52.444\n",
      "| epoch  69 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.35 | ppl 6089977837128732.00 | bpc   52.435\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 32.17s | valid loss  2.19 | valid ppl     8.96 | bpc    3.163\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 14 out of 25\n",
      "| epoch  70 |    50/  559 batches | lr 0.0001 | ms/batch 40.55 | loss 37.16 | ppl 13747398581898620.00 | bpc   53.610\n",
      "| epoch  70 |   100/  559 batches | lr 0.0001 | ms/batch 41.83 | loss 36.44 | ppl 6676347237130465.00 | bpc   52.568\n",
      "| epoch  70 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.44 | ppl 6683176216572586.00 | bpc   52.569\n",
      "| epoch  70 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.44 | ppl 6687435120109783.00 | bpc   52.570\n",
      "| epoch  70 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.44 | ppl 6683125228179013.00 | bpc   52.569\n",
      "| epoch  70 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.43 | ppl 6619288907216058.00 | bpc   52.556\n",
      "| epoch  70 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.43 | ppl 6648872752883233.00 | bpc   52.562\n",
      "| epoch  70 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.44 | ppl 6678767158726460.00 | bpc   52.569\n",
      "| epoch  70 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.44 | ppl 6716990423335238.00 | bpc   52.577\n",
      "| epoch  70 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.44 | ppl 6691747791454048.00 | bpc   52.571\n",
      "| epoch  70 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.44 | ppl 6668736573474643.00 | bpc   52.566\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 32.15s | valid loss  2.19 | valid ppl     8.95 | bpc    3.162\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 15 out of 25\n",
      "| epoch  71 |    50/  559 batches | lr 0.0001 | ms/batch 40.14 | loss 37.25 | ppl 15109683788134206.00 | bpc   53.746\n",
      "| epoch  71 |   100/  559 batches | lr 0.0001 | ms/batch 41.91 | loss 36.53 | ppl 7308238186669372.00 | bpc   52.698\n",
      "| epoch  71 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.53 | ppl 7312951208753120.00 | bpc   52.699\n",
      "| epoch  71 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.53 | ppl 7327360079804428.00 | bpc   52.702\n",
      "| epoch  71 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.53 | ppl 7307123123095046.00 | bpc   52.698\n",
      "| epoch  71 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.52 | ppl 7258505273685279.00 | bpc   52.689\n",
      "| epoch  71 |   350/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 36.52 | ppl 7272252018731652.00 | bpc   52.691\n",
      "| epoch  71 |   400/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.53 | ppl 7317751014760820.00 | bpc   52.700\n",
      "| epoch  71 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.53 | ppl 7357217215244250.00 | bpc   52.708\n",
      "| epoch  71 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.53 | ppl 7331470126160267.00 | bpc   52.703\n",
      "| epoch  71 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.53 | ppl 7289277419805733.00 | bpc   52.695\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 32.13s | valid loss  2.19 | valid ppl     8.95 | bpc    3.162\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 16 out of 25\n",
      "| epoch  72 |    50/  559 batches | lr 0.0001 | ms/batch 43.06 | loss 37.34 | ppl 16530674997840540.00 | bpc   53.876\n",
      "| epoch  72 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.62 | ppl 7985696311710125.00 | bpc   52.826\n",
      "| epoch  72 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.62 | ppl 8007507097668583.00 | bpc   52.830\n",
      "| epoch  72 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.62 | ppl 8006987828843710.00 | bpc   52.830\n",
      "| epoch  72 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.62 | ppl 7988255614899124.00 | bpc   52.827\n",
      "| epoch  72 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.61 | ppl 7932321505411023.00 | bpc   52.817\n",
      "| epoch  72 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.61 | ppl 7954380968851389.00 | bpc   52.821\n",
      "| epoch  72 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.62 | ppl 7991760753015652.00 | bpc   52.827\n",
      "| epoch  72 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.62 | ppl 8024416984466800.00 | bpc   52.833\n",
      "| epoch  72 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.62 | ppl 8008087496794944.00 | bpc   52.830\n",
      "| epoch  72 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 36.61 | ppl 7965372923642043.00 | bpc   52.823\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 32.30s | valid loss  2.19 | valid ppl     8.93 | bpc    3.159\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 17 out of 25\n",
      "| epoch  73 |    50/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.43 | ppl 18085027461982076.00 | bpc   54.006\n",
      "| epoch  73 |   100/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.70 | ppl 8721161369977628.00 | bpc   52.953\n",
      "| epoch  73 |   150/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.71 | ppl 8726452680381373.00 | bpc   52.954\n",
      "| epoch  73 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.71 | ppl 8740478514374266.00 | bpc   52.957\n",
      "| epoch  73 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.71 | ppl 8727251647558913.00 | bpc   52.954\n",
      "| epoch  73 |   300/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 36.70 | ppl 8654349128379366.00 | bpc   52.942\n",
      "| epoch  73 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.70 | ppl 8681330297105322.00 | bpc   52.947\n",
      "| epoch  73 |   400/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.71 | ppl 8734678882730095.00 | bpc   52.956\n",
      "| epoch  73 |   450/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 36.71 | ppl 8784936430400543.00 | bpc   52.964\n",
      "| epoch  73 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.71 | ppl 8751521779388905.00 | bpc   52.958\n",
      "| epoch  73 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.70 | ppl 8720196634218645.00 | bpc   52.953\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 32.26s | valid loss  2.19 | valid ppl     8.89 | bpc    3.152\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.188691 --> 2.185001).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  74 |    50/  559 batches | lr 0.0001 | ms/batch 40.15 | loss 37.53 | ppl 19835939629836552.00 | bpc   54.139\n",
      "| epoch  74 |   100/  559 batches | lr 0.0001 | ms/batch 42.19 | loss 36.80 | ppl 9556824981485938.00 | bpc   53.085\n",
      "| epoch  74 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.80 | ppl 9578431554695824.00 | bpc   53.089\n",
      "| epoch  74 |   200/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 36.80 | ppl 9576129885832632.00 | bpc   53.088\n",
      "| epoch  74 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.80 | ppl 9557043722353968.00 | bpc   53.085\n",
      "| epoch  74 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.79 | ppl 9481802093409618.00 | bpc   53.074\n",
      "| epoch  74 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.79 | ppl 9505305638453390.00 | bpc   53.078\n",
      "| epoch  74 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.79 | ppl 9545129641009636.00 | bpc   53.084\n",
      "| epoch  74 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.80 | ppl 9608916798931090.00 | bpc   53.093\n",
      "| epoch  74 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.80 | ppl 9586766028827570.00 | bpc   53.090\n",
      "| epoch  74 |   550/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 36.79 | ppl 9536358434530922.00 | bpc   53.082\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 32.16s | valid loss  2.19 | valid ppl     8.90 | bpc    3.153\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  75 |    50/  559 batches | lr 0.0001 | ms/batch 40.11 | loss 37.62 | ppl 21682793402400172.00 | bpc   54.267\n",
      "| epoch  75 |   100/  559 batches | lr 0.0001 | ms/batch 42.02 | loss 36.88 | ppl 10411219955754538.00 | bpc   53.209\n",
      "| epoch  75 |   150/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 36.88 | ppl 10428908430228048.00 | bpc   53.211\n",
      "| epoch  75 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.88 | ppl 10432807905663508.00 | bpc   53.212\n",
      "| epoch  75 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.88 | ppl 10405145233877242.00 | bpc   53.208\n",
      "| epoch  75 |   300/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.87 | ppl 10331026770655454.00 | bpc   53.198\n",
      "| epoch  75 |   350/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.88 | ppl 10359677897493978.00 | bpc   53.202\n",
      "| epoch  75 |   400/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.88 | ppl 10409115238954686.00 | bpc   53.209\n",
      "| epoch  75 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.89 | ppl 10465812749406192.00 | bpc   53.217\n",
      "| epoch  75 |   500/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.88 | ppl 10428948213432400.00 | bpc   53.211\n",
      "| epoch  75 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 36.88 | ppl 10374983058650942.00 | bpc   53.204\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 32.15s | valid loss  2.18 | valid ppl     8.87 | bpc    3.149\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.185001 --> 2.182979).  Saving model ...\n",
      "| epoch  76 |    50/  559 batches | lr 0.0001 | ms/batch 42.83 | loss 37.70 | ppl 23687139264111192.00 | bpc   54.395\n",
      "| epoch  76 |   100/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.97 | ppl 11345504276980976.00 | bpc   53.333\n",
      "| epoch  76 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.97 | ppl 11369723422703374.00 | bpc   53.336\n",
      "| epoch  76 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 36.97 | ppl 11379312687921498.00 | bpc   53.337\n",
      "| epoch  76 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 36.97 | ppl 11378574765087930.00 | bpc   53.337\n",
      "| epoch  76 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.96 | ppl 11258801860152394.00 | bpc   53.322\n",
      "| epoch  76 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 36.96 | ppl 11311494258718134.00 | bpc   53.329\n",
      "| epoch  76 |   400/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 36.97 | ppl 11371545194858934.00 | bpc   53.336\n",
      "| epoch  76 |   450/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 36.97 | ppl 11422324911809928.00 | bpc   53.343\n",
      "| epoch  76 |   500/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 36.97 | ppl 11394646257052938.00 | bpc   53.339\n",
      "| epoch  76 |   550/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 36.97 | ppl 11339143949828802.00 | bpc   53.332\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 32.29s | valid loss  2.18 | valid ppl     8.85 | bpc    3.146\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (2.182979 --> 2.180601).  Saving model ...\n",
      "| epoch  77 |    50/  559 batches | lr 0.0001 | ms/batch 39.75 | loss 37.79 | ppl 25944867833721664.00 | bpc   54.526\n",
      "| epoch  77 |   100/  559 batches | lr 0.0001 | ms/batch 40.93 | loss 37.06 | ppl 12392574665363752.00 | bpc   53.460\n",
      "| epoch  77 |   150/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 37.06 | ppl 12459743184665066.00 | bpc   53.468\n",
      "| epoch  77 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.06 | ppl 12446821689155192.00 | bpc   53.467\n",
      "| epoch  77 |   250/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.06 | ppl 12426611270246422.00 | bpc   53.464\n",
      "| epoch  77 |   300/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 37.05 | ppl 12308852991656728.00 | bpc   53.451\n",
      "| epoch  77 |   350/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 37.05 | ppl 12366554090942592.00 | bpc   53.457\n",
      "| epoch  77 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.06 | ppl 12443640878259388.00 | bpc   53.466\n",
      "| epoch  77 |   450/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.06 | ppl 12478103335989780.00 | bpc   53.470\n",
      "| epoch  77 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.06 | ppl 12446916651230770.00 | bpc   53.467\n",
      "| epoch  77 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.06 | ppl 12400992280771402.00 | bpc   53.461\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 32.08s | valid loss  2.18 | valid ppl     8.85 | bpc    3.146\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 25\n",
      "| epoch  78 |    50/  559 batches | lr 0.0001 | ms/batch 40.57 | loss 37.88 | ppl 28384962922390292.00 | bpc   54.656\n",
      "| epoch  78 |   100/  559 batches | lr 0.0001 | ms/batch 42.00 | loss 37.15 | ppl 13566468117042016.00 | bpc   53.591\n",
      "| epoch  78 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.15 | ppl 13589983868155254.00 | bpc   53.593\n",
      "| epoch  78 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.15 | ppl 13589620981280226.00 | bpc   53.593\n",
      "| epoch  78 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.15 | ppl 13572886879166614.00 | bpc   53.592\n",
      "| epoch  78 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.14 | ppl 13453244162998246.00 | bpc   53.579\n",
      "| epoch  78 |   350/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.14 | ppl 13506465413846696.00 | bpc   53.584\n",
      "| epoch  78 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.15 | ppl 13566726879353908.00 | bpc   53.591\n",
      "| epoch  78 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.15 | ppl 13653951043156924.00 | bpc   53.600\n",
      "| epoch  78 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.15 | ppl 13610165249505148.00 | bpc   53.596\n",
      "| epoch  78 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.15 | ppl 13552295485681660.00 | bpc   53.589\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 32.16s | valid loss  2.18 | valid ppl     8.87 | bpc    3.149\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 25\n",
      "| epoch  79 |    50/  559 batches | lr 0.0001 | ms/batch 40.03 | loss 37.97 | ppl 31039269041125956.00 | bpc   54.785\n",
      "| epoch  79 |   100/  559 batches | lr 0.0001 | ms/batch 41.77 | loss 37.23 | ppl 14811502213740002.00 | bpc   53.718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  79 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.24 | ppl 14865956412880502.00 | bpc   53.723\n",
      "| epoch  79 |   200/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.24 | ppl 14849010051320500.00 | bpc   53.721\n",
      "| epoch  79 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.23 | ppl 14807152245064520.00 | bpc   53.717\n",
      "| epoch  79 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.23 | ppl 14694724601112714.00 | bpc   53.706\n",
      "| epoch  79 |   350/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.23 | ppl 14754714449061948.00 | bpc   53.712\n",
      "| epoch  79 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.24 | ppl 14829593700699056.00 | bpc   53.719\n",
      "| epoch  79 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.24 | ppl 14931087328989472.00 | bpc   53.729\n",
      "| epoch  79 |   500/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.24 | ppl 14862384167382718.00 | bpc   53.723\n",
      "| epoch  79 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.23 | ppl 14780402639515204.00 | bpc   53.715\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 32.11s | valid loss  2.18 | valid ppl     8.88 | bpc    3.150\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 25\n",
      "| epoch  80 |    50/  559 batches | lr 0.0001 | ms/batch 39.99 | loss 38.07 | ppl 34050068149402272.00 | bpc   54.919\n",
      "| epoch  80 |   100/  559 batches | lr 0.0001 | ms/batch 42.06 | loss 37.32 | ppl 16160498300560950.00 | bpc   53.843\n",
      "| epoch  80 |   150/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.33 | ppl 16233963550784616.00 | bpc   53.850\n",
      "| epoch  80 |   200/  559 batches | lr 0.0001 | ms/batch 42.20 | loss 37.33 | ppl 16226348235773598.00 | bpc   53.849\n",
      "| epoch  80 |   250/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.32 | ppl 16194439969110510.00 | bpc   53.846\n",
      "| epoch  80 |   300/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.32 | ppl 16066697637325518.00 | bpc   53.835\n",
      "| epoch  80 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.32 | ppl 16109473321579732.00 | bpc   53.839\n",
      "| epoch  80 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.32 | ppl 16191907314851906.00 | bpc   53.846\n",
      "| epoch  80 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.33 | ppl 16290664218481880.00 | bpc   53.855\n",
      "| epoch  80 |   500/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 37.33 | ppl 16236069227650994.00 | bpc   53.850\n",
      "| epoch  80 |   550/  559 batches | lr 0.0001 | ms/batch 42.20 | loss 37.32 | ppl 16170241527066466.00 | bpc   53.844\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 32.12s | valid loss  2.18 | valid ppl     8.88 | bpc    3.151\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 25\n",
      "| epoch  81 |    50/  559 batches | lr 0.0001 | ms/batch 40.81 | loss 38.15 | ppl 37177494273823856.00 | bpc   55.045\n",
      "| epoch  81 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.41 | ppl 17661034666612284.00 | bpc   53.971\n",
      "| epoch  81 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.41 | ppl 17709338597873902.00 | bpc   53.975\n",
      "| epoch  81 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.41 | ppl 17717379558926346.00 | bpc   53.976\n",
      "| epoch  81 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.41 | ppl 17699343166427982.00 | bpc   53.975\n",
      "| epoch  81 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.41 | ppl 17583257605219988.00 | bpc   53.965\n",
      "| epoch  81 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.41 | ppl 17621061300757048.00 | bpc   53.968\n",
      "| epoch  81 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.41 | ppl 17696845190187786.00 | bpc   53.974\n",
      "| epoch  81 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 37.42 | ppl 17789776977400844.00 | bpc   53.982\n",
      "| epoch  81 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.41 | ppl 17739561785572254.00 | bpc   53.978\n",
      "| epoch  81 |   550/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.41 | ppl 17644536359819350.00 | bpc   53.970\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 32.19s | valid loss  2.19 | valid ppl     8.89 | bpc    3.153\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 25\n",
      "| epoch  82 |    50/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 38.24 | ppl 40660822956978248.00 | bpc   55.174\n",
      "| epoch  82 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.50 | ppl 19284781401835788.00 | bpc   54.098\n",
      "| epoch  82 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.50 | ppl 19335092221009476.00 | bpc   54.102\n",
      "| epoch  82 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.50 | ppl 19340698605443648.00 | bpc   54.102\n",
      "| epoch  82 |   250/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 37.50 | ppl 19324252904480148.00 | bpc   54.101\n",
      "| epoch  82 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.49 | ppl 19154497403584132.00 | bpc   54.089\n",
      "| epoch  82 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.49 | ppl 19215460362730172.00 | bpc   54.093\n",
      "| epoch  82 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.50 | ppl 19331035982752248.00 | bpc   54.102\n",
      "| epoch  82 |   450/  559 batches | lr 0.0001 | ms/batch 42.33 | loss 37.51 | ppl 19431363395351132.00 | bpc   54.109\n",
      "| epoch  82 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.50 | ppl 19377105831933192.00 | bpc   54.105\n",
      "| epoch  82 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.50 | ppl 19264414492295392.00 | bpc   54.097\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 32.27s | valid loss  2.18 | valid ppl     8.88 | bpc    3.151\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 25\n",
      "| epoch  83 |    50/  559 batches | lr 0.0001 | ms/batch 43.05 | loss 38.33 | ppl 44433384571440248.00 | bpc   55.302\n",
      "| epoch  83 |   100/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 37.58 | ppl 21011114875740128.00 | bpc   54.222\n",
      "| epoch  83 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.59 | ppl 21066090135582524.00 | bpc   54.226\n",
      "| epoch  83 |   200/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.59 | ppl 21102525029984840.00 | bpc   54.228\n",
      "| epoch  83 |   250/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.59 | ppl 21053316649495648.00 | bpc   54.225\n",
      "| epoch  83 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.58 | ppl 20926326310890640.00 | bpc   54.216\n",
      "| epoch  83 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.58 | ppl 20962919308658188.00 | bpc   54.219\n",
      "| epoch  83 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.59 | ppl 21108563374575500.00 | bpc   54.229\n",
      "| epoch  83 |   450/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 37.59 | ppl 21206221147339400.00 | bpc   54.235\n",
      "| epoch  83 |   500/  559 batches | lr 0.0001 | ms/batch 42.19 | loss 37.59 | ppl 21120484110624768.00 | bpc   54.229\n",
      "| epoch  83 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.59 | ppl 21041353557279252.00 | bpc   54.224\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 32.29s | valid loss  2.19 | valid ppl     8.91 | bpc    3.155\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 25\n",
      "| epoch  84 |    50/  559 batches | lr 0.0001 | ms/batch 40.55 | loss 38.42 | ppl 48482674884319504.00 | bpc   55.428\n",
      "| epoch  84 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.67 | ppl 22929654589622140.00 | bpc   54.348\n",
      "| epoch  84 |   150/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.68 | ppl 23023965399112844.00 | bpc   54.354\n",
      "| epoch  84 |   200/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.68 | ppl 23025107210376504.00 | bpc   54.354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  84 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.68 | ppl 23048307017215616.00 | bpc   54.356\n",
      "| epoch  84 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.67 | ppl 22834946107126776.00 | bpc   54.342\n",
      "| epoch  84 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.67 | ppl 22925981156895788.00 | bpc   54.348\n",
      "| epoch  84 |   400/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.67 | ppl 23009390324354800.00 | bpc   54.353\n",
      "| epoch  84 |   450/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.68 | ppl 23168545597422756.00 | bpc   54.363\n",
      "| epoch  84 |   500/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.68 | ppl 23075403004635684.00 | bpc   54.357\n",
      "| epoch  84 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.67 | ppl 22963530358950120.00 | bpc   54.350\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 32.18s | valid loss  2.19 | valid ppl     8.92 | bpc    3.157\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 25\n",
      "| epoch  85 |    50/  559 batches | lr 0.0001 | ms/batch 42.48 | loss 38.51 | ppl 52969842946338280.00 | bpc   55.556\n",
      "| epoch  85 |   100/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.76 | ppl 25040279042766392.00 | bpc   54.475\n",
      "| epoch  85 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.76 | ppl 25077177340397768.00 | bpc   54.477\n",
      "| epoch  85 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.76 | ppl 25053273280595932.00 | bpc   54.476\n",
      "| epoch  85 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.76 | ppl 25016791878187220.00 | bpc   54.474\n",
      "| epoch  85 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.75 | ppl 24835653856355720.00 | bpc   54.463\n",
      "| epoch  85 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.75 | ppl 24885822183495056.00 | bpc   54.466\n",
      "| epoch  85 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.76 | ppl 25058816991731676.00 | bpc   54.476\n",
      "| epoch  85 |   450/  559 batches | lr 0.0001 | ms/batch 42.19 | loss 37.76 | ppl 25178399984994556.00 | bpc   54.483\n",
      "| epoch  85 |   500/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 37.76 | ppl 25077081678740400.00 | bpc   54.477\n",
      "| epoch  85 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.76 | ppl 24983699059313004.00 | bpc   54.472\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 32.26s | valid loss  2.19 | valid ppl     8.91 | bpc    3.155\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 25\n",
      "| epoch  86 |    50/  559 batches | lr 0.0001 | ms/batch 40.94 | loss 38.60 | ppl 58109674005423544.00 | bpc   55.690\n",
      "| epoch  86 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.85 | ppl 27404600747102044.00 | bpc   54.605\n",
      "| epoch  86 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.85 | ppl 27426981495752260.00 | bpc   54.606\n",
      "| epoch  86 |   200/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.85 | ppl 27483537567623160.00 | bpc   54.609\n",
      "| epoch  86 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.85 | ppl 27450008795929980.00 | bpc   54.608\n",
      "| epoch  86 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.84 | ppl 27271115377244332.00 | bpc   54.598\n",
      "| epoch  86 |   350/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.84 | ppl 27262794163084620.00 | bpc   54.598\n",
      "| epoch  86 |   400/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.85 | ppl 27436608743086104.00 | bpc   54.607\n",
      "| epoch  86 |   450/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.86 | ppl 27618905540850384.00 | bpc   54.617\n",
      "| epoch  86 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.86 | ppl 27557445092693920.00 | bpc   54.613\n",
      "| epoch  86 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 37.85 | ppl 27413383535646412.00 | bpc   54.606\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 32.19s | valid loss  2.19 | valid ppl     8.91 | bpc    3.156\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 25\n",
      "| epoch  87 |    50/  559 batches | lr 0.0001 | ms/batch 41.19 | loss 38.69 | ppl 63487355626057552.00 | bpc   55.817\n",
      "| epoch  87 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.94 | ppl 29868967678551308.00 | bpc   54.729\n",
      "| epoch  87 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 37.94 | ppl 29991133777398188.00 | bpc   54.735\n",
      "| epoch  87 |   200/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 37.94 | ppl 30005323613094796.00 | bpc   54.736\n",
      "| epoch  87 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 37.94 | ppl 29922568017008500.00 | bpc   54.732\n",
      "| epoch  87 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 37.93 | ppl 29734252225756116.00 | bpc   54.723\n",
      "| epoch  87 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 37.93 | ppl 29818989408902528.00 | bpc   54.727\n",
      "| epoch  87 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.94 | ppl 29982783222144824.00 | bpc   54.735\n",
      "| epoch  87 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.94 | ppl 30107711782759664.00 | bpc   54.741\n",
      "| epoch  87 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.94 | ppl 30026162789437560.00 | bpc   54.737\n",
      "| epoch  87 |   550/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 37.94 | ppl 29874209427627832.00 | bpc   54.730\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 32.23s | valid loss  2.19 | valid ppl     8.90 | bpc    3.154\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 11 out of 25\n",
      "| epoch  88 |    50/  559 batches | lr 0.0001 | ms/batch 39.92 | loss 38.78 | ppl 69585857031854560.00 | bpc   55.950\n",
      "| epoch  88 |   100/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.02 | ppl 32638628942987824.00 | bpc   54.857\n",
      "| epoch  88 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.03 | ppl 32745755438209876.00 | bpc   54.862\n",
      "| epoch  88 |   200/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.03 | ppl 32765247999997984.00 | bpc   54.863\n",
      "| epoch  88 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.03 | ppl 32713418393220864.00 | bpc   54.861\n",
      "| epoch  88 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.02 | ppl 32454383314216832.00 | bpc   54.849\n",
      "| epoch  88 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.02 | ppl 32559663002242976.00 | bpc   54.854\n",
      "| epoch  88 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.03 | ppl 32714791131686496.00 | bpc   54.861\n",
      "| epoch  88 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.03 | ppl 32897754107191904.00 | bpc   54.869\n",
      "| epoch  88 |   500/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.03 | ppl 32822042400020464.00 | bpc   54.866\n",
      "| epoch  88 |   550/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.03 | ppl 32672512283479696.00 | bpc   54.859\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 32.16s | valid loss  2.19 | valid ppl     8.90 | bpc    3.154\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 12 out of 25\n",
      "| epoch  89 |    50/  559 batches | lr 0.0001 | ms/batch 42.68 | loss 38.87 | ppl 76235265731687024.00 | bpc   56.081\n",
      "| epoch  89 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.12 | ppl 35777259149325400.00 | bpc   54.990\n",
      "| epoch  89 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.12 | ppl 35798146594332556.00 | bpc   54.991\n",
      "| epoch  89 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.12 | ppl 35857051973868140.00 | bpc   54.993\n",
      "| epoch  89 |   250/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.11 | ppl 35692469586303708.00 | bpc   54.986\n",
      "| epoch  89 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.11 | ppl 35508318787970464.00 | bpc   54.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  89 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.11 | ppl 35584389562360140.00 | bpc   54.982\n",
      "| epoch  89 |   400/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.12 | ppl 35762522408642844.00 | bpc   54.989\n",
      "| epoch  89 |   450/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.12 | ppl 35969664722485868.00 | bpc   54.998\n",
      "| epoch  89 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.12 | ppl 35854726724696984.00 | bpc   54.993\n",
      "| epoch  89 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.11 | ppl 35675318056858220.00 | bpc   54.986\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 32.29s | valid loss  2.19 | valid ppl     8.90 | bpc    3.153\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 13 out of 25\n",
      "| epoch  90 |    50/  559 batches | lr 0.0001 | ms/batch 42.56 | loss 38.96 | ppl 83318638406528560.00 | bpc   56.209\n",
      "| epoch  90 |   100/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.20 | ppl 38977585812838296.00 | bpc   55.113\n",
      "| epoch  90 |   150/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 38.21 | ppl 39123870947824176.00 | bpc   55.119\n",
      "| epoch  90 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.21 | ppl 39149250949380928.00 | bpc   55.120\n",
      "| epoch  90 |   250/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 38.20 | ppl 39042914394813344.00 | bpc   55.116\n",
      "| epoch  90 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.20 | ppl 38739818920852728.00 | bpc   55.105\n",
      "| epoch  90 |   350/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.20 | ppl 38911327483540912.00 | bpc   55.111\n",
      "| epoch  90 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.20 | ppl 39068987053821088.00 | bpc   55.117\n",
      "| epoch  90 |   450/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.21 | ppl 39329022834210736.00 | bpc   55.126\n",
      "| epoch  90 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.21 | ppl 39191836718626440.00 | bpc   55.121\n",
      "| epoch  90 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.20 | ppl 39043956967024608.00 | bpc   55.116\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 32.27s | valid loss  2.19 | valid ppl     8.92 | bpc    3.157\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 14 out of 25\n",
      "| epoch  91 |    50/  559 batches | lr 0.0001 | ms/batch 42.88 | loss 39.05 | ppl 91010153037181088.00 | bpc   56.337\n",
      "| epoch  91 |   100/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.29 | ppl 42437304745051232.00 | bpc   55.236\n",
      "| epoch  91 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.29 | ppl 42577404541978360.00 | bpc   55.241\n",
      "| epoch  91 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.29 | ppl 42602099526902144.00 | bpc   55.242\n",
      "| epoch  91 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.29 | ppl 42577729383034896.00 | bpc   55.241\n",
      "| epoch  91 |   300/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.28 | ppl 42153340632529600.00 | bpc   55.226\n",
      "| epoch  91 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.28 | ppl 42332693994199168.00 | bpc   55.233\n",
      "| epoch  91 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.29 | ppl 42577404541978360.00 | bpc   55.241\n",
      "| epoch  91 |   450/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.29 | ppl 42679200901317384.00 | bpc   55.244\n",
      "| epoch  91 |   500/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.29 | ppl 42577891804492544.00 | bpc   55.241\n",
      "| epoch  91 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.29 | ppl 42384239515849136.00 | bpc   55.234\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 32.31s | valid loss  2.19 | valid ppl     8.91 | bpc    3.156\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 15 out of 25\n",
      "| epoch  92 |    50/  559 batches | lr 0.0001 | ms/batch 40.39 | loss 39.14 | ppl 99129205529049088.00 | bpc   56.460\n",
      "| epoch  92 |   100/  559 batches | lr 0.0001 | ms/batch 42.20 | loss 38.37 | ppl 46178212223298264.00 | bpc   55.358\n",
      "| epoch  92 |   150/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.37 | ppl 46310518323368568.00 | bpc   55.362\n",
      "| epoch  92 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.37 | ppl 46320235676142776.00 | bpc   55.362\n",
      "| epoch  92 |   250/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.37 | ppl 46205700721974848.00 | bpc   55.359\n",
      "| epoch  92 |   300/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.37 | ppl 45908603043710464.00 | bpc   55.350\n",
      "| epoch  92 |   350/  559 batches | lr 0.0001 | ms/batch 42.22 | loss 38.37 | ppl 45992741213797664.00 | bpc   55.352\n",
      "| epoch  92 |   400/  559 batches | lr 0.0001 | ms/batch 42.21 | loss 38.37 | ppl 46223506488677112.00 | bpc   55.359\n",
      "| epoch  92 |   450/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.38 | ppl 46517673176738304.00 | bpc   55.369\n",
      "| epoch  92 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.38 | ppl 46382475035555056.00 | bpc   55.364\n",
      "| epoch  92 |   550/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.37 | ppl 46162889202839400.00 | bpc   55.358\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 32.16s | valid loss  2.19 | valid ppl     8.91 | bpc    3.156\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 16 out of 25\n",
      "| epoch  93 |    50/  559 batches | lr 0.0001 | ms/batch 41.72 | loss 39.22 | ppl 107881162732629968.00 | bpc   56.582\n",
      "| epoch  93 |   100/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.45 | ppl 50197349275802448.00 | bpc   55.478\n",
      "| epoch  93 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.46 | ppl 50365565206251640.00 | bpc   55.483\n",
      "| epoch  93 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.46 | ppl 50419197839910240.00 | bpc   55.485\n",
      "| epoch  93 |   250/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.45 | ppl 50201370678386352.00 | bpc   55.479\n",
      "| epoch  93 |   300/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.45 | ppl 49787144503909136.00 | bpc   55.467\n",
      "| epoch  93 |   350/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 38.45 | ppl 50005081815996504.00 | bpc   55.473\n",
      "| epoch  93 |   400/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.46 | ppl 50224739485642808.00 | bpc   55.479\n",
      "| epoch  93 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.46 | ppl 50430546821595712.00 | bpc   55.485\n",
      "| epoch  93 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.46 | ppl 50274578162947304.00 | bpc   55.481\n",
      "| epoch  93 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.45 | ppl 50056611995861104.00 | bpc   55.474\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 32.26s | valid loss  2.19 | valid ppl     8.90 | bpc    3.154\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 17 out of 25\n",
      "| epoch  94 |    50/  559 batches | lr 0.0001 | ms/batch 42.60 | loss 39.31 | ppl 117480185654009696.00 | bpc   56.705\n",
      "| epoch  94 |   100/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.54 | ppl 54596692277278632.00 | bpc   55.600\n",
      "| epoch  94 |   150/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.54 | ppl 54773382135594256.00 | bpc   55.604\n",
      "| epoch  94 |   200/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.54 | ppl 54779232876441696.00 | bpc   55.604\n",
      "| epoch  94 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.54 | ppl 54608148320924240.00 | bpc   55.600\n",
      "| epoch  94 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.53 | ppl 54161899199234088.00 | bpc   55.588\n",
      "| epoch  94 |   350/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.54 | ppl 54396911363361944.00 | bpc   55.594\n",
      "| epoch  94 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.54 | ppl 54571913789312408.00 | bpc   55.599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  94 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.54 | ppl 54851792157088848.00 | bpc   55.606\n",
      "| epoch  94 |   500/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.54 | ppl 54719918614086480.00 | bpc   55.603\n",
      "| epoch  94 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.54 | ppl 54402929420955344.00 | bpc   55.595\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 32.28s | valid loss  2.19 | valid ppl     8.93 | bpc    3.158\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 18 out of 25\n",
      "| epoch  95 |    50/  559 batches | lr 0.0001 | ms/batch 43.02 | loss 39.39 | ppl 127810384348012608.00 | bpc   56.827\n",
      "| epoch  95 |   100/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.62 | ppl 59219176994834912.00 | bpc   55.717\n",
      "| epoch  95 |   150/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.62 | ppl 59390659449865168.00 | bpc   55.721\n",
      "| epoch  95 |   200/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 38.62 | ppl 59427146392422120.00 | bpc   55.722\n",
      "| epoch  95 |   250/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.62 | ppl 59329294122882832.00 | bpc   55.720\n",
      "| epoch  95 |   300/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.61 | ppl 58868488148032312.00 | bpc   55.708\n",
      "| epoch  95 |   350/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.62 | ppl 59063734034508704.00 | bpc   55.713\n",
      "| epoch  95 |   400/  559 batches | lr 0.0001 | ms/batch 42.34 | loss 38.62 | ppl 59287212920596136.00 | bpc   55.719\n",
      "| epoch  95 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.63 | ppl 59598321664492336.00 | bpc   55.726\n",
      "| epoch  95 |   500/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.62 | ppl 59358949883917472.00 | bpc   55.720\n",
      "| epoch  95 |   550/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.62 | ppl 59104980208039632.00 | bpc   55.714\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 32.33s | valid loss  2.19 | valid ppl     8.91 | bpc    3.155\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 19 out of 25\n",
      "| epoch  96 |    50/  559 batches | lr 0.0001 | ms/batch 40.30 | loss 39.47 | ppl 138876119440168368.00 | bpc   56.947\n",
      "| epoch  96 |   100/  559 batches | lr 0.0001 | ms/batch 42.07 | loss 38.70 | ppl 64375549155162288.00 | bpc   55.837\n",
      "| epoch  96 |   150/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.71 | ppl 64576741798154184.00 | bpc   55.842\n",
      "| epoch  96 |   200/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.71 | ppl 64563933351106496.00 | bpc   55.842\n",
      "| epoch  96 |   250/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 38.70 | ppl 64374812439683808.00 | bpc   55.837\n",
      "| epoch  96 |   300/  559 batches | lr 0.0001 | ms/batch 42.23 | loss 38.70 | ppl 63946007584615240.00 | bpc   55.828\n",
      "| epoch  96 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.70 | ppl 64133134799540192.00 | bpc   55.832\n",
      "| epoch  96 |   400/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.70 | ppl 64318846725343728.00 | bpc   55.836\n",
      "| epoch  96 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.71 | ppl 64806739963253776.00 | bpc   55.847\n",
      "| epoch  96 |   500/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.71 | ppl 64623316982121232.00 | bpc   55.843\n",
      "| epoch  96 |   550/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.70 | ppl 64357379300726408.00 | bpc   55.837\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 32.16s | valid loss  2.19 | valid ppl     8.90 | bpc    3.154\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 20 out of 25\n",
      "| epoch  97 |    50/  559 batches | lr 0.0001 | ms/batch 41.49 | loss 39.56 | ppl 151706230417972576.00 | bpc   57.074\n",
      "| epoch  97 |   100/  559 batches | lr 0.0001 | ms/batch 42.15 | loss 38.79 | ppl 70019619753613920.00 | bpc   55.959\n",
      "| epoch  97 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.79 | ppl 70263910551232456.00 | bpc   55.964\n",
      "| epoch  97 |   200/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.79 | ppl 70225859810220800.00 | bpc   55.963\n",
      "| epoch  97 |   250/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.79 | ppl 70086427517978536.00 | bpc   55.960\n",
      "| epoch  97 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.78 | ppl 69452994095429888.00 | bpc   55.947\n",
      "| epoch  97 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.78 | ppl 69825171688312312.00 | bpc   55.955\n",
      "| epoch  97 |   400/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.79 | ppl 70125740239460320.00 | bpc   55.961\n",
      "| epoch  97 |   450/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 38.79 | ppl 70484850445252256.00 | bpc   55.968\n",
      "| epoch  97 |   500/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.79 | ppl 70328805103028504.00 | bpc   55.965\n",
      "| epoch  97 |   550/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.79 | ppl 69983570043902936.00 | bpc   55.958\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 32.23s | valid loss  2.19 | valid ppl     8.91 | bpc    3.156\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 21 out of 25\n",
      "| epoch  98 |    50/  559 batches | lr 0.0001 | ms/batch 40.55 | loss 39.65 | ppl 165094459934013408.00 | bpc   57.196\n",
      "| epoch  98 |   100/  559 batches | lr 0.0001 | ms/batch 42.20 | loss 38.87 | ppl 76172766256130496.00 | bpc   56.080\n",
      "| epoch  98 |   150/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.87 | ppl 76385765165964656.00 | bpc   56.084\n",
      "| epoch  98 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.88 | ppl 76479941681667856.00 | bpc   56.086\n",
      "| epoch  98 |   250/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.87 | ppl 76248062641844576.00 | bpc   56.082\n",
      "| epoch  98 |   300/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 38.86 | ppl 75602476983733392.00 | bpc   56.069\n",
      "| epoch  98 |   350/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.87 | ppl 75866824575546128.00 | bpc   56.074\n",
      "| epoch  98 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.87 | ppl 76308295117917616.00 | bpc   56.083\n",
      "| epoch  98 |   450/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.88 | ppl 76524884046330912.00 | bpc   56.087\n",
      "| epoch  98 |   500/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 38.87 | ppl 76411120178673264.00 | bpc   56.085\n",
      "| epoch  98 |   550/  559 batches | lr 0.0001 | ms/batch 42.35 | loss 38.87 | ppl 76017756583786896.00 | bpc   56.077\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 32.19s | valid loss  2.19 | valid ppl     8.91 | bpc    3.155\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 22 out of 25\n",
      "| epoch  99 |    50/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 39.73 | ppl 179727964569833856.00 | bpc   57.319\n",
      "| epoch  99 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 38.96 | ppl 82803121675191536.00 | bpc   56.201\n",
      "| epoch  99 |   150/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.96 | ppl 83063173369702480.00 | bpc   56.205\n",
      "| epoch  99 |   200/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.96 | ppl 83203344007348560.00 | bpc   56.207\n",
      "| epoch  99 |   250/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.96 | ppl 83008691177324752.00 | bpc   56.204\n",
      "| epoch  99 |   300/  559 batches | lr 0.0001 | ms/batch 42.25 | loss 38.95 | ppl 82202318313498352.00 | bpc   56.190\n",
      "| epoch  99 |   350/  559 batches | lr 0.0001 | ms/batch 42.24 | loss 38.95 | ppl 82378109108456208.00 | bpc   56.193\n",
      "| epoch  99 |   400/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.96 | ppl 82933678323906432.00 | bpc   56.203\n",
      "| epoch  99 |   450/  559 batches | lr 0.0001 | ms/batch 42.26 | loss 38.96 | ppl 83332942226394864.00 | bpc   56.210\n",
      "| epoch  99 |   500/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 38.96 | ppl 83088209149883808.00 | bpc   56.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  99 |   550/  559 batches | lr 0.0001 | ms/batch 42.32 | loss 38.95 | ppl 82739656372233344.00 | bpc   56.199\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time: 32.27s | valid loss  2.19 | valid ppl     8.90 | bpc    3.153\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 23 out of 25\n",
      "| epoch 100 |    50/  559 batches | lr 0.0001 | ms/batch 43.13 | loss 39.82 | ppl 195934148998829568.00 | bpc   57.443\n",
      "| epoch 100 |   100/  559 batches | lr 0.0001 | ms/batch 42.27 | loss 39.04 | ppl 90258857367376096.00 | bpc   56.325\n",
      "| epoch 100 |   150/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 39.04 | ppl 90301561933522640.00 | bpc   56.326\n",
      "| epoch 100 |   200/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 39.04 | ppl 90448426783086448.00 | bpc   56.328\n",
      "| epoch 100 |   250/  559 batches | lr 0.0001 | ms/batch 42.31 | loss 39.04 | ppl 90308107160022720.00 | bpc   56.326\n",
      "| epoch 100 |   300/  559 batches | lr 0.0001 | ms/batch 42.30 | loss 39.03 | ppl 89428437415730496.00 | bpc   56.312\n",
      "| epoch 100 |   350/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 39.04 | ppl 89855198193484848.00 | bpc   56.318\n",
      "| epoch 100 |   400/  559 batches | lr 0.0001 | ms/batch 42.29 | loss 39.04 | ppl 90188301364463840.00 | bpc   56.324\n",
      "| epoch 100 |   450/  559 batches | lr 0.0001 | ms/batch 42.34 | loss 39.05 | ppl 90707226320492048.00 | bpc   56.332\n",
      "| epoch 100 |   500/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 39.04 | ppl 90363243678952832.00 | bpc   56.327\n",
      "| epoch 100 |   550/  559 batches | lr 0.0001 | ms/batch 42.28 | loss 39.04 | ppl 89944019592445760.00 | bpc   56.320\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time: 32.33s | valid loss  2.18 | valid ppl     8.86 | bpc    3.147\n",
      "-----------------------------------------------------------------------------------------\n",
      "EarlyStopping counter: 24 out of 25\n",
      "=========================================================================================\n",
      "| End of training | test loss  2.16 | test ppl     8.65 | bpc    3.113\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = lr\n",
    "best_val_loss = None\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.99)\n",
    "opts = 'SGD'\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "epochs = 100\n",
    "early_stopping = EarlyStopping(patience=25, verbose=True)\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.to(device)\n",
    "\n",
    "        param_vector = parameters_to_vector(model.rnn.parameters())\n",
    "        param_vector.to(device)\n",
    "        n_params = len(param_vector)\n",
    "        noise = torch.distributions.Normal(loc=torch.tensor(0.), scale=torch.tensor(0.075)).sample_n(n_params)\n",
    "        param_vector.add_(noise.to(device))\n",
    "        \n",
    "        vector_to_parameters(param_vector, model.rnn.parameters())\n",
    "        model.to(device)\n",
    "        \n",
    "        train()\n",
    "        train_loss = evaluate(train_data)\n",
    "        val_loss = evaluate(val_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f} | bpc {:8.3f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                           val_loss, math.exp(val_loss), val_loss / math.log(2)))\n",
    "        val_losses.append(val_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        print('-' * 89)\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "    test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "0rhqYahOFUZ5"
   },
   "outputs": [],
   "source": [
    "validation_losses = [i.item() for i in val_losses]\n",
    "training_losses = [i.item() for i in train_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "mWYUPwb_FUdb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(range(100), training_losses, c='#00ff00')\n",
    "plt.plot(range(100), validation_losses)\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 3.0)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Loss')\n",
    "plt.savefig('Char_Noise_Adaptive'+'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "cIVqLt5OFlnN"
   },
   "outputs": [],
   "source": [
    "data = 'data/penn'\n",
    "batch_size = 64\n",
    "emsize = 256\n",
    "nlayers = 1\n",
    "nhid = 1000\n",
    "lr = 0.0001\n",
    "dropout = 0.5\n",
    "checkpoint = ''\n",
    "clip = 1\n",
    "bptt = 35\n",
    "epochs = 10\n",
    "save = 'output/model_test_word_none.pt'\n",
    "\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "# Load data\n",
    "corpus = Corpus(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "z5VSLOTdFlnN"
   },
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "nIhXbQwwFlnN"
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 64\n",
    "train_data = batchify(corpus.train, batch_size) # size(total_len//bsz, bsz)\n",
    "val_data = batchify(corpus.valid, eval_batch_size)\n",
    "test_data = batchify(corpus.test, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i2Jjp0zFlnN",
    "outputId": "8d488e02-a5cd-453c-e493-32719c90ce04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFfBvbfdFlnO",
    "outputId": "2aaa7218-7307-419d-8893-e6af2ce293d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  988,   48,  ...,   32, 3490,  556],\n",
       "        [   1,   40,   32,  ..., 6789,  119,   27],\n",
       "        [   2, 2756,  189,  ..., 1168,  129, 1880],\n",
       "        ...,\n",
       "        [1825,   54,   32,  ...,  416,   26,   35],\n",
       "        [  35, 3940, 2361,  ...,   27,  373,  198],\n",
       "        [ 101, 1305, 4923,  ...,   24,   42,   42]], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zP8AXSokFlnO",
    "outputId": "f5a7cf7c-f87f-49b0-acc8-f704e8abf216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 142,  712,  439,  ..., 1940,   64, 3981],\n",
       "        [  78, 4480,   48,  ...,   64, 4500,  500],\n",
       "        [  54,  556,   40,  ...,  872,  398,   32],\n",
       "        ...,\n",
       "        [ 555,   64, 2380,  ...,  801,   32,   26],\n",
       "        [1319,   26,  301,  ..., 2030, 6851,   64],\n",
       "        [ 410,  119,   32,  ...,  159,  548,  220]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.to(device)\n",
    "test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOWwV7sdFlnO",
    "outputId": "ca558a66-1b81-45df-ea71-4171cd4c0696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (encoder): Embedding(10000, 256)\n",
      "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
      "  (decoder): Linear(in_features=1000, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "interval = 50 # interval to report\n",
    "ntokens = len(corpus.dictionary) # 10000\n",
    "model = RNNModel(ntokens, emsize, nhid, nlayers, dropout)\n",
    "\n",
    "# Load checkpoint\n",
    "if checkpoint != '':\n",
    "    model = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfrpT7ooFlnO",
    "outputId": "0f364522-52db-46f8-dbaa-9b74156395e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (encoder): Embedding(10000, 256)\n",
       "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
       "  (decoder): Linear(in_features=1000, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "mzQDckWKFlnO"
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    # detach\n",
    "    return tuple(v.clone().detach() for v in h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "89PfPgfPFlnP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(source, i):\n",
    "    # source: size(total_len//bsz, bsz)\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    #data = torch.tensor(source[i:i+seq_len]) # size(bptt, bsz)\n",
    "    data = source[i:i+seq_len].clone().detach()\n",
    "    target = source[i+1:i+1+seq_len].clone().detach().view(-1)\n",
    "    #target = torch.tensor(source[i+1:i+1+seq_len].view(-1)) # size(bptt * bsz)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "PEdnvP0WFlnP"
   },
   "outputs": [],
   "source": [
    "def evaluate(data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        ntokens = len(corpus.dictionary)\n",
    "        hidden = model.init_hidden(eval_batch_size) #hidden size(nlayers, bsz, hdsize)\n",
    "        for i in range(0, data_source.size(0) - 1, bptt):# iterate over every timestep\n",
    "            data, targets = get_batch(data_source, i)\n",
    "            output, hidden = model(data.to(device), hidden)\n",
    "            # model input and output\n",
    "            # inputdata size(bptt, bsz), and size(bptt, bsz, embsize) after embedding\n",
    "            # output size(bptt*bsz, ntoken)\n",
    "            total_loss += len(data) * criterion(output.to(device), targets.to(device)).data\n",
    "            hidden = repackage_hidden(hidden)\n",
    "        return total_loss / len(data_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "DWo320JXFlnP"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # choose a optimizer\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    # train_data size(batchcnt, bsz)\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        # print(hidden.to(device))\n",
    "        output, hidden = model(data.to(device), hidden)\n",
    "        loss = criterion(output.to(device), targets.to(device))\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), clip)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "\n",
    "        if batch % interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.4f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "                epoch, batch, len(train_data) // bptt, lr,\n",
    "                elapsed * 1000 / interval, cur_loss, math.exp(cur_loss), cur_loss / math.log(2)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqWZrhvQFlnP",
    "outputId": "78778ff9-f9f0-43ec-f33c-124033326c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:\n",
      "Train:  929589\n",
      "Valid:  73760\n",
      "Test:   82430\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\")\n",
    "print(\"Train: \", len(corpus.train))\n",
    "print(\"Valid: \", len(corpus.valid))\n",
    "print(\"Test:  \", len(corpus.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hb7POEtPFlnP",
    "outputId": "52b6d63e-28e0-4eca-ed5d-0adfce46e368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  414 batches | lr 0.0001 | ms/batch 31.79 | loss  9.39 | ppl 12016.95 | bpc   13.553\n",
      "| epoch   1 |   100/  414 batches | lr 0.0001 | ms/batch 30.27 | loss  9.21 | ppl  9955.06 | bpc   13.281\n",
      "| epoch   1 |   150/  414 batches | lr 0.0001 | ms/batch 30.40 | loss  9.20 | ppl  9892.48 | bpc   13.272\n",
      "| epoch   1 |   200/  414 batches | lr 0.0001 | ms/batch 30.41 | loss  9.19 | ppl  9820.05 | bpc   13.262\n",
      "| epoch   1 |   250/  414 batches | lr 0.0001 | ms/batch 30.48 | loss  9.18 | ppl  9731.62 | bpc   13.248\n",
      "| epoch   1 |   300/  414 batches | lr 0.0001 | ms/batch 30.47 | loss  9.17 | ppl  9641.81 | bpc   13.235\n",
      "| epoch   1 |   350/  414 batches | lr 0.0001 | ms/batch 30.47 | loss  9.16 | ppl  9546.74 | bpc   13.221\n",
      "| epoch   1 |   400/  414 batches | lr 0.0001 | ms/batch 30.50 | loss  9.15 | ppl  9450.07 | bpc   13.206\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 17.41s | valid loss  9.14 | valid ppl  9301.65 | bpc   13.183\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (inf --> 9.137947).  Saving model ...\n",
      "| epoch   2 |    50/  414 batches | lr 0.0001 | ms/batch 31.19 | loss  9.32 | ppl 11195.63 | bpc   13.451\n",
      "| epoch   2 |   100/  414 batches | lr 0.0001 | ms/batch 30.65 | loss  9.13 | ppl  9225.36 | bpc   13.171\n",
      "| epoch   2 |   150/  414 batches | lr 0.0001 | ms/batch 30.65 | loss  9.12 | ppl  9115.88 | bpc   13.154\n",
      "| epoch   2 |   200/  414 batches | lr 0.0001 | ms/batch 30.72 | loss  9.11 | ppl  9033.02 | bpc   13.141\n",
      "| epoch   2 |   250/  414 batches | lr 0.0001 | ms/batch 30.75 | loss  9.10 | ppl  8921.81 | bpc   13.123\n",
      "| epoch   2 |   300/  414 batches | lr 0.0001 | ms/batch 30.83 | loss  9.08 | ppl  8815.12 | bpc   13.106\n",
      "| epoch   2 |   350/  414 batches | lr 0.0001 | ms/batch 30.88 | loss  9.07 | ppl  8701.40 | bpc   13.087\n",
      "| epoch   2 |   400/  414 batches | lr 0.0001 | ms/batch 30.85 | loss  9.06 | ppl  8579.87 | bpc   13.067\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 17.55s | valid loss  9.04 | valid ppl  8425.50 | bpc   13.041\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (9.137947 --> 9.039018).  Saving model ...\n",
      "| epoch   3 |    50/  414 batches | lr 0.0001 | ms/batch 31.53 | loss  9.22 | ppl 10096.52 | bpc   13.302\n",
      "| epoch   3 |   100/  414 batches | lr 0.0001 | ms/batch 30.94 | loss  9.02 | ppl  8299.13 | bpc   13.019\n",
      "| epoch   3 |   150/  414 batches | lr 0.0001 | ms/batch 30.98 | loss  9.01 | ppl  8145.22 | bpc   12.992\n",
      "| epoch   3 |   200/  414 batches | lr 0.0001 | ms/batch 30.97 | loss  8.99 | ppl  8035.59 | bpc   12.972\n",
      "| epoch   3 |   250/  414 batches | lr 0.0001 | ms/batch 31.00 | loss  8.97 | ppl  7872.18 | bpc   12.943\n",
      "| epoch   3 |   300/  414 batches | lr 0.0001 | ms/batch 31.00 | loss  8.95 | ppl  7709.63 | bpc   12.912\n",
      "| epoch   3 |   350/  414 batches | lr 0.0001 | ms/batch 31.08 | loss  8.93 | ppl  7521.21 | bpc   12.877\n",
      "| epoch   3 |   400/  414 batches | lr 0.0001 | ms/batch 31.08 | loss  8.90 | ppl  7308.24 | bpc   12.835\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 17.70s | valid loss  8.87 | valid ppl  7084.18 | bpc   12.790\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (9.039018 --> 8.865620).  Saving model ...\n",
      "| epoch   4 |    50/  414 batches | lr 0.0001 | ms/batch 31.82 | loss  9.03 | ppl  8368.58 | bpc   13.031\n",
      "| epoch   4 |   100/  414 batches | lr 0.0001 | ms/batch 31.16 | loss  8.82 | ppl  6736.56 | bpc   12.718\n",
      "| epoch   4 |   150/  414 batches | lr 0.0001 | ms/batch 31.20 | loss  8.76 | ppl  6377.33 | bpc   12.639\n",
      "| epoch   4 |   200/  414 batches | lr 0.0001 | ms/batch 31.23 | loss  8.71 | ppl  6046.16 | bpc   12.562\n",
      "| epoch   4 |   250/  414 batches | lr 0.0001 | ms/batch 31.33 | loss  8.62 | ppl  5534.79 | bpc   12.434\n",
      "| epoch   4 |   300/  414 batches | lr 0.0001 | ms/batch 31.30 | loss  8.50 | ppl  4896.94 | bpc   12.258\n",
      "| epoch   4 |   350/  414 batches | lr 0.0001 | ms/batch 31.32 | loss  8.31 | ppl  4052.35 | bpc   11.985\n",
      "| epoch   4 |   400/  414 batches | lr 0.0001 | ms/batch 31.36 | loss  8.03 | ppl  3083.81 | bpc   11.590\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 17.90s | valid loss  7.83 | valid ppl  2521.16 | bpc   11.300\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (8.865620 --> 7.832474).  Saving model ...\n",
      "| epoch   5 |    50/  414 batches | lr 0.0001 | ms/batch 32.21 | loss  7.98 | ppl  2925.17 | bpc   11.514\n",
      "| epoch   5 |   100/  414 batches | lr 0.0001 | ms/batch 33.25 | loss  7.74 | ppl  2299.95 | bpc   11.167\n",
      "| epoch   5 |   150/  414 batches | lr 0.0001 | ms/batch 33.26 | loss  7.59 | ppl  1979.10 | bpc   10.951\n",
      "| epoch   5 |   200/  414 batches | lr 0.0001 | ms/batch 33.04 | loss  7.56 | ppl  1915.12 | bpc   10.903\n",
      "| epoch   5 |   250/  414 batches | lr 0.0001 | ms/batch 33.24 | loss  7.53 | ppl  1861.32 | bpc   10.862\n",
      "| epoch   5 |   300/  414 batches | lr 0.0001 | ms/batch 33.32 | loss  7.47 | ppl  1752.54 | bpc   10.775\n",
      "| epoch   5 |   350/  414 batches | lr 0.0001 | ms/batch 33.50 | loss  7.43 | ppl  1683.94 | bpc   10.718\n",
      "| epoch   5 |   400/  414 batches | lr 0.0001 | ms/batch 33.73 | loss  7.38 | ppl  1597.67 | bpc   10.642\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 18.96s | valid loss  7.32 | valid ppl  1513.91 | bpc   10.564\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (7.832474 --> 7.322452).  Saving model ...\n",
      "| epoch   6 |    50/  414 batches | lr 0.0001 | ms/batch 32.45 | loss  7.48 | ppl  1778.55 | bpc   10.796\n",
      "| epoch   6 |   100/  414 batches | lr 0.0001 | ms/batch 33.08 | loss  7.31 | ppl  1491.42 | bpc   10.542\n",
      "| epoch   6 |   150/  414 batches | lr 0.0001 | ms/batch 34.19 | loss  7.24 | ppl  1391.62 | bpc   10.443\n",
      "| epoch   6 |   200/  414 batches | lr 0.0001 | ms/batch 34.43 | loss  7.23 | ppl  1386.61 | bpc   10.437\n",
      "| epoch   6 |   250/  414 batches | lr 0.0001 | ms/batch 34.27 | loss  7.22 | ppl  1368.44 | bpc   10.418\n",
      "| epoch   6 |   300/  414 batches | lr 0.0001 | ms/batch 34.22 | loss  7.18 | ppl  1316.80 | bpc   10.363\n",
      "| epoch   6 |   350/  414 batches | lr 0.0001 | ms/batch 34.00 | loss  7.16 | ppl  1283.43 | bpc   10.326\n",
      "| epoch   6 |   400/  414 batches | lr 0.0001 | ms/batch 33.76 | loss  7.12 | ppl  1237.72 | bpc   10.273\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 19.28s | valid loss  7.07 | valid ppl  1171.02 | bpc   10.194\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (7.322452 --> 7.065630).  Saving model ...\n",
      "| epoch   7 |    50/  414 batches | lr 0.0001 | ms/batch 33.40 | loss  7.25 | ppl  1410.59 | bpc   10.462\n",
      "| epoch   7 |   100/  414 batches | lr 0.0001 | ms/batch 33.55 | loss  7.09 | ppl  1199.59 | bpc   10.228\n",
      "| epoch   7 |   150/  414 batches | lr 0.0001 | ms/batch 34.77 | loss  7.04 | ppl  1138.13 | bpc   10.152\n",
      "| epoch   7 |   200/  414 batches | lr 0.0001 | ms/batch 34.12 | loss  7.05 | ppl  1148.60 | bpc   10.166\n",
      "| epoch   7 |   250/  414 batches | lr 0.0001 | ms/batch 34.49 | loss  7.05 | ppl  1156.00 | bpc   10.175\n",
      "| epoch   7 |   300/  414 batches | lr 0.0001 | ms/batch 34.36 | loss  7.03 | ppl  1124.52 | bpc   10.135\n",
      "| epoch   7 |   350/  414 batches | lr 0.0001 | ms/batch 34.21 | loss  7.01 | ppl  1106.92 | bpc   10.112\n",
      "| epoch   7 |   400/  414 batches | lr 0.0001 | ms/batch 34.35 | loss  6.98 | ppl  1079.26 | bpc   10.076\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 19.43s | valid loss  6.93 | valid ppl  1019.76 | bpc    9.994\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (7.065630 --> 6.927325).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   8 |    50/  414 batches | lr 0.0001 | ms/batch 32.90 | loss  7.13 | ppl  1247.38 | bpc   10.285\n",
      "| epoch   8 |   100/  414 batches | lr 0.0001 | ms/batch 32.45 | loss  6.98 | ppl  1070.85 | bpc   10.065\n",
      "| epoch   8 |   150/  414 batches | lr 0.0001 | ms/batch 34.57 | loss  6.93 | ppl  1024.39 | bpc   10.001\n",
      "| epoch   8 |   200/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.95 | ppl  1040.86 | bpc   10.024\n",
      "| epoch   8 |   250/  414 batches | lr 0.0001 | ms/batch 34.78 | loss  6.96 | ppl  1053.25 | bpc   10.041\n",
      "| epoch   8 |   300/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.94 | ppl  1031.45 | bpc   10.010\n",
      "| epoch   8 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.92 | ppl  1017.29 | bpc    9.991\n",
      "| epoch   8 |   400/  414 batches | lr 0.0001 | ms/batch 34.50 | loss  6.90 | ppl   994.64 | bpc    9.958\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 19.50s | valid loss  6.84 | valid ppl   936.48 | bpc    9.871\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.927325 --> 6.842125).  Saving model ...\n",
      "| epoch   9 |    50/  414 batches | lr 0.0001 | ms/batch 32.87 | loss  7.06 | ppl  1160.31 | bpc   10.180\n",
      "| epoch   9 |   100/  414 batches | lr 0.0001 | ms/batch 34.30 | loss  6.90 | ppl   996.19 | bpc    9.960\n",
      "| epoch   9 |   150/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.87 | ppl   958.18 | bpc    9.904\n",
      "| epoch   9 |   200/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.88 | ppl   973.40 | bpc    9.927\n",
      "| epoch   9 |   250/  414 batches | lr 0.0001 | ms/batch 34.79 | loss  6.90 | ppl   988.75 | bpc    9.949\n",
      "| epoch   9 |   300/  414 batches | lr 0.0001 | ms/batch 34.54 | loss  6.88 | ppl   972.82 | bpc    9.926\n",
      "| epoch   9 |   350/  414 batches | lr 0.0001 | ms/batch 34.77 | loss  6.87 | ppl   959.71 | bpc    9.906\n",
      "| epoch   9 |   400/  414 batches | lr 0.0001 | ms/batch 34.37 | loss  6.84 | ppl   938.23 | bpc    9.874\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 19.58s | valid loss  6.78 | valid ppl   880.17 | bpc    9.782\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.842125 --> 6.780111).  Saving model ...\n",
      "| epoch  10 |    50/  414 batches | lr 0.0001 | ms/batch 33.70 | loss  7.00 | ppl  1097.97 | bpc   10.101\n",
      "| epoch  10 |   100/  414 batches | lr 0.0001 | ms/batch 34.21 | loss  6.85 | ppl   948.01 | bpc    9.889\n",
      "| epoch  10 |   150/  414 batches | lr 0.0001 | ms/batch 34.79 | loss  6.81 | ppl   911.05 | bpc    9.831\n",
      "| epoch  10 |   200/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.83 | ppl   926.67 | bpc    9.856\n",
      "| epoch  10 |   250/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.85 | ppl   941.59 | bpc    9.879\n",
      "| epoch  10 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.84 | ppl   930.27 | bpc    9.862\n",
      "| epoch  10 |   350/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.82 | ppl   918.72 | bpc    9.843\n",
      "| epoch  10 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.80 | ppl   898.23 | bpc    9.811\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 19.66s | valid loss  6.73 | valid ppl   840.85 | bpc    9.716\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.780111 --> 6.734410).  Saving model ...\n",
      "| epoch  11 |    50/  414 batches | lr 0.0001 | ms/batch 32.59 | loss  6.96 | ppl  1053.18 | bpc   10.041\n",
      "| epoch  11 |   100/  414 batches | lr 0.0001 | ms/batch 33.79 | loss  6.81 | ppl   910.96 | bpc    9.831\n",
      "| epoch  11 |   150/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.78 | ppl   876.89 | bpc    9.776\n",
      "| epoch  11 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.80 | ppl   893.83 | bpc    9.804\n",
      "| epoch  11 |   250/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.81 | ppl   909.39 | bpc    9.829\n",
      "| epoch  11 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.80 | ppl   900.08 | bpc    9.814\n",
      "| epoch  11 |   350/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.79 | ppl   885.06 | bpc    9.790\n",
      "| epoch  11 |   400/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.77 | ppl   868.78 | bpc    9.763\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 19.59s | valid loss  6.70 | valid ppl   812.35 | bpc    9.666\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.734410 --> 6.699927).  Saving model ...\n",
      "| epoch  12 |    50/  414 batches | lr 0.0001 | ms/batch 33.89 | loss  6.93 | ppl  1017.56 | bpc    9.991\n",
      "| epoch  12 |   100/  414 batches | lr 0.0001 | ms/batch 34.50 | loss  6.78 | ppl   882.41 | bpc    9.785\n",
      "| epoch  12 |   150/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.75 | ppl   851.24 | bpc    9.733\n",
      "| epoch  12 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.77 | ppl   867.71 | bpc    9.761\n",
      "| epoch  12 |   250/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.78 | ppl   884.40 | bpc    9.789\n",
      "| epoch  12 |   300/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.77 | ppl   875.23 | bpc    9.774\n",
      "| epoch  12 |   350/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.76 | ppl   864.15 | bpc    9.755\n",
      "| epoch  12 |   400/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.74 | ppl   846.85 | bpc    9.726\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 19.68s | valid loss  6.67 | valid ppl   790.90 | bpc    9.627\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.699927 --> 6.673178).  Saving model ...\n",
      "| epoch  13 |    50/  414 batches | lr 0.0001 | ms/batch 33.33 | loss  6.90 | ppl   993.81 | bpc    9.957\n",
      "| epoch  13 |   100/  414 batches | lr 0.0001 | ms/batch 32.60 | loss  6.76 | ppl   862.25 | bpc    9.752\n",
      "| epoch  13 |   150/  414 batches | lr 0.0001 | ms/batch 33.42 | loss  6.72 | ppl   830.67 | bpc    9.698\n",
      "| epoch  13 |   200/  414 batches | lr 0.0001 | ms/batch 34.57 | loss  6.74 | ppl   848.30 | bpc    9.728\n",
      "| epoch  13 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.76 | ppl   865.70 | bpc    9.758\n",
      "| epoch  13 |   300/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.75 | ppl   857.86 | bpc    9.745\n",
      "| epoch  13 |   350/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.74 | ppl   845.83 | bpc    9.724\n",
      "| epoch  13 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.72 | ppl   830.00 | bpc    9.697\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 19.48s | valid loss  6.65 | valid ppl   774.38 | bpc    9.597\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.673178 --> 6.652058).  Saving model ...\n",
      "| epoch  14 |    50/  414 batches | lr 0.0001 | ms/batch 35.52 | loss  6.88 | ppl   973.99 | bpc    9.928\n",
      "| epoch  14 |   100/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.74 | ppl   844.13 | bpc    9.721\n",
      "| epoch  14 |   150/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.71 | ppl   817.75 | bpc    9.676\n",
      "| epoch  14 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.73 | ppl   833.18 | bpc    9.702\n",
      "| epoch  14 |   250/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.75 | ppl   850.20 | bpc    9.732\n",
      "| epoch  14 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.74 | ppl   842.30 | bpc    9.718\n",
      "| epoch  14 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.72 | ppl   830.66 | bpc    9.698\n",
      "| epoch  14 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.71 | ppl   818.11 | bpc    9.676\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 19.79s | valid loss  6.64 | valid ppl   761.44 | bpc    9.573\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.652058 --> 6.635217).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  15 |    50/  414 batches | lr 0.0001 | ms/batch 34.52 | loss  6.86 | ppl   956.59 | bpc    9.902\n",
      "| epoch  15 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.72 | ppl   831.83 | bpc    9.700\n",
      "| epoch  15 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.69 | ppl   803.82 | bpc    9.651\n",
      "| epoch  15 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.71 | ppl   820.22 | bpc    9.680\n",
      "| epoch  15 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.73 | ppl   837.07 | bpc    9.709\n",
      "| epoch  15 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.72 | ppl   829.71 | bpc    9.696\n",
      "| epoch  15 |   350/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.71 | ppl   818.57 | bpc    9.677\n",
      "| epoch  15 |   400/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.69 | ppl   805.70 | bpc    9.654\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 19.74s | valid loss  6.62 | valid ppl   751.05 | bpc    9.553\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.635217 --> 6.621475).  Saving model ...\n",
      "| epoch  16 |    50/  414 batches | lr 0.0001 | ms/batch 35.54 | loss  6.85 | ppl   944.29 | bpc    9.883\n",
      "| epoch  16 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.71 | ppl   822.06 | bpc    9.683\n",
      "| epoch  16 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.68 | ppl   793.55 | bpc    9.632\n",
      "| epoch  16 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.69 | ppl   807.55 | bpc    9.657\n",
      "| epoch  16 |   250/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.72 | ppl   826.61 | bpc    9.691\n",
      "| epoch  16 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.71 | ppl   819.91 | bpc    9.679\n",
      "| epoch  16 |   350/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.70 | ppl   809.92 | bpc    9.662\n",
      "| epoch  16 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.68 | ppl   795.87 | bpc    9.636\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 19.79s | valid loss  6.61 | valid ppl   742.68 | bpc    9.537\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.621475 --> 6.610271).  Saving model ...\n",
      "| epoch  17 |    50/  414 batches | lr 0.0001 | ms/batch 32.99 | loss  6.84 | ppl   933.71 | bpc    9.867\n",
      "| epoch  17 |   100/  414 batches | lr 0.0001 | ms/batch 32.87 | loss  6.70 | ppl   812.32 | bpc    9.666\n",
      "| epoch  17 |   150/  414 batches | lr 0.0001 | ms/batch 33.88 | loss  6.67 | ppl   785.69 | bpc    9.618\n",
      "| epoch  17 |   200/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.68 | ppl   799.79 | bpc    9.643\n",
      "| epoch  17 |   250/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.71 | ppl   819.56 | bpc    9.679\n",
      "| epoch  17 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.70 | ppl   812.50 | bpc    9.666\n",
      "| epoch  17 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.68 | ppl   800.29 | bpc    9.644\n",
      "| epoch  17 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.67 | ppl   787.64 | bpc    9.621\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 19.51s | valid loss  6.60 | valid ppl   735.77 | bpc    9.523\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.610271 --> 6.600924).  Saving model ...\n",
      "| epoch  18 |    50/  414 batches | lr 0.0001 | ms/batch 35.54 | loss  6.83 | ppl   923.73 | bpc    9.851\n",
      "| epoch  18 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.69 | ppl   805.14 | bpc    9.653\n",
      "| epoch  18 |   150/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.66 | ppl   778.59 | bpc    9.605\n",
      "| epoch  18 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.67 | ppl   792.18 | bpc    9.630\n",
      "| epoch  18 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.70 | ppl   811.41 | bpc    9.664\n",
      "| epoch  18 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.69 | ppl   803.59 | bpc    9.650\n",
      "| epoch  18 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.68 | ppl   794.81 | bpc    9.634\n",
      "| epoch  18 |   400/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.66 | ppl   783.50 | bpc    9.614\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 19.79s | valid loss  6.59 | valid ppl   730.03 | bpc    9.512\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.600924 --> 6.593092).  Saving model ...\n",
      "| epoch  19 |    50/  414 batches | lr 0.0001 | ms/batch 32.18 | loss  6.82 | ppl   915.81 | bpc    9.839\n",
      "| epoch  19 |   100/  414 batches | lr 0.0001 | ms/batch 32.53 | loss  6.68 | ppl   797.96 | bpc    9.640\n",
      "| epoch  19 |   150/  414 batches | lr 0.0001 | ms/batch 33.83 | loss  6.65 | ppl   772.10 | bpc    9.593\n",
      "| epoch  19 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.66 | ppl   784.41 | bpc    9.615\n",
      "| epoch  19 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.69 | ppl   802.87 | bpc    9.649\n",
      "| epoch  19 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.68 | ppl   798.07 | bpc    9.640\n",
      "| epoch  19 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.67 | ppl   789.34 | bpc    9.625\n",
      "| epoch  19 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.66 | ppl   776.81 | bpc    9.601\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 19.46s | valid loss  6.59 | valid ppl   725.18 | bpc    9.502\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.593092 --> 6.586426).  Saving model ...\n",
      "| epoch  20 |    50/  414 batches | lr 0.0001 | ms/batch 34.53 | loss  6.81 | ppl   907.89 | bpc    9.826\n",
      "| epoch  20 |   100/  414 batches | lr 0.0001 | ms/batch 34.68 | loss  6.67 | ppl   791.96 | bpc    9.629\n",
      "| epoch  20 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.64 | ppl   765.06 | bpc    9.579\n",
      "| epoch  20 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.66 | ppl   779.89 | bpc    9.607\n",
      "| epoch  20 |   250/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.68 | ppl   797.83 | bpc    9.640\n",
      "| epoch  20 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.68 | ppl   793.56 | bpc    9.632\n",
      "| epoch  20 |   350/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.66 | ppl   783.46 | bpc    9.614\n",
      "| epoch  20 |   400/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.65 | ppl   772.16 | bpc    9.593\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 19.73s | valid loss  6.58 | valid ppl   721.07 | bpc    9.494\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.586426 --> 6.580731).  Saving model ...\n",
      "| epoch  21 |    50/  414 batches | lr 0.0001 | ms/batch 32.25 | loss  6.81 | ppl   904.95 | bpc    9.822\n",
      "| epoch  21 |   100/  414 batches | lr 0.0001 | ms/batch 33.31 | loss  6.67 | ppl   787.48 | bpc    9.621\n",
      "| epoch  21 |   150/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.63 | ppl   760.26 | bpc    9.570\n",
      "| epoch  21 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.65 | ppl   773.25 | bpc    9.595\n",
      "| epoch  21 |   250/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.68 | ppl   792.55 | bpc    9.630\n",
      "| epoch  21 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.67 | ppl   786.32 | bpc    9.619\n",
      "| epoch  21 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.66 | ppl   777.84 | bpc    9.603\n",
      "| epoch  21 |   400/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.64 | ppl   766.69 | bpc    9.583\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 19.55s | valid loss  6.58 | valid ppl   717.49 | bpc    9.487\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.580731 --> 6.575762).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  22 |    50/  414 batches | lr 0.0001 | ms/batch 33.13 | loss  6.80 | ppl   897.79 | bpc    9.810\n",
      "| epoch  22 |   100/  414 batches | lr 0.0001 | ms/batch 32.79 | loss  6.66 | ppl   784.09 | bpc    9.615\n",
      "| epoch  22 |   150/  414 batches | lr 0.0001 | ms/batch 33.76 | loss  6.63 | ppl   757.04 | bpc    9.564\n",
      "| epoch  22 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.65 | ppl   769.99 | bpc    9.589\n",
      "| epoch  22 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.67 | ppl   790.53 | bpc    9.627\n",
      "| epoch  22 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.66 | ppl   783.73 | bpc    9.614\n",
      "| epoch  22 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.65 | ppl   773.91 | bpc    9.596\n",
      "| epoch  22 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.64 | ppl   762.15 | bpc    9.574\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 19.51s | valid loss  6.57 | valid ppl   714.48 | bpc    9.481\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.575762 --> 6.571561).  Saving model ...\n",
      "| epoch  23 |    50/  414 batches | lr 0.0001 | ms/batch 32.33 | loss  6.79 | ppl   892.91 | bpc    9.802\n",
      "| epoch  23 |   100/  414 batches | lr 0.0001 | ms/batch 33.46 | loss  6.66 | ppl   778.58 | bpc    9.605\n",
      "| epoch  23 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.62 | ppl   752.43 | bpc    9.555\n",
      "| epoch  23 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.64 | ppl   765.77 | bpc    9.581\n",
      "| epoch  23 |   250/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.67 | ppl   786.62 | bpc    9.620\n",
      "| epoch  23 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.66 | ppl   778.76 | bpc    9.605\n",
      "| epoch  23 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.65 | ppl   771.49 | bpc    9.591\n",
      "| epoch  23 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.63 | ppl   757.90 | bpc    9.566\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 19.56s | valid loss  6.57 | valid ppl   711.77 | bpc    9.475\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.571561 --> 6.567756).  Saving model ...\n",
      "| epoch  24 |    50/  414 batches | lr 0.0001 | ms/batch 35.56 | loss  6.79 | ppl   888.07 | bpc    9.795\n",
      "| epoch  24 |   100/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.66 | ppl   776.67 | bpc    9.601\n",
      "| epoch  24 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.62 | ppl   747.36 | bpc    9.546\n",
      "| epoch  24 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.64 | ppl   761.82 | bpc    9.573\n",
      "| epoch  24 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.66 | ppl   780.95 | bpc    9.609\n",
      "| epoch  24 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.65 | ppl   776.40 | bpc    9.601\n",
      "| epoch  24 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.64 | ppl   767.42 | bpc    9.584\n",
      "| epoch  24 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.63 | ppl   754.95 | bpc    9.560\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 19.79s | valid loss  6.56 | valid ppl   709.40 | bpc    9.470\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.567756 --> 6.564418).  Saving model ...\n",
      "| epoch  25 |    50/  414 batches | lr 0.0001 | ms/batch 32.23 | loss  6.79 | ppl   885.03 | bpc    9.790\n",
      "| epoch  25 |   100/  414 batches | lr 0.0001 | ms/batch 32.97 | loss  6.65 | ppl   772.38 | bpc    9.593\n",
      "| epoch  25 |   150/  414 batches | lr 0.0001 | ms/batch 34.08 | loss  6.61 | ppl   745.61 | bpc    9.542\n",
      "| epoch  25 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.63 | ppl   759.03 | bpc    9.568\n",
      "| epoch  25 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.66 | ppl   778.47 | bpc    9.604\n",
      "| epoch  25 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.65 | ppl   773.06 | bpc    9.594\n",
      "| epoch  25 |   350/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.64 | ppl   765.49 | bpc    9.580\n",
      "| epoch  25 |   400/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.62 | ppl   753.51 | bpc    9.557\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 19.49s | valid loss  6.56 | valid ppl   707.33 | bpc    9.466\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.564418 --> 6.561492).  Saving model ...\n",
      "| epoch  26 |    50/  414 batches | lr 0.0001 | ms/batch 34.76 | loss  6.78 | ppl   881.58 | bpc    9.784\n",
      "| epoch  26 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.64 | ppl   768.71 | bpc    9.586\n",
      "| epoch  26 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   741.79 | bpc    9.535\n",
      "| epoch  26 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.63 | ppl   755.20 | bpc    9.561\n",
      "| epoch  26 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.65 | ppl   775.56 | bpc    9.599\n",
      "| epoch  26 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.65 | ppl   770.56 | bpc    9.590\n",
      "| epoch  26 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.64 | ppl   761.76 | bpc    9.573\n",
      "| epoch  26 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.62 | ppl   750.54 | bpc    9.552\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 19.75s | valid loss  6.56 | valid ppl   705.45 | bpc    9.462\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.561492 --> 6.558842).  Saving model ...\n",
      "| epoch  27 |    50/  414 batches | lr 0.0001 | ms/batch 33.29 | loss  6.78 | ppl   877.98 | bpc    9.778\n",
      "| epoch  27 |   100/  414 batches | lr 0.0001 | ms/batch 34.31 | loss  6.64 | ppl   766.15 | bpc    9.581\n",
      "| epoch  27 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   739.11 | bpc    9.530\n",
      "| epoch  27 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.62 | ppl   753.03 | bpc    9.557\n",
      "| epoch  27 |   250/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.65 | ppl   773.73 | bpc    9.596\n",
      "| epoch  27 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.64 | ppl   766.59 | bpc    9.582\n",
      "| epoch  27 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.63 | ppl   758.60 | bpc    9.567\n",
      "| epoch  27 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   748.28 | bpc    9.547\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 19.65s | valid loss  6.56 | valid ppl   703.79 | bpc    9.459\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.558842 --> 6.556481).  Saving model ...\n",
      "| epoch  28 |    50/  414 batches | lr 0.0001 | ms/batch 33.03 | loss  6.77 | ppl   874.35 | bpc    9.772\n",
      "| epoch  28 |   100/  414 batches | lr 0.0001 | ms/batch 34.54 | loss  6.64 | ppl   764.53 | bpc    9.578\n",
      "| epoch  28 |   150/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.60 | ppl   737.21 | bpc    9.526\n",
      "| epoch  28 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   751.13 | bpc    9.553\n",
      "| epoch  28 |   250/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.65 | ppl   769.09 | bpc    9.587\n",
      "| epoch  28 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.64 | ppl   764.60 | bpc    9.579\n",
      "| epoch  28 |   350/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.63 | ppl   757.94 | bpc    9.566\n",
      "| epoch  28 |   400/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.61 | ppl   746.13 | bpc    9.543\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 19.65s | valid loss  6.55 | valid ppl   702.30 | bpc    9.456\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.556481 --> 6.554362).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  29 |    50/  414 batches | lr 0.0001 | ms/batch 32.60 | loss  6.77 | ppl   873.44 | bpc    9.771\n",
      "| epoch  29 |   100/  414 batches | lr 0.0001 | ms/batch 32.52 | loss  6.64 | ppl   761.37 | bpc    9.572\n",
      "| epoch  29 |   150/  414 batches | lr 0.0001 | ms/batch 33.90 | loss  6.60 | ppl   734.05 | bpc    9.520\n",
      "| epoch  29 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.62 | ppl   747.28 | bpc    9.546\n",
      "| epoch  29 |   250/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.65 | ppl   769.07 | bpc    9.587\n",
      "| epoch  29 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.64 | ppl   762.83 | bpc    9.575\n",
      "| epoch  29 |   350/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.63 | ppl   754.21 | bpc    9.559\n",
      "| epoch  29 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   743.28 | bpc    9.538\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 19.48s | valid loss  6.55 | valid ppl   700.95 | bpc    9.453\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.554362 --> 6.552436).  Saving model ...\n",
      "| epoch  30 |    50/  414 batches | lr 0.0001 | ms/batch 34.17 | loss  6.77 | ppl   870.66 | bpc    9.766\n",
      "| epoch  30 |   100/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.63 | ppl   758.63 | bpc    9.567\n",
      "| epoch  30 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   731.86 | bpc    9.515\n",
      "| epoch  30 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.61 | ppl   744.99 | bpc    9.541\n",
      "| epoch  30 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.64 | ppl   765.37 | bpc    9.580\n",
      "| epoch  30 |   300/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.63 | ppl   761.19 | bpc    9.572\n",
      "| epoch  30 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.63 | ppl   753.91 | bpc    9.558\n",
      "| epoch  30 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   742.55 | bpc    9.536\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 19.73s | valid loss  6.55 | valid ppl   699.72 | bpc    9.451\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.552436 --> 6.550683).  Saving model ...\n",
      "| epoch  31 |    50/  414 batches | lr 0.0001 | ms/batch 33.37 | loss  6.76 | ppl   866.90 | bpc    9.760\n",
      "| epoch  31 |   100/  414 batches | lr 0.0001 | ms/batch 34.67 | loss  6.63 | ppl   758.86 | bpc    9.568\n",
      "| epoch  31 |   150/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.60 | ppl   732.08 | bpc    9.516\n",
      "| epoch  31 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.61 | ppl   743.58 | bpc    9.538\n",
      "| epoch  31 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.64 | ppl   765.42 | bpc    9.580\n",
      "| epoch  31 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.63 | ppl   758.69 | bpc    9.567\n",
      "| epoch  31 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.62 | ppl   751.51 | bpc    9.554\n",
      "| epoch  31 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   739.75 | bpc    9.531\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 19.68s | valid loss  6.55 | valid ppl   698.63 | bpc    9.448\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.550683 --> 6.549128).  Saving model ...\n",
      "| epoch  32 |    50/  414 batches | lr 0.0001 | ms/batch 35.58 | loss  6.76 | ppl   866.15 | bpc    9.758\n",
      "| epoch  32 |   100/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.63 | ppl   756.31 | bpc    9.563\n",
      "| epoch  32 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   729.29 | bpc    9.510\n",
      "| epoch  32 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.61 | ppl   742.74 | bpc    9.537\n",
      "| epoch  32 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.64 | ppl   762.13 | bpc    9.574\n",
      "| epoch  32 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.63 | ppl   757.26 | bpc    9.565\n",
      "| epoch  32 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.62 | ppl   750.47 | bpc    9.552\n",
      "| epoch  32 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.60 | ppl   738.57 | bpc    9.529\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 19.80s | valid loss  6.55 | valid ppl   697.63 | bpc    9.446\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.549128 --> 6.547690).  Saving model ...\n",
      "| epoch  33 |    50/  414 batches | lr 0.0001 | ms/batch 32.40 | loss  6.76 | ppl   866.72 | bpc    9.759\n",
      "| epoch  33 |   100/  414 batches | lr 0.0001 | ms/batch 33.70 | loss  6.63 | ppl   755.94 | bpc    9.562\n",
      "| epoch  33 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   729.07 | bpc    9.510\n",
      "| epoch  33 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.61 | ppl   741.03 | bpc    9.533\n",
      "| epoch  33 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.64 | ppl   761.65 | bpc    9.573\n",
      "| epoch  33 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.63 | ppl   754.49 | bpc    9.559\n",
      "| epoch  33 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.62 | ppl   747.26 | bpc    9.545\n",
      "| epoch  33 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   737.21 | bpc    9.526\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 19.58s | valid loss  6.55 | valid ppl   696.72 | bpc    9.444\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.547690 --> 6.546389).  Saving model ...\n",
      "| epoch  34 |    50/  414 batches | lr 0.0001 | ms/batch 32.33 | loss  6.76 | ppl   862.08 | bpc    9.752\n",
      "| epoch  34 |   100/  414 batches | lr 0.0001 | ms/batch 32.21 | loss  6.62 | ppl   751.98 | bpc    9.555\n",
      "| epoch  34 |   150/  414 batches | lr 0.0001 | ms/batch 34.32 | loss  6.59 | ppl   724.95 | bpc    9.502\n",
      "| epoch  34 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   740.57 | bpc    9.532\n",
      "| epoch  34 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.63 | ppl   760.19 | bpc    9.570\n",
      "| epoch  34 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.63 | ppl   754.20 | bpc    9.559\n",
      "| epoch  34 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   746.19 | bpc    9.543\n",
      "| epoch  34 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   736.34 | bpc    9.524\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 19.47s | valid loss  6.55 | valid ppl   695.87 | bpc    9.443\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.546389 --> 6.545166).  Saving model ...\n",
      "| epoch  35 |    50/  414 batches | lr 0.0001 | ms/batch 35.44 | loss  6.76 | ppl   860.02 | bpc    9.748\n",
      "| epoch  35 |   100/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.62 | ppl   752.07 | bpc    9.555\n",
      "| epoch  35 |   150/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.59 | ppl   725.39 | bpc    9.503\n",
      "| epoch  35 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   737.84 | bpc    9.527\n",
      "| epoch  35 |   250/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.63 | ppl   758.04 | bpc    9.566\n",
      "| epoch  35 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.62 | ppl   751.90 | bpc    9.554\n",
      "| epoch  35 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   743.68 | bpc    9.539\n",
      "| epoch  35 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   733.95 | bpc    9.520\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 19.79s | valid loss  6.54 | valid ppl   695.10 | bpc    9.441\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.545166 --> 6.544052).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  36 |    50/  414 batches | lr 0.0001 | ms/batch 35.40 | loss  6.76 | ppl   860.13 | bpc    9.748\n",
      "| epoch  36 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   749.87 | bpc    9.551\n",
      "| epoch  36 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   722.90 | bpc    9.498\n",
      "| epoch  36 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.60 | ppl   735.51 | bpc    9.523\n",
      "| epoch  36 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.63 | ppl   756.22 | bpc    9.563\n",
      "| epoch  36 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.62 | ppl   750.62 | bpc    9.552\n",
      "| epoch  36 |   350/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.61 | ppl   744.79 | bpc    9.541\n",
      "| epoch  36 |   400/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.60 | ppl   732.87 | bpc    9.517\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 19.78s | valid loss  6.54 | valid ppl   694.35 | bpc    9.440\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.544052 --> 6.542972).  Saving model ...\n",
      "| epoch  37 |    50/  414 batches | lr 0.0001 | ms/batch 33.47 | loss  6.75 | ppl   857.99 | bpc    9.745\n",
      "| epoch  37 |   100/  414 batches | lr 0.0001 | ms/batch 34.38 | loss  6.62 | ppl   749.37 | bpc    9.550\n",
      "| epoch  37 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   721.39 | bpc    9.495\n",
      "| epoch  37 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   733.33 | bpc    9.518\n",
      "| epoch  37 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.63 | ppl   755.22 | bpc    9.561\n",
      "| epoch  37 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   749.82 | bpc    9.550\n",
      "| epoch  37 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   742.75 | bpc    9.537\n",
      "| epoch  37 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   731.67 | bpc    9.515\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 19.67s | valid loss  6.54 | valid ppl   693.68 | bpc    9.438\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.542972 --> 6.542014).  Saving model ...\n",
      "| epoch  38 |    50/  414 batches | lr 0.0001 | ms/batch 33.59 | loss  6.75 | ppl   857.19 | bpc    9.743\n",
      "| epoch  38 |   100/  414 batches | lr 0.0001 | ms/batch 33.81 | loss  6.62 | ppl   747.21 | bpc    9.545\n",
      "| epoch  38 |   150/  414 batches | lr 0.0001 | ms/batch 34.79 | loss  6.58 | ppl   720.32 | bpc    9.492\n",
      "| epoch  38 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   733.63 | bpc    9.519\n",
      "| epoch  38 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.63 | ppl   754.75 | bpc    9.560\n",
      "| epoch  38 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.62 | ppl   748.19 | bpc    9.547\n",
      "| epoch  38 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.61 | ppl   740.35 | bpc    9.532\n",
      "| epoch  38 |   400/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.59 | ppl   728.85 | bpc    9.509\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 19.63s | valid loss  6.54 | valid ppl   693.07 | bpc    9.437\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.542014 --> 6.541131).  Saving model ...\n",
      "| epoch  39 |    50/  414 batches | lr 0.0001 | ms/batch 32.80 | loss  6.75 | ppl   856.32 | bpc    9.742\n",
      "| epoch  39 |   100/  414 batches | lr 0.0001 | ms/batch 34.60 | loss  6.61 | ppl   745.26 | bpc    9.542\n",
      "| epoch  39 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   719.88 | bpc    9.492\n",
      "| epoch  39 |   200/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.60 | ppl   731.51 | bpc    9.515\n",
      "| epoch  39 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   753.09 | bpc    9.557\n",
      "| epoch  39 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.61 | ppl   746.14 | bpc    9.543\n",
      "| epoch  39 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.61 | ppl   740.49 | bpc    9.532\n",
      "| epoch  39 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.59 | ppl   729.63 | bpc    9.511\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 19.64s | valid loss  6.54 | valid ppl   692.47 | bpc    9.436\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.541131 --> 6.540270).  Saving model ...\n",
      "| epoch  40 |    50/  414 batches | lr 0.0001 | ms/batch 35.39 | loss  6.75 | ppl   853.19 | bpc    9.737\n",
      "| epoch  40 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   744.94 | bpc    9.541\n",
      "| epoch  40 |   150/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.58 | ppl   718.10 | bpc    9.488\n",
      "| epoch  40 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.59 | ppl   730.51 | bpc    9.513\n",
      "| epoch  40 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   751.39 | bpc    9.553\n",
      "| epoch  40 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.62 | ppl   746.60 | bpc    9.544\n",
      "| epoch  40 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.61 | ppl   740.04 | bpc    9.531\n",
      "| epoch  40 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   727.94 | bpc    9.508\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 19.78s | valid loss  6.54 | valid ppl   691.91 | bpc    9.434\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.540270 --> 6.539454).  Saving model ...\n",
      "| epoch  41 |    50/  414 batches | lr 0.0001 | ms/batch 33.68 | loss  6.75 | ppl   851.51 | bpc    9.734\n",
      "| epoch  41 |   100/  414 batches | lr 0.0001 | ms/batch 34.78 | loss  6.61 | ppl   744.21 | bpc    9.540\n",
      "| epoch  41 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   715.84 | bpc    9.483\n",
      "| epoch  41 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   730.80 | bpc    9.513\n",
      "| epoch  41 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   751.28 | bpc    9.553\n",
      "| epoch  41 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.61 | ppl   745.65 | bpc    9.542\n",
      "| epoch  41 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   738.19 | bpc    9.528\n",
      "| epoch  41 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   727.37 | bpc    9.507\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 19.70s | valid loss  6.54 | valid ppl   691.42 | bpc    9.433\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.539454 --> 6.538745).  Saving model ...\n",
      "| epoch  42 |    50/  414 batches | lr 0.0001 | ms/batch 35.49 | loss  6.75 | ppl   851.13 | bpc    9.733\n",
      "| epoch  42 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   742.93 | bpc    9.537\n",
      "| epoch  42 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   714.96 | bpc    9.482\n",
      "| epoch  42 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   729.48 | bpc    9.511\n",
      "| epoch  42 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.62 | ppl   749.70 | bpc    9.550\n",
      "| epoch  42 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.61 | ppl   744.97 | bpc    9.541\n",
      "| epoch  42 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   737.41 | bpc    9.526\n",
      "| epoch  42 |   400/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.59 | ppl   726.21 | bpc    9.504\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 19.79s | valid loss  6.54 | valid ppl   690.97 | bpc    9.432\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.538745 --> 6.538092).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  43 |    50/  414 batches | lr 0.0001 | ms/batch 33.63 | loss  6.75 | ppl   850.63 | bpc    9.732\n",
      "| epoch  43 |   100/  414 batches | lr 0.0001 | ms/batch 34.57 | loss  6.61 | ppl   742.75 | bpc    9.537\n",
      "| epoch  43 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   715.75 | bpc    9.483\n",
      "| epoch  43 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   728.11 | bpc    9.508\n",
      "| epoch  43 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   749.63 | bpc    9.550\n",
      "| epoch  43 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   743.33 | bpc    9.538\n",
      "| epoch  43 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   736.46 | bpc    9.524\n",
      "| epoch  43 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   725.67 | bpc    9.503\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 19.69s | valid loss  6.54 | valid ppl   690.52 | bpc    9.432\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.538092 --> 6.537448).  Saving model ...\n",
      "| epoch  44 |    50/  414 batches | lr 0.0001 | ms/batch 35.60 | loss  6.74 | ppl   848.85 | bpc    9.729\n",
      "| epoch  44 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   740.86 | bpc    9.533\n",
      "| epoch  44 |   150/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.57 | ppl   714.05 | bpc    9.480\n",
      "| epoch  44 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   726.04 | bpc    9.504\n",
      "| epoch  44 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.62 | ppl   747.46 | bpc    9.546\n",
      "| epoch  44 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.61 | ppl   743.80 | bpc    9.539\n",
      "| epoch  44 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   735.35 | bpc    9.522\n",
      "| epoch  44 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   725.39 | bpc    9.503\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 19.80s | valid loss  6.54 | valid ppl   690.11 | bpc    9.431\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.537448 --> 6.536849).  Saving model ...\n",
      "| epoch  45 |    50/  414 batches | lr 0.0001 | ms/batch 35.42 | loss  6.74 | ppl   849.66 | bpc    9.731\n",
      "| epoch  45 |   100/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.61 | ppl   739.10 | bpc    9.530\n",
      "| epoch  45 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   713.36 | bpc    9.478\n",
      "| epoch  45 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   727.00 | bpc    9.506\n",
      "| epoch  45 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.62 | ppl   747.78 | bpc    9.546\n",
      "| epoch  45 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.61 | ppl   741.13 | bpc    9.534\n",
      "| epoch  45 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   733.96 | bpc    9.520\n",
      "| epoch  45 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   723.21 | bpc    9.498\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 19.79s | valid loss  6.54 | valid ppl   689.72 | bpc    9.430\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.536849 --> 6.536292).  Saving model ...\n",
      "| epoch  46 |    50/  414 batches | lr 0.0001 | ms/batch 32.85 | loss  6.74 | ppl   846.10 | bpc    9.725\n",
      "| epoch  46 |   100/  414 batches | lr 0.0001 | ms/batch 32.13 | loss  6.61 | ppl   740.23 | bpc    9.532\n",
      "| epoch  46 |   150/  414 batches | lr 0.0001 | ms/batch 34.05 | loss  6.57 | ppl   711.83 | bpc    9.475\n",
      "| epoch  46 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   725.50 | bpc    9.503\n",
      "| epoch  46 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   746.18 | bpc    9.543\n",
      "| epoch  46 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.61 | ppl   740.04 | bpc    9.531\n",
      "| epoch  46 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   733.74 | bpc    9.519\n",
      "| epoch  46 |   400/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.58 | ppl   723.12 | bpc    9.498\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 19.48s | valid loss  6.54 | valid ppl   689.32 | bpc    9.429\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.536292 --> 6.535712).  Saving model ...\n",
      "| epoch  47 |    50/  414 batches | lr 0.0001 | ms/batch 35.59 | loss  6.74 | ppl   846.09 | bpc    9.725\n",
      "| epoch  47 |   100/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.61 | ppl   739.10 | bpc    9.530\n",
      "| epoch  47 |   150/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.57 | ppl   710.94 | bpc    9.474\n",
      "| epoch  47 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.59 | ppl   724.65 | bpc    9.501\n",
      "| epoch  47 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   745.54 | bpc    9.542\n",
      "| epoch  47 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   740.92 | bpc    9.533\n",
      "| epoch  47 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   733.50 | bpc    9.519\n",
      "| epoch  47 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   721.35 | bpc    9.495\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 19.80s | valid loss  6.54 | valid ppl   688.97 | bpc    9.428\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.535712 --> 6.535194).  Saving model ...\n",
      "| epoch  48 |    50/  414 batches | lr 0.0001 | ms/batch 35.47 | loss  6.74 | ppl   844.91 | bpc    9.723\n",
      "| epoch  48 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   738.71 | bpc    9.529\n",
      "| epoch  48 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   710.59 | bpc    9.473\n",
      "| epoch  48 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   723.78 | bpc    9.499\n",
      "| epoch  48 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   744.38 | bpc    9.540\n",
      "| epoch  48 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   739.57 | bpc    9.531\n",
      "| epoch  48 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   733.24 | bpc    9.518\n",
      "| epoch  48 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   721.67 | bpc    9.495\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 19.79s | valid loss  6.53 | valid ppl   688.63 | bpc    9.428\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.535194 --> 6.534699).  Saving model ...\n",
      "| epoch  49 |    50/  414 batches | lr 0.0001 | ms/batch 32.13 | loss  6.74 | ppl   844.27 | bpc    9.722\n",
      "| epoch  49 |   100/  414 batches | lr 0.0001 | ms/batch 33.45 | loss  6.60 | ppl   738.13 | bpc    9.528\n",
      "| epoch  49 |   150/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.57 | ppl   710.46 | bpc    9.473\n",
      "| epoch  49 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   721.39 | bpc    9.495\n",
      "| epoch  49 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   744.13 | bpc    9.539\n",
      "| epoch  49 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.61 | ppl   739.54 | bpc    9.530\n",
      "| epoch  49 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   731.82 | bpc    9.515\n",
      "| epoch  49 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   721.16 | bpc    9.494\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 19.55s | valid loss  6.53 | valid ppl   688.32 | bpc    9.427\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.534699 --> 6.534256).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  50 |    50/  414 batches | lr 0.0001 | ms/batch 32.38 | loss  6.74 | ppl   844.70 | bpc    9.722\n",
      "| epoch  50 |   100/  414 batches | lr 0.0001 | ms/batch 33.14 | loss  6.60 | ppl   735.92 | bpc    9.523\n",
      "| epoch  50 |   150/  414 batches | lr 0.0001 | ms/batch 34.72 | loss  6.57 | ppl   709.96 | bpc    9.472\n",
      "| epoch  50 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   722.70 | bpc    9.497\n",
      "| epoch  50 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.61 | ppl   742.70 | bpc    9.537\n",
      "| epoch  50 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.61 | ppl   739.54 | bpc    9.530\n",
      "| epoch  50 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   730.84 | bpc    9.513\n",
      "| epoch  50 |   400/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.58 | ppl   720.04 | bpc    9.492\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 19.54s | valid loss  6.53 | valid ppl   688.02 | bpc    9.426\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.534256 --> 6.533823).  Saving model ...\n",
      "| epoch  51 |    50/  414 batches | lr 0.0001 | ms/batch 35.49 | loss  6.74 | ppl   842.44 | bpc    9.718\n",
      "| epoch  51 |   100/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.60 | ppl   736.62 | bpc    9.525\n",
      "| epoch  51 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   709.15 | bpc    9.470\n",
      "| epoch  51 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   721.11 | bpc    9.494\n",
      "| epoch  51 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.61 | ppl   743.98 | bpc    9.539\n",
      "| epoch  51 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.60 | ppl   737.81 | bpc    9.527\n",
      "| epoch  51 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   730.12 | bpc    9.512\n",
      "| epoch  51 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   720.85 | bpc    9.494\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 19.79s | valid loss  6.53 | valid ppl   687.75 | bpc    9.426\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.533823 --> 6.533428).  Saving model ...\n",
      "| epoch  52 |    50/  414 batches | lr 0.0001 | ms/batch 33.81 | loss  6.74 | ppl   843.46 | bpc    9.720\n",
      "| epoch  52 |   100/  414 batches | lr 0.0001 | ms/batch 34.67 | loss  6.60 | ppl   734.47 | bpc    9.521\n",
      "| epoch  52 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   709.54 | bpc    9.471\n",
      "| epoch  52 |   200/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.58 | ppl   721.17 | bpc    9.494\n",
      "| epoch  52 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   740.91 | bpc    9.533\n",
      "| epoch  52 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   736.68 | bpc    9.525\n",
      "| epoch  52 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   730.61 | bpc    9.513\n",
      "| epoch  52 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   718.88 | bpc    9.490\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 19.70s | valid loss  6.53 | valid ppl   687.48 | bpc    9.425\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.533428 --> 6.533032).  Saving model ...\n",
      "| epoch  53 |    50/  414 batches | lr 0.0001 | ms/batch 35.58 | loss  6.74 | ppl   841.99 | bpc    9.718\n",
      "| epoch  53 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   735.58 | bpc    9.523\n",
      "| epoch  53 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   707.33 | bpc    9.466\n",
      "| epoch  53 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   719.65 | bpc    9.491\n",
      "| epoch  53 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.61 | ppl   741.60 | bpc    9.535\n",
      "| epoch  53 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.60 | ppl   735.45 | bpc    9.522\n",
      "| epoch  53 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   728.54 | bpc    9.509\n",
      "| epoch  53 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   717.83 | bpc    9.487\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 19.80s | valid loss  6.53 | valid ppl   687.21 | bpc    9.425\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.533032 --> 6.532640).  Saving model ...\n",
      "| epoch  54 |    50/  414 batches | lr 0.0001 | ms/batch 32.61 | loss  6.73 | ppl   840.55 | bpc    9.715\n",
      "| epoch  54 |   100/  414 batches | lr 0.0001 | ms/batch 32.82 | loss  6.60 | ppl   734.02 | bpc    9.520\n",
      "| epoch  54 |   150/  414 batches | lr 0.0001 | ms/batch 33.36 | loss  6.56 | ppl   707.79 | bpc    9.467\n",
      "| epoch  54 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   720.27 | bpc    9.492\n",
      "| epoch  54 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   740.87 | bpc    9.533\n",
      "| epoch  54 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   735.55 | bpc    9.523\n",
      "| epoch  54 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   728.75 | bpc    9.509\n",
      "| epoch  54 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   717.82 | bpc    9.487\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 19.48s | valid loss  6.53 | valid ppl   686.98 | bpc    9.424\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.532640 --> 6.532307).  Saving model ...\n",
      "| epoch  55 |    50/  414 batches | lr 0.0001 | ms/batch 35.56 | loss  6.73 | ppl   840.12 | bpc    9.714\n",
      "| epoch  55 |   100/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.60 | ppl   733.39 | bpc    9.518\n",
      "| epoch  55 |   150/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.56 | ppl   706.93 | bpc    9.465\n",
      "| epoch  55 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   719.20 | bpc    9.490\n",
      "| epoch  55 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.61 | ppl   740.20 | bpc    9.532\n",
      "| epoch  55 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.60 | ppl   734.64 | bpc    9.521\n",
      "| epoch  55 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   728.14 | bpc    9.508\n",
      "| epoch  55 |   400/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.57 | ppl   716.17 | bpc    9.484\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 19.81s | valid loss  6.53 | valid ppl   686.74 | bpc    9.424\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.532307 --> 6.531955).  Saving model ...\n",
      "| epoch  56 |    50/  414 batches | lr 0.0001 | ms/batch 32.40 | loss  6.73 | ppl   838.78 | bpc    9.712\n",
      "| epoch  56 |   100/  414 batches | lr 0.0001 | ms/batch 33.27 | loss  6.60 | ppl   733.21 | bpc    9.518\n",
      "| epoch  56 |   150/  414 batches | lr 0.0001 | ms/batch 34.39 | loss  6.56 | ppl   706.18 | bpc    9.464\n",
      "| epoch  56 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   719.19 | bpc    9.490\n",
      "| epoch  56 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.61 | ppl   740.72 | bpc    9.533\n",
      "| epoch  56 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   733.53 | bpc    9.519\n",
      "| epoch  56 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   726.96 | bpc    9.506\n",
      "| epoch  56 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   717.19 | bpc    9.486\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 19.54s | valid loss  6.53 | valid ppl   686.52 | bpc    9.423\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.531955 --> 6.531628).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  57 |    50/  414 batches | lr 0.0001 | ms/batch 32.64 | loss  6.73 | ppl   837.47 | bpc    9.710\n",
      "| epoch  57 |   100/  414 batches | lr 0.0001 | ms/batch 33.33 | loss  6.60 | ppl   732.31 | bpc    9.516\n",
      "| epoch  57 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   705.40 | bpc    9.462\n",
      "| epoch  57 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   718.37 | bpc    9.489\n",
      "| epoch  57 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.61 | ppl   739.73 | bpc    9.531\n",
      "| epoch  57 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   733.18 | bpc    9.518\n",
      "| epoch  57 |   350/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.59 | ppl   727.04 | bpc    9.506\n",
      "| epoch  57 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   715.29 | bpc    9.482\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 19.57s | valid loss  6.53 | valid ppl   686.30 | bpc    9.423\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.531628 --> 6.531322).  Saving model ...\n",
      "| epoch  58 |    50/  414 batches | lr 0.0001 | ms/batch 35.40 | loss  6.73 | ppl   838.14 | bpc    9.711\n",
      "| epoch  58 |   100/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.60 | ppl   732.71 | bpc    9.517\n",
      "| epoch  58 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   704.96 | bpc    9.461\n",
      "| epoch  58 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   718.15 | bpc    9.488\n",
      "| epoch  58 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.61 | ppl   738.90 | bpc    9.529\n",
      "| epoch  58 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.60 | ppl   732.70 | bpc    9.517\n",
      "| epoch  58 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   727.05 | bpc    9.506\n",
      "| epoch  58 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   715.35 | bpc    9.482\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 19.79s | valid loss  6.53 | valid ppl   686.11 | bpc    9.422\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.531322 --> 6.531034).  Saving model ...\n",
      "| epoch  59 |    50/  414 batches | lr 0.0001 | ms/batch 32.90 | loss  6.73 | ppl   837.81 | bpc    9.710\n",
      "| epoch  59 |   100/  414 batches | lr 0.0001 | ms/batch 33.77 | loss  6.60 | ppl   731.62 | bpc    9.515\n",
      "| epoch  59 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   703.05 | bpc    9.457\n",
      "| epoch  59 |   200/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.57 | ppl   716.60 | bpc    9.485\n",
      "| epoch  59 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   737.42 | bpc    9.526\n",
      "| epoch  59 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   732.74 | bpc    9.517\n",
      "| epoch  59 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   725.63 | bpc    9.503\n",
      "| epoch  59 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   714.35 | bpc    9.480\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 19.62s | valid loss  6.53 | valid ppl   685.89 | bpc    9.422\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.531034 --> 6.530719).  Saving model ...\n",
      "| epoch  60 |    50/  414 batches | lr 0.0001 | ms/batch 33.24 | loss  6.73 | ppl   837.81 | bpc    9.710\n",
      "| epoch  60 |   100/  414 batches | lr 0.0001 | ms/batch 34.35 | loss  6.59 | ppl   730.83 | bpc    9.513\n",
      "| epoch  60 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   703.18 | bpc    9.458\n",
      "| epoch  60 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   716.31 | bpc    9.484\n",
      "| epoch  60 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   736.74 | bpc    9.525\n",
      "| epoch  60 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.60 | ppl   732.36 | bpc    9.516\n",
      "| epoch  60 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   724.24 | bpc    9.500\n",
      "| epoch  60 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   715.99 | bpc    9.484\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 19.66s | valid loss  6.53 | valid ppl   685.71 | bpc    9.421\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.530719 --> 6.530455).  Saving model ...\n",
      "| epoch  61 |    50/  414 batches | lr 0.0001 | ms/batch 35.55 | loss  6.73 | ppl   836.88 | bpc    9.709\n",
      "| epoch  61 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   730.87 | bpc    9.513\n",
      "| epoch  61 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   703.92 | bpc    9.459\n",
      "| epoch  61 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   716.42 | bpc    9.485\n",
      "| epoch  61 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.60 | ppl   737.58 | bpc    9.527\n",
      "| epoch  61 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   731.34 | bpc    9.514\n",
      "| epoch  61 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   724.41 | bpc    9.501\n",
      "| epoch  61 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   714.52 | bpc    9.481\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 19.80s | valid loss  6.53 | valid ppl   685.54 | bpc    9.421\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.530455 --> 6.530214).  Saving model ...\n",
      "| epoch  62 |    50/  414 batches | lr 0.0001 | ms/batch 32.72 | loss  6.73 | ppl   835.36 | bpc    9.706\n",
      "| epoch  62 |   100/  414 batches | lr 0.0001 | ms/batch 34.11 | loss  6.59 | ppl   730.24 | bpc    9.512\n",
      "| epoch  62 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   703.19 | bpc    9.458\n",
      "| epoch  62 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   716.11 | bpc    9.484\n",
      "| epoch  62 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   737.20 | bpc    9.526\n",
      "| epoch  62 |   300/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   730.59 | bpc    9.513\n",
      "| epoch  62 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   723.75 | bpc    9.499\n",
      "| epoch  62 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   712.35 | bpc    9.476\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 19.62s | valid loss  6.53 | valid ppl   685.35 | bpc    9.421\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.530214 --> 6.529928).  Saving model ...\n",
      "| epoch  63 |    50/  414 batches | lr 0.0001 | ms/batch 33.13 | loss  6.73 | ppl   835.63 | bpc    9.707\n",
      "| epoch  63 |   100/  414 batches | lr 0.0001 | ms/batch 34.74 | loss  6.59 | ppl   728.99 | bpc    9.510\n",
      "| epoch  63 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   702.83 | bpc    9.457\n",
      "| epoch  63 |   200/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.57 | ppl   715.02 | bpc    9.482\n",
      "| epoch  63 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   737.31 | bpc    9.526\n",
      "| epoch  63 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   730.88 | bpc    9.513\n",
      "| epoch  63 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   724.37 | bpc    9.501\n",
      "| epoch  63 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   712.99 | bpc    9.478\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 19.67s | valid loss  6.53 | valid ppl   685.18 | bpc    9.420\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.529928 --> 6.529688).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  64 |    50/  414 batches | lr 0.0001 | ms/batch 32.46 | loss  6.73 | ppl   835.56 | bpc    9.707\n",
      "| epoch  64 |   100/  414 batches | lr 0.0001 | ms/batch 33.37 | loss  6.59 | ppl   728.95 | bpc    9.510\n",
      "| epoch  64 |   150/  414 batches | lr 0.0001 | ms/batch 34.81 | loss  6.55 | ppl   702.33 | bpc    9.456\n",
      "| epoch  64 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   714.87 | bpc    9.482\n",
      "| epoch  64 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.60 | ppl   736.47 | bpc    9.524\n",
      "| epoch  64 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   730.00 | bpc    9.512\n",
      "| epoch  64 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   724.18 | bpc    9.500\n",
      "| epoch  64 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   712.28 | bpc    9.476\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 19.57s | valid loss  6.53 | valid ppl   685.03 | bpc    9.420\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.529688 --> 6.529469).  Saving model ...\n",
      "| epoch  65 |    50/  414 batches | lr 0.0001 | ms/batch 32.43 | loss  6.73 | ppl   835.65 | bpc    9.707\n",
      "| epoch  65 |   100/  414 batches | lr 0.0001 | ms/batch 33.71 | loss  6.59 | ppl   728.98 | bpc    9.510\n",
      "| epoch  65 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.55 | ppl   702.36 | bpc    9.456\n",
      "| epoch  65 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   714.46 | bpc    9.481\n",
      "| epoch  65 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.60 | ppl   735.41 | bpc    9.522\n",
      "| epoch  65 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   730.42 | bpc    9.513\n",
      "| epoch  65 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   722.96 | bpc    9.498\n",
      "| epoch  65 |   400/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.57 | ppl   712.41 | bpc    9.477\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 19.59s | valid loss  6.53 | valid ppl   684.87 | bpc    9.420\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.529469 --> 6.529228).  Saving model ...\n",
      "| epoch  66 |    50/  414 batches | lr 0.0001 | ms/batch 34.12 | loss  6.73 | ppl   834.32 | bpc    9.704\n",
      "| epoch  66 |   100/  414 batches | lr 0.0001 | ms/batch 34.80 | loss  6.59 | ppl   727.19 | bpc    9.506\n",
      "| epoch  66 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.55 | ppl   701.50 | bpc    9.454\n",
      "| epoch  66 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   713.33 | bpc    9.478\n",
      "| epoch  66 |   250/  414 batches | lr 0.0001 | ms/batch 34.96 | loss  6.60 | ppl   734.44 | bpc    9.520\n",
      "| epoch  66 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   729.37 | bpc    9.511\n",
      "| epoch  66 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   724.34 | bpc    9.501\n",
      "| epoch  66 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   711.62 | bpc    9.475\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 19.73s | valid loss  6.53 | valid ppl   684.73 | bpc    9.419\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.529228 --> 6.529025).  Saving model ...\n",
      "| epoch  67 |    50/  414 batches | lr 0.0001 | ms/batch 35.52 | loss  6.72 | ppl   832.43 | bpc    9.701\n",
      "| epoch  67 |   100/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   728.54 | bpc    9.509\n",
      "| epoch  67 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.55 | ppl   702.03 | bpc    9.455\n",
      "| epoch  67 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   714.02 | bpc    9.480\n",
      "| epoch  67 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.60 | ppl   735.36 | bpc    9.522\n",
      "| epoch  67 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   729.14 | bpc    9.510\n",
      "| epoch  67 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   722.15 | bpc    9.496\n",
      "| epoch  67 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   710.91 | bpc    9.474\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 19.80s | valid loss  6.53 | valid ppl   684.58 | bpc    9.419\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.529025 --> 6.528801).  Saving model ...\n",
      "| epoch  68 |    50/  414 batches | lr 0.0001 | ms/batch 33.50 | loss  6.73 | ppl   834.18 | bpc    9.704\n",
      "| epoch  68 |   100/  414 batches | lr 0.0001 | ms/batch 33.96 | loss  6.59 | ppl   726.52 | bpc    9.505\n",
      "| epoch  68 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.55 | ppl   700.18 | bpc    9.452\n",
      "| epoch  68 |   200/  414 batches | lr 0.0001 | ms/batch 34.94 | loss  6.57 | ppl   713.47 | bpc    9.479\n",
      "| epoch  68 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.60 | ppl   734.50 | bpc    9.521\n",
      "| epoch  68 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   729.13 | bpc    9.510\n",
      "| epoch  68 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   722.52 | bpc    9.497\n",
      "| epoch  68 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   709.52 | bpc    9.471\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 19.65s | valid loss  6.53 | valid ppl   684.43 | bpc    9.419\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.528801 --> 6.528580).  Saving model ...\n",
      "| epoch  69 |    50/  414 batches | lr 0.0001 | ms/batch 32.40 | loss  6.73 | ppl   834.55 | bpc    9.705\n",
      "| epoch  69 |   100/  414 batches | lr 0.0001 | ms/batch 32.07 | loss  6.59 | ppl   727.00 | bpc    9.506\n",
      "| epoch  69 |   150/  414 batches | lr 0.0001 | ms/batch 34.05 | loss  6.55 | ppl   699.79 | bpc    9.451\n",
      "| epoch  69 |   200/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.57 | ppl   712.21 | bpc    9.476\n",
      "| epoch  69 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.60 | ppl   734.35 | bpc    9.520\n",
      "| epoch  69 |   300/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   728.00 | bpc    9.508\n",
      "| epoch  69 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   720.94 | bpc    9.494\n",
      "| epoch  69 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   710.86 | bpc    9.473\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 19.46s | valid loss  6.53 | valid ppl   684.27 | bpc    9.418\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.528580 --> 6.528352).  Saving model ...\n",
      "| epoch  70 |    50/  414 batches | lr 0.0001 | ms/batch 35.47 | loss  6.72 | ppl   832.22 | bpc    9.701\n",
      "| epoch  70 |   100/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   726.91 | bpc    9.506\n",
      "| epoch  70 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.55 | ppl   701.47 | bpc    9.454\n",
      "| epoch  70 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   711.25 | bpc    9.474\n",
      "| epoch  70 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.60 | ppl   733.73 | bpc    9.519\n",
      "| epoch  70 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   727.76 | bpc    9.507\n",
      "| epoch  70 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   720.76 | bpc    9.493\n",
      "| epoch  70 |   400/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.57 | ppl   710.74 | bpc    9.473\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 19.81s | valid loss  6.53 | valid ppl   684.11 | bpc    9.418\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.528352 --> 6.528124).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  71 |    50/  414 batches | lr 0.0001 | ms/batch 33.43 | loss  6.72 | ppl   830.75 | bpc    9.698\n",
      "| epoch  71 |   100/  414 batches | lr 0.0001 | ms/batch 34.18 | loss  6.59 | ppl   725.82 | bpc    9.503\n",
      "| epoch  71 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.55 | ppl   698.51 | bpc    9.448\n",
      "| epoch  71 |   200/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.57 | ppl   712.74 | bpc    9.477\n",
      "| epoch  71 |   250/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.60 | ppl   732.41 | bpc    9.516\n",
      "| epoch  71 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   727.81 | bpc    9.507\n",
      "| epoch  71 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   721.14 | bpc    9.494\n",
      "| epoch  71 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   710.15 | bpc    9.472\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 19.67s | valid loss  6.53 | valid ppl   683.98 | bpc    9.418\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.528124 --> 6.527936).  Saving model ...\n",
      "| epoch  72 |    50/  414 batches | lr 0.0001 | ms/batch 35.59 | loss  6.72 | ppl   831.24 | bpc    9.699\n",
      "| epoch  72 |   100/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   727.19 | bpc    9.506\n",
      "| epoch  72 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.55 | ppl   700.66 | bpc    9.453\n",
      "| epoch  72 |   200/  414 batches | lr 0.0001 | ms/batch 34.92 | loss  6.57 | ppl   711.31 | bpc    9.474\n",
      "| epoch  72 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.60 | ppl   733.54 | bpc    9.519\n",
      "| epoch  72 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   728.53 | bpc    9.509\n",
      "| epoch  72 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   720.21 | bpc    9.492\n",
      "| epoch  72 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   709.92 | bpc    9.472\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 19.81s | valid loss  6.53 | valid ppl   683.86 | bpc    9.418\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.527936 --> 6.527760).  Saving model ...\n",
      "| epoch  73 |    50/  414 batches | lr 0.0001 | ms/batch 32.60 | loss  6.72 | ppl   831.04 | bpc    9.699\n",
      "| epoch  73 |   100/  414 batches | lr 0.0001 | ms/batch 33.30 | loss  6.59 | ppl   724.66 | bpc    9.501\n",
      "| epoch  73 |   150/  414 batches | lr 0.0001 | ms/batch 34.70 | loss  6.55 | ppl   699.33 | bpc    9.450\n",
      "| epoch  73 |   200/  414 batches | lr 0.0001 | ms/batch 34.92 | loss  6.57 | ppl   711.04 | bpc    9.474\n",
      "| epoch  73 |   250/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.60 | ppl   732.38 | bpc    9.516\n",
      "| epoch  73 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   726.49 | bpc    9.505\n",
      "| epoch  73 |   350/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   720.25 | bpc    9.492\n",
      "| epoch  73 |   400/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.56 | ppl   709.46 | bpc    9.471\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 19.57s | valid loss  6.53 | valid ppl   683.74 | bpc    9.417\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.527760 --> 6.527571).  Saving model ...\n",
      "| epoch  74 |    50/  414 batches | lr 0.0001 | ms/batch 33.58 | loss  6.72 | ppl   830.89 | bpc    9.699\n",
      "| epoch  74 |   100/  414 batches | lr 0.0001 | ms/batch 34.57 | loss  6.59 | ppl   726.28 | bpc    9.504\n",
      "| epoch  74 |   150/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.55 | ppl   699.53 | bpc    9.450\n",
      "| epoch  74 |   200/  414 batches | lr 0.0001 | ms/batch 34.92 | loss  6.57 | ppl   710.40 | bpc    9.472\n",
      "| epoch  74 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   731.23 | bpc    9.514\n",
      "| epoch  74 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   726.88 | bpc    9.506\n",
      "| epoch  74 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   719.64 | bpc    9.491\n",
      "| epoch  74 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   709.34 | bpc    9.470\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 19.69s | valid loss  6.53 | valid ppl   683.63 | bpc    9.417\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.527571 --> 6.527421).  Saving model ...\n",
      "| epoch  75 |    50/  414 batches | lr 0.0001 | ms/batch 35.57 | loss  6.72 | ppl   830.04 | bpc    9.697\n",
      "| epoch  75 |   100/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   726.54 | bpc    9.505\n",
      "| epoch  75 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.55 | ppl   698.06 | bpc    9.447\n",
      "| epoch  75 |   200/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.56 | ppl   709.72 | bpc    9.471\n",
      "| epoch  75 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.60 | ppl   731.67 | bpc    9.515\n",
      "| epoch  75 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   726.59 | bpc    9.505\n",
      "| epoch  75 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   719.42 | bpc    9.491\n",
      "| epoch  75 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   708.87 | bpc    9.469\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 19.80s | valid loss  6.53 | valid ppl   683.53 | bpc    9.417\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.527421 --> 6.527266).  Saving model ...\n",
      "| epoch  76 |    50/  414 batches | lr 0.0001 | ms/batch 33.42 | loss  6.72 | ppl   830.29 | bpc    9.697\n",
      "| epoch  76 |   100/  414 batches | lr 0.0001 | ms/batch 33.59 | loss  6.59 | ppl   724.75 | bpc    9.501\n",
      "| epoch  76 |   150/  414 batches | lr 0.0001 | ms/batch 34.66 | loss  6.55 | ppl   698.35 | bpc    9.448\n",
      "| epoch  76 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   710.25 | bpc    9.472\n",
      "| epoch  76 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   731.13 | bpc    9.514\n",
      "| epoch  76 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   726.04 | bpc    9.504\n",
      "| epoch  76 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   719.24 | bpc    9.490\n",
      "| epoch  76 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   708.54 | bpc    9.469\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 19.62s | valid loss  6.53 | valid ppl   683.39 | bpc    9.417\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.527266 --> 6.527073).  Saving model ...\n",
      "| epoch  77 |    50/  414 batches | lr 0.0001 | ms/batch 32.41 | loss  6.72 | ppl   829.05 | bpc    9.695\n",
      "| epoch  77 |   100/  414 batches | lr 0.0001 | ms/batch 32.82 | loss  6.59 | ppl   724.35 | bpc    9.501\n",
      "| epoch  77 |   150/  414 batches | lr 0.0001 | ms/batch 34.39 | loss  6.55 | ppl   696.95 | bpc    9.445\n",
      "| epoch  77 |   200/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.56 | ppl   709.21 | bpc    9.470\n",
      "| epoch  77 |   250/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.59 | ppl   730.84 | bpc    9.513\n",
      "| epoch  77 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   724.93 | bpc    9.502\n",
      "| epoch  77 |   350/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   719.54 | bpc    9.491\n",
      "| epoch  77 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   708.24 | bpc    9.468\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 19.52s | valid loss  6.53 | valid ppl   683.25 | bpc    9.416\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.527073 --> 6.526865).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  78 |    50/  414 batches | lr 0.0001 | ms/batch 35.48 | loss  6.72 | ppl   828.58 | bpc    9.694\n",
      "| epoch  78 |   100/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   724.84 | bpc    9.502\n",
      "| epoch  78 |   150/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.55 | ppl   698.12 | bpc    9.447\n",
      "| epoch  78 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   709.02 | bpc    9.470\n",
      "| epoch  78 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   730.65 | bpc    9.513\n",
      "| epoch  78 |   300/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.59 | ppl   726.18 | bpc    9.504\n",
      "| epoch  78 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   719.06 | bpc    9.490\n",
      "| epoch  78 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   707.57 | bpc    9.467\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 19.80s | valid loss  6.53 | valid ppl   683.14 | bpc    9.416\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.526865 --> 6.526699).  Saving model ...\n",
      "| epoch  79 |    50/  414 batches | lr 0.0001 | ms/batch 35.59 | loss  6.72 | ppl   828.86 | bpc    9.695\n",
      "| epoch  79 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   724.31 | bpc    9.500\n",
      "| epoch  79 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.55 | ppl   697.72 | bpc    9.447\n",
      "| epoch  79 |   200/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.57 | ppl   710.10 | bpc    9.472\n",
      "| epoch  79 |   250/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.59 | ppl   730.54 | bpc    9.513\n",
      "| epoch  79 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   725.05 | bpc    9.502\n",
      "| epoch  79 |   350/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   718.84 | bpc    9.490\n",
      "| epoch  79 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   707.67 | bpc    9.467\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 19.81s | valid loss  6.53 | valid ppl   683.02 | bpc    9.416\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.526699 --> 6.526525).  Saving model ...\n",
      "| epoch  80 |    50/  414 batches | lr 0.0001 | ms/batch 33.68 | loss  6.72 | ppl   827.90 | bpc    9.693\n",
      "| epoch  80 |   100/  414 batches | lr 0.0001 | ms/batch 33.88 | loss  6.58 | ppl   723.76 | bpc    9.499\n",
      "| epoch  80 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.55 | ppl   697.05 | bpc    9.445\n",
      "| epoch  80 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   709.12 | bpc    9.470\n",
      "| epoch  80 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   729.40 | bpc    9.511\n",
      "| epoch  80 |   300/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.59 | ppl   724.35 | bpc    9.501\n",
      "| epoch  80 |   350/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.58 | ppl   717.95 | bpc    9.488\n",
      "| epoch  80 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   708.19 | bpc    9.468\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 19.66s | valid loss  6.53 | valid ppl   682.92 | bpc    9.416\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.526525 --> 6.526379).  Saving model ...\n",
      "| epoch  81 |    50/  414 batches | lr 0.0001 | ms/batch 35.60 | loss  6.72 | ppl   828.55 | bpc    9.694\n",
      "| epoch  81 |   100/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   722.54 | bpc    9.497\n",
      "| epoch  81 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.55 | ppl   696.27 | bpc    9.444\n",
      "| epoch  81 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   708.19 | bpc    9.468\n",
      "| epoch  81 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   729.96 | bpc    9.512\n",
      "| epoch  81 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   723.92 | bpc    9.500\n",
      "| epoch  81 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   717.75 | bpc    9.487\n",
      "| epoch  81 |   400/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.56 | ppl   707.57 | bpc    9.467\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 19.81s | valid loss  6.53 | valid ppl   682.82 | bpc    9.415\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.526379 --> 6.526235).  Saving model ...\n",
      "| epoch  82 |    50/  414 batches | lr 0.0001 | ms/batch 33.24 | loss  6.72 | ppl   828.03 | bpc    9.694\n",
      "| epoch  82 |   100/  414 batches | lr 0.0001 | ms/batch 33.93 | loss  6.58 | ppl   723.44 | bpc    9.499\n",
      "| epoch  82 |   150/  414 batches | lr 0.0001 | ms/batch 34.74 | loss  6.55 | ppl   696.69 | bpc    9.444\n",
      "| epoch  82 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   708.57 | bpc    9.469\n",
      "| epoch  82 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   728.92 | bpc    9.510\n",
      "| epoch  82 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   724.69 | bpc    9.501\n",
      "| epoch  82 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   717.90 | bpc    9.488\n",
      "| epoch  82 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   707.39 | bpc    9.466\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 19.63s | valid loss  6.53 | valid ppl   682.72 | bpc    9.415\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.526235 --> 6.526081).  Saving model ...\n",
      "| epoch  83 |    50/  414 batches | lr 0.0001 | ms/batch 32.55 | loss  6.72 | ppl   827.80 | bpc    9.693\n",
      "| epoch  83 |   100/  414 batches | lr 0.0001 | ms/batch 33.01 | loss  6.58 | ppl   722.97 | bpc    9.498\n",
      "| epoch  83 |   150/  414 batches | lr 0.0001 | ms/batch 34.49 | loss  6.55 | ppl   695.87 | bpc    9.443\n",
      "| epoch  83 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   708.85 | bpc    9.469\n",
      "| epoch  83 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   729.66 | bpc    9.511\n",
      "| epoch  83 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   723.38 | bpc    9.499\n",
      "| epoch  83 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   717.70 | bpc    9.487\n",
      "| epoch  83 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   706.46 | bpc    9.464\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 19.54s | valid loss  6.53 | valid ppl   682.60 | bpc    9.415\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.526081 --> 6.525913).  Saving model ...\n",
      "| epoch  84 |    50/  414 batches | lr 0.0001 | ms/batch 32.67 | loss  6.72 | ppl   826.32 | bpc    9.691\n",
      "| epoch  84 |   100/  414 batches | lr 0.0001 | ms/batch 33.52 | loss  6.58 | ppl   723.50 | bpc    9.499\n",
      "| epoch  84 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.54 | ppl   695.33 | bpc    9.442\n",
      "| epoch  84 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   707.40 | bpc    9.466\n",
      "| epoch  84 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   728.64 | bpc    9.509\n",
      "| epoch  84 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   722.44 | bpc    9.497\n",
      "| epoch  84 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   716.78 | bpc    9.485\n",
      "| epoch  84 |   400/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   705.56 | bpc    9.463\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 19.59s | valid loss  6.53 | valid ppl   682.50 | bpc    9.415\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.525913 --> 6.525758).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  85 |    50/  414 batches | lr 0.0001 | ms/batch 35.52 | loss  6.72 | ppl   826.96 | bpc    9.692\n",
      "| epoch  85 |   100/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   722.63 | bpc    9.497\n",
      "| epoch  85 |   150/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.55 | ppl   696.10 | bpc    9.443\n",
      "| epoch  85 |   200/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.56 | ppl   707.18 | bpc    9.466\n",
      "| epoch  85 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   729.21 | bpc    9.510\n",
      "| epoch  85 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   723.56 | bpc    9.499\n",
      "| epoch  85 |   350/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.57 | ppl   716.80 | bpc    9.485\n",
      "| epoch  85 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   706.22 | bpc    9.464\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 19.80s | valid loss  6.53 | valid ppl   682.40 | bpc    9.414\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.525758 --> 6.525609).  Saving model ...\n",
      "| epoch  86 |    50/  414 batches | lr 0.0001 | ms/batch 35.56 | loss  6.72 | ppl   826.75 | bpc    9.691\n",
      "| epoch  86 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   721.70 | bpc    9.495\n",
      "| epoch  86 |   150/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.54 | ppl   695.11 | bpc    9.441\n",
      "| epoch  86 |   200/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.56 | ppl   706.88 | bpc    9.465\n",
      "| epoch  86 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   728.23 | bpc    9.508\n",
      "| epoch  86 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   723.34 | bpc    9.499\n",
      "| epoch  86 |   350/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.57 | ppl   715.79 | bpc    9.483\n",
      "| epoch  86 |   400/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.56 | ppl   705.52 | bpc    9.463\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 19.82s | valid loss  6.53 | valid ppl   682.29 | bpc    9.414\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.525609 --> 6.525459).  Saving model ...\n",
      "| epoch  87 |    50/  414 batches | lr 0.0001 | ms/batch 32.79 | loss  6.72 | ppl   827.67 | bpc    9.693\n",
      "| epoch  87 |   100/  414 batches | lr 0.0001 | ms/batch 34.43 | loss  6.58 | ppl   721.13 | bpc    9.494\n",
      "| epoch  87 |   150/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.54 | ppl   695.50 | bpc    9.442\n",
      "| epoch  87 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   707.17 | bpc    9.466\n",
      "| epoch  87 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   727.74 | bpc    9.507\n",
      "| epoch  87 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.58 | ppl   722.30 | bpc    9.496\n",
      "| epoch  87 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   715.98 | bpc    9.484\n",
      "| epoch  87 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   705.74 | bpc    9.463\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 19.64s | valid loss  6.53 | valid ppl   682.19 | bpc    9.414\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.525459 --> 6.525305).  Saving model ...\n",
      "| epoch  88 |    50/  414 batches | lr 0.0001 | ms/batch 32.23 | loss  6.72 | ppl   826.89 | bpc    9.692\n",
      "| epoch  88 |   100/  414 batches | lr 0.0001 | ms/batch 32.03 | loss  6.58 | ppl   722.16 | bpc    9.496\n",
      "| epoch  88 |   150/  414 batches | lr 0.0001 | ms/batch 33.66 | loss  6.54 | ppl   694.45 | bpc    9.440\n",
      "| epoch  88 |   200/  414 batches | lr 0.0001 | ms/batch 34.59 | loss  6.56 | ppl   706.14 | bpc    9.464\n",
      "| epoch  88 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   728.64 | bpc    9.509\n",
      "| epoch  88 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   722.13 | bpc    9.496\n",
      "| epoch  88 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.57 | ppl   715.01 | bpc    9.482\n",
      "| epoch  88 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   705.57 | bpc    9.463\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 19.41s | valid loss  6.53 | valid ppl   682.08 | bpc    9.414\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.525305 --> 6.525153).  Saving model ...\n",
      "| epoch  89 |    50/  414 batches | lr 0.0001 | ms/batch 34.11 | loss  6.72 | ppl   825.80 | bpc    9.690\n",
      "| epoch  89 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   721.57 | bpc    9.495\n",
      "| epoch  89 |   150/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.54 | ppl   694.73 | bpc    9.440\n",
      "| epoch  89 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   706.41 | bpc    9.464\n",
      "| epoch  89 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   726.83 | bpc    9.505\n",
      "| epoch  89 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   721.85 | bpc    9.496\n",
      "| epoch  89 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   715.36 | bpc    9.483\n",
      "| epoch  89 |   400/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   704.05 | bpc    9.460\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 19.73s | valid loss  6.52 | valid ppl   681.96 | bpc    9.414\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.525153 --> 6.524973).  Saving model ...\n",
      "| epoch  90 |    50/  414 batches | lr 0.0001 | ms/batch 32.76 | loss  6.72 | ppl   826.24 | bpc    9.690\n",
      "| epoch  90 |   100/  414 batches | lr 0.0001 | ms/batch 32.75 | loss  6.58 | ppl   721.01 | bpc    9.494\n",
      "| epoch  90 |   150/  414 batches | lr 0.0001 | ms/batch 34.61 | loss  6.54 | ppl   694.98 | bpc    9.441\n",
      "| epoch  90 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   706.16 | bpc    9.464\n",
      "| epoch  90 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   727.03 | bpc    9.506\n",
      "| epoch  90 |   300/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.58 | ppl   722.08 | bpc    9.496\n",
      "| epoch  90 |   350/  414 batches | lr 0.0001 | ms/batch 34.82 | loss  6.57 | ppl   715.87 | bpc    9.484\n",
      "| epoch  90 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   705.09 | bpc    9.462\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 19.54s | valid loss  6.52 | valid ppl   681.85 | bpc    9.413\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524973 --> 6.524811).  Saving model ...\n",
      "| epoch  91 |    50/  414 batches | lr 0.0001 | ms/batch 35.58 | loss  6.72 | ppl   824.84 | bpc    9.688\n",
      "| epoch  91 |   100/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   721.21 | bpc    9.494\n",
      "| epoch  91 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.54 | ppl   693.98 | bpc    9.439\n",
      "| epoch  91 |   200/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   705.33 | bpc    9.462\n",
      "| epoch  91 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   726.75 | bpc    9.505\n",
      "| epoch  91 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   721.18 | bpc    9.494\n",
      "| epoch  91 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   714.28 | bpc    9.480\n",
      "| epoch  91 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.56 | ppl   704.33 | bpc    9.460\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 19.80s | valid loss  6.52 | valid ppl   681.75 | bpc    9.413\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524811 --> 6.524659).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  92 |    50/  414 batches | lr 0.0001 | ms/batch 33.83 | loss  6.72 | ppl   825.17 | bpc    9.689\n",
      "| epoch  92 |   100/  414 batches | lr 0.0001 | ms/batch 34.33 | loss  6.58 | ppl   721.34 | bpc    9.495\n",
      "| epoch  92 |   150/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.54 | ppl   693.36 | bpc    9.437\n",
      "| epoch  92 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   705.89 | bpc    9.463\n",
      "| epoch  92 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   725.98 | bpc    9.504\n",
      "| epoch  92 |   300/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.58 | ppl   722.21 | bpc    9.496\n",
      "| epoch  92 |   350/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.57 | ppl   715.00 | bpc    9.482\n",
      "| epoch  92 |   400/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.56 | ppl   704.43 | bpc    9.460\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 19.69s | valid loss  6.52 | valid ppl   681.63 | bpc    9.413\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524659 --> 6.524494).  Saving model ...\n",
      "| epoch  93 |    50/  414 batches | lr 0.0001 | ms/batch 33.01 | loss  6.71 | ppl   824.43 | bpc    9.687\n",
      "| epoch  93 |   100/  414 batches | lr 0.0001 | ms/batch 34.17 | loss  6.58 | ppl   719.52 | bpc    9.491\n",
      "| epoch  93 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.54 | ppl   693.73 | bpc    9.438\n",
      "| epoch  93 |   200/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   704.98 | bpc    9.461\n",
      "| epoch  93 |   250/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.59 | ppl   726.54 | bpc    9.505\n",
      "| epoch  93 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   720.50 | bpc    9.493\n",
      "| epoch  93 |   350/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.57 | ppl   714.62 | bpc    9.481\n",
      "| epoch  93 |   400/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   703.90 | bpc    9.459\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 19.64s | valid loss  6.52 | valid ppl   681.52 | bpc    9.413\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524494 --> 6.524325).  Saving model ...\n",
      "| epoch  94 |    50/  414 batches | lr 0.0001 | ms/batch 35.49 | loss  6.71 | ppl   824.04 | bpc    9.687\n",
      "| epoch  94 |   100/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   720.54 | bpc    9.493\n",
      "| epoch  94 |   150/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.54 | ppl   693.11 | bpc    9.437\n",
      "| epoch  94 |   200/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.56 | ppl   704.44 | bpc    9.460\n",
      "| epoch  94 |   250/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.59 | ppl   727.04 | bpc    9.506\n",
      "| epoch  94 |   300/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.58 | ppl   720.24 | bpc    9.492\n",
      "| epoch  94 |   350/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.57 | ppl   713.95 | bpc    9.480\n",
      "| epoch  94 |   400/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   704.42 | bpc    9.460\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 19.80s | valid loss  6.52 | valid ppl   681.44 | bpc    9.412\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524325 --> 6.524208).  Saving model ...\n",
      "| epoch  95 |    50/  414 batches | lr 0.0001 | ms/batch 32.37 | loss  6.71 | ppl   824.23 | bpc    9.687\n",
      "| epoch  95 |   100/  414 batches | lr 0.0001 | ms/batch 33.08 | loss  6.58 | ppl   720.32 | bpc    9.492\n",
      "| epoch  95 |   150/  414 batches | lr 0.0001 | ms/batch 34.14 | loss  6.54 | ppl   692.86 | bpc    9.436\n",
      "| epoch  95 |   200/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.56 | ppl   704.27 | bpc    9.460\n",
      "| epoch  95 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   726.00 | bpc    9.504\n",
      "| epoch  95 |   300/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.58 | ppl   721.06 | bpc    9.494\n",
      "| epoch  95 |   350/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.57 | ppl   713.60 | bpc    9.479\n",
      "| epoch  95 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   704.42 | bpc    9.460\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 19.53s | valid loss  6.52 | valid ppl   681.32 | bpc    9.412\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524208 --> 6.524030).  Saving model ...\n",
      "| epoch  96 |    50/  414 batches | lr 0.0001 | ms/batch 32.57 | loss  6.71 | ppl   822.75 | bpc    9.684\n",
      "| epoch  96 |   100/  414 batches | lr 0.0001 | ms/batch 33.66 | loss  6.58 | ppl   719.83 | bpc    9.492\n",
      "| epoch  96 |   150/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.54 | ppl   693.12 | bpc    9.437\n",
      "| epoch  96 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   704.32 | bpc    9.460\n",
      "| epoch  96 |   250/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.59 | ppl   725.23 | bpc    9.502\n",
      "| epoch  96 |   300/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.58 | ppl   719.81 | bpc    9.491\n",
      "| epoch  96 |   350/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.57 | ppl   713.44 | bpc    9.479\n",
      "| epoch  96 |   400/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   703.03 | bpc    9.457\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 19.60s | valid loss  6.52 | valid ppl   681.24 | bpc    9.412\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.524030 --> 6.523913).  Saving model ...\n",
      "| epoch  97 |    50/  414 batches | lr 0.0001 | ms/batch 32.72 | loss  6.71 | ppl   822.72 | bpc    9.684\n",
      "| epoch  97 |   100/  414 batches | lr 0.0001 | ms/batch 32.63 | loss  6.58 | ppl   719.58 | bpc    9.491\n",
      "| epoch  97 |   150/  414 batches | lr 0.0001 | ms/batch 33.61 | loss  6.54 | ppl   691.79 | bpc    9.434\n",
      "| epoch  97 |   200/  414 batches | lr 0.0001 | ms/batch 34.88 | loss  6.56 | ppl   704.72 | bpc    9.461\n",
      "| epoch  97 |   250/  414 batches | lr 0.0001 | ms/batch 34.92 | loss  6.59 | ppl   725.10 | bpc    9.502\n",
      "| epoch  97 |   300/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.58 | ppl   719.43 | bpc    9.491\n",
      "| epoch  97 |   350/  414 batches | lr 0.0001 | ms/batch 34.89 | loss  6.57 | ppl   714.79 | bpc    9.481\n",
      "| epoch  97 |   400/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.56 | ppl   702.88 | bpc    9.457\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 19.50s | valid loss  6.52 | valid ppl   681.10 | bpc    9.412\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.523913 --> 6.523712).  Saving model ...\n",
      "| epoch  98 |    50/  414 batches | lr 0.0001 | ms/batch 35.62 | loss  6.71 | ppl   823.02 | bpc    9.685\n",
      "| epoch  98 |   100/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.58 | ppl   718.50 | bpc    9.489\n",
      "| epoch  98 |   150/  414 batches | lr 0.0001 | ms/batch 34.94 | loss  6.54 | ppl   691.68 | bpc    9.434\n",
      "| epoch  98 |   200/  414 batches | lr 0.0001 | ms/batch 34.92 | loss  6.56 | ppl   703.17 | bpc    9.458\n",
      "| epoch  98 |   250/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.59 | ppl   724.89 | bpc    9.502\n",
      "| epoch  98 |   300/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.58 | ppl   720.62 | bpc    9.493\n",
      "| epoch  98 |   350/  414 batches | lr 0.0001 | ms/batch 34.91 | loss  6.57 | ppl   714.59 | bpc    9.481\n",
      "| epoch  98 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.56 | ppl   703.12 | bpc    9.458\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 19.82s | valid loss  6.52 | valid ppl   680.99 | bpc    9.411\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.523712 --> 6.523552).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  99 |    50/  414 batches | lr 0.0001 | ms/batch 32.56 | loss  6.71 | ppl   823.44 | bpc    9.686\n",
      "| epoch  99 |   100/  414 batches | lr 0.0001 | ms/batch 32.85 | loss  6.58 | ppl   718.91 | bpc    9.490\n",
      "| epoch  99 |   150/  414 batches | lr 0.0001 | ms/batch 32.85 | loss  6.54 | ppl   692.81 | bpc    9.436\n",
      "| epoch  99 |   200/  414 batches | lr 0.0001 | ms/batch 34.74 | loss  6.56 | ppl   703.59 | bpc    9.459\n",
      "| epoch  99 |   250/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.59 | ppl   726.07 | bpc    9.504\n",
      "| epoch  99 |   300/  414 batches | lr 0.0001 | ms/batch 34.83 | loss  6.58 | ppl   719.25 | bpc    9.490\n",
      "| epoch  99 |   350/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.57 | ppl   713.36 | bpc    9.478\n",
      "| epoch  99 |   400/  414 batches | lr 0.0001 | ms/batch 34.87 | loss  6.55 | ppl   702.67 | bpc    9.457\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time: 19.44s | valid loss  6.52 | valid ppl   680.88 | bpc    9.411\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.523552 --> 6.523383).  Saving model ...\n",
      "| epoch 100 |    50/  414 batches | lr 0.0001 | ms/batch 33.43 | loss  6.71 | ppl   822.58 | bpc    9.684\n",
      "| epoch 100 |   100/  414 batches | lr 0.0001 | ms/batch 34.63 | loss  6.58 | ppl   718.61 | bpc    9.489\n",
      "| epoch 100 |   150/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.54 | ppl   691.51 | bpc    9.434\n",
      "| epoch 100 |   200/  414 batches | lr 0.0001 | ms/batch 34.90 | loss  6.56 | ppl   703.31 | bpc    9.458\n",
      "| epoch 100 |   250/  414 batches | lr 0.0001 | ms/batch 34.85 | loss  6.59 | ppl   724.95 | bpc    9.502\n",
      "| epoch 100 |   300/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.58 | ppl   718.99 | bpc    9.490\n",
      "| epoch 100 |   350/  414 batches | lr 0.0001 | ms/batch 34.84 | loss  6.57 | ppl   712.75 | bpc    9.477\n",
      "| epoch 100 |   400/  414 batches | lr 0.0001 | ms/batch 34.86 | loss  6.55 | ppl   702.38 | bpc    9.456\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time: 19.68s | valid loss  6.52 | valid ppl   680.76 | bpc    9.411\n",
      "-----------------------------------------------------------------------------------------\n",
      "Validation loss decreased (6.523383 --> 6.523205).  Saving model ...\n",
      "=========================================================================================\n",
      "| End of training | test loss  6.47 | test ppl   643.01 | bpc    9.329\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = lr\n",
    "best_val_loss = None\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.99)\n",
    "opts = 'SGD'\n",
    "\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "epochs = 100\n",
    "early_stopping = EarlyStopping(patience=25, verbose=True)\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        train_loss = evaluate(train_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f} | bpc {:8.3f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                           val_loss, math.exp(val_loss), val_loss / math.log(2)))\n",
    "        val_losses.append(val_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        print('-' * 89)\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "    test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_losses = [i.item() for i in val_losses]\n",
    "training_losses = [i.item() for i in train_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "XPrFSXzRJ_2W"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(range(100), training_losses, c='#00ff00')\n",
    "plt.plot(range(100), validation_losses)\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 3.0)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.title('Loss')\n",
    "plt.savefig('Word_None'+'.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXJ4DpbGJ__i"
   },
   "source": [
    "**Word Noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHhzL3OtKAGG",
    "outputId": "ceb69048-3f7c-4c73-e234-79c3d88d0161"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      "  (encoder): Embedding(10000, 256)\n",
      "  (rnn): LSTM(256, 1000, dropout=0.5)\n",
      "  (decoder): Linear(in_features=1000, out_features=10000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "interval = 50 # interval to report\n",
    "ntokens = len(corpus.dictionary) # 10000\n",
    "model = RNNModel(ntokens, emsize, nhid, nlayers, dropout)\n",
    "save = '/content/output/model_test_word_noise.pt'\n",
    "checkpoint = \"/content/output/model_test_word_none.pt\"\n",
    "\n",
    "# Load checkpoint\n",
    "if checkpoint != '':\n",
    "    model = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "\n",
    "print(model)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBCZxgDQKAGG",
    "outputId": "17bdf323-d010-40d5-a097-50b463caa42e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:161: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  414 batches | lr 0.0001 | ms/batch 136.33 | loss  7.64 | ppl  2083.54 | bpc   11.025\n",
      "| epoch   1 |   100/  414 batches | lr 0.0001 | ms/batch 133.73 | loss  7.01 | ppl  1106.82 | bpc   10.112\n",
      "| epoch   1 |   150/  414 batches | lr 0.0001 | ms/batch 133.12 | loss  6.90 | ppl   997.01 | bpc    9.961\n",
      "| epoch   1 |   200/  414 batches | lr 0.0001 | ms/batch 133.57 | loss  6.89 | ppl   983.50 | bpc    9.942\n",
      "| epoch   1 |   250/  414 batches | lr 0.0001 | ms/batch 133.09 | loss  6.90 | ppl   988.29 | bpc    9.949\n",
      "| epoch   1 |   300/  414 batches | lr 0.0001 | ms/batch 132.93 | loss  6.87 | ppl   959.97 | bpc    9.907\n",
      "| epoch   1 |   350/  414 batches | lr 0.0001 | ms/batch 133.00 | loss  6.85 | ppl   939.19 | bpc    9.875\n",
      "| epoch   1 |   400/  414 batches | lr 0.0001 | ms/batch 132.95 | loss  6.82 | ppl   915.84 | bpc    9.839\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 57.63s | valid loss  6.74 | valid ppl   843.24 | bpc    9.720\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |    50/  414 batches | lr 0.0001 | ms/batch 135.47 | loss  7.86 | ppl  2598.58 | bpc   11.344\n",
      "| epoch   2 |   100/  414 batches | lr 0.0001 | ms/batch 133.12 | loss  7.09 | ppl  1202.93 | bpc   10.232\n",
      "| epoch   2 |   150/  414 batches | lr 0.0001 | ms/batch 133.36 | loss  6.91 | ppl  1001.17 | bpc    9.967\n",
      "| epoch   2 |   200/  414 batches | lr 0.0001 | ms/batch 132.20 | loss  6.90 | ppl   987.50 | bpc    9.948\n",
      "| epoch   2 |   250/  414 batches | lr 0.0001 | ms/batch 132.43 | loss  6.90 | ppl   992.66 | bpc    9.955\n",
      "| epoch   2 |   300/  414 batches | lr 0.0001 | ms/batch 132.63 | loss  6.87 | ppl   959.61 | bpc    9.906\n",
      "| epoch   2 |   350/  414 batches | lr 0.0001 | ms/batch 132.42 | loss  6.85 | ppl   940.73 | bpc    9.878\n",
      "| epoch   2 |   400/  414 batches | lr 0.0001 | ms/batch 132.58 | loss  6.82 | ppl   915.75 | bpc    9.839\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 57.35s | valid loss  6.73 | valid ppl   836.64 | bpc    9.708\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |    50/  414 batches | lr 0.0001 | ms/batch 135.53 | loss  7.68 | ppl  2166.94 | bpc   11.081\n",
      "| epoch   3 |   100/  414 batches | lr 0.0001 | ms/batch 133.42 | loss  7.02 | ppl  1117.49 | bpc   10.126\n",
      "| epoch   3 |   150/  414 batches | lr 0.0001 | ms/batch 133.11 | loss  6.90 | ppl   991.58 | bpc    9.954\n",
      "| epoch   3 |   200/  414 batches | lr 0.0001 | ms/batch 132.73 | loss  6.88 | ppl   973.43 | bpc    9.927\n",
      "| epoch   3 |   250/  414 batches | lr 0.0001 | ms/batch 132.90 | loss  6.88 | ppl   976.81 | bpc    9.932\n",
      "| epoch   3 |   300/  414 batches | lr 0.0001 | ms/batch 132.70 | loss  6.86 | ppl   955.61 | bpc    9.900\n",
      "| epoch   3 |   350/  414 batches | lr 0.0001 | ms/batch 132.81 | loss  6.84 | ppl   934.81 | bpc    9.869\n",
      "| epoch   3 |   400/  414 batches | lr 0.0001 | ms/batch 132.78 | loss  6.81 | ppl   908.76 | bpc    9.828\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 57.46s | valid loss  6.71 | valid ppl   823.80 | bpc    9.686\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |    50/  414 batches | lr 0.0001 | ms/batch 135.17 | loss  7.86 | ppl  2603.80 | bpc   11.346\n",
      "| epoch   4 |   100/  414 batches | lr 0.0001 | ms/batch 132.52 | loss  7.11 | ppl  1223.80 | bpc   10.257\n",
      "| epoch   4 |   150/  414 batches | lr 0.0001 | ms/batch 132.12 | loss  6.89 | ppl   984.75 | bpc    9.944\n",
      "| epoch   4 |   200/  414 batches | lr 0.0001 | ms/batch 132.96 | loss  6.88 | ppl   973.70 | bpc    9.927\n",
      "| epoch   4 |   250/  414 batches | lr 0.0001 | ms/batch 132.65 | loss  6.88 | ppl   969.34 | bpc    9.921\n",
      "| epoch   4 |   300/  414 batches | lr 0.0001 | ms/batch 132.25 | loss  6.85 | ppl   944.49 | bpc    9.883\n",
      "| epoch   4 |   350/  414 batches | lr 0.0001 | ms/batch 132.45 | loss  6.83 | ppl   922.03 | bpc    9.849\n",
      "| epoch   4 |   400/  414 batches | lr 0.0001 | ms/batch 132.60 | loss  6.80 | ppl   901.10 | bpc    9.816\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 57.28s | valid loss  6.71 | valid ppl   820.59 | bpc    9.681\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |    50/  414 batches | lr 0.0001 | ms/batch 135.38 | loss  7.15 | ppl  1267.95 | bpc   10.308\n",
      "| epoch   5 |   100/  414 batches | lr 0.0001 | ms/batch 132.63 | loss  6.89 | ppl   986.74 | bpc    9.947\n",
      "| epoch   5 |   150/  414 batches | lr 0.0001 | ms/batch 132.70 | loss  6.83 | ppl   926.46 | bpc    9.856\n",
      "| epoch   5 |   200/  414 batches | lr 0.0001 | ms/batch 132.87 | loss  6.83 | ppl   923.10 | bpc    9.850\n",
      "| epoch   5 |   250/  414 batches | lr 0.0001 | ms/batch 132.78 | loss  6.85 | ppl   940.08 | bpc    9.877\n",
      "| epoch   5 |   300/  414 batches | lr 0.0001 | ms/batch 133.27 | loss  6.82 | ppl   919.75 | bpc    9.845\n",
      "| epoch   5 |   350/  414 batches | lr 0.0001 | ms/batch 133.00 | loss  6.80 | ppl   900.33 | bpc    9.814\n",
      "| epoch   5 |   400/  414 batches | lr 0.0001 | ms/batch 132.89 | loss  6.78 | ppl   880.91 | bpc    9.783\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 57.46s | valid loss  6.69 | valid ppl   803.92 | bpc    9.651\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |    50/  414 batches | lr 0.0001 | ms/batch 135.72 | loss  7.28 | ppl  1452.15 | bpc   10.504\n",
      "| epoch   6 |   100/  414 batches | lr 0.0001 | ms/batch 132.66 | loss  6.92 | ppl  1014.13 | bpc    9.986\n",
      "| epoch   6 |   150/  414 batches | lr 0.0001 | ms/batch 132.53 | loss  6.83 | ppl   928.68 | bpc    9.859\n",
      "| epoch   6 |   200/  414 batches | lr 0.0001 | ms/batch 132.53 | loss  6.83 | ppl   922.41 | bpc    9.849\n",
      "| epoch   6 |   250/  414 batches | lr 0.0001 | ms/batch 132.64 | loss  6.84 | ppl   938.25 | bpc    9.874\n",
      "| epoch   6 |   300/  414 batches | lr 0.0001 | ms/batch 132.49 | loss  6.83 | ppl   922.89 | bpc    9.850\n",
      "| epoch   6 |   350/  414 batches | lr 0.0001 | ms/batch 132.46 | loss  6.80 | ppl   898.54 | bpc    9.811\n",
      "| epoch   6 |   400/  414 batches | lr 0.0001 | ms/batch 132.75 | loss  6.78 | ppl   879.91 | bpc    9.781\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 57.37s | valid loss  6.68 | valid ppl   796.60 | bpc    9.638\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |    50/  414 batches | lr 0.0001 | ms/batch 135.49 | loss  7.24 | ppl  1396.90 | bpc   10.448\n",
      "| epoch   7 |   100/  414 batches | lr 0.0001 | ms/batch 133.12 | loss  6.94 | ppl  1028.10 | bpc   10.006\n",
      "| epoch   7 |   150/  414 batches | lr 0.0001 | ms/batch 132.68 | loss  6.85 | ppl   944.12 | bpc    9.883\n",
      "| epoch   7 |   200/  414 batches | lr 0.0001 | ms/batch 132.93 | loss  6.85 | ppl   940.55 | bpc    9.877\n",
      "| epoch   7 |   250/  414 batches | lr 0.0001 | ms/batch 132.92 | loss  6.86 | ppl   949.36 | bpc    9.891\n",
      "| epoch   7 |   300/  414 batches | lr 0.0001 | ms/batch 133.00 | loss  6.83 | ppl   926.49 | bpc    9.856\n",
      "| epoch   7 |   350/  414 batches | lr 0.0001 | ms/batch 132.67 | loss  6.81 | ppl   905.79 | bpc    9.823\n",
      "| epoch   7 |   400/  414 batches | lr 0.0001 | ms/batch 132.61 | loss  6.79 | ppl   886.04 | bpc    9.791\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 57.46s | valid loss  6.69 | valid ppl   801.88 | bpc    9.647\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |    50/  414 batches | lr 0.0000 | ms/batch 135.43 | loss  7.45 | ppl  1725.74 | bpc   10.753\n",
      "| epoch   8 |   100/  414 batches | lr 0.0000 | ms/batch 132.98 | loss  7.19 | ppl  1321.32 | bpc   10.368\n",
      "| epoch   8 |   150/  414 batches | lr 0.0000 | ms/batch 132.80 | loss  6.98 | ppl  1080.15 | bpc   10.077\n",
      "| epoch   8 |   200/  414 batches | lr 0.0000 | ms/batch 133.00 | loss  6.90 | ppl   991.83 | bpc    9.954\n",
      "| epoch   8 |   250/  414 batches | lr 0.0000 | ms/batch 132.71 | loss  6.89 | ppl   981.30 | bpc    9.939\n",
      "| epoch   8 |   300/  414 batches | lr 0.0000 | ms/batch 133.03 | loss  6.87 | ppl   964.38 | bpc    9.913\n",
      "| epoch   8 |   350/  414 batches | lr 0.0000 | ms/batch 132.30 | loss  6.84 | ppl   938.44 | bpc    9.874\n",
      "| epoch   8 |   400/  414 batches | lr 0.0000 | ms/batch 132.71 | loss  6.82 | ppl   916.50 | bpc    9.840\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 57.42s | valid loss  6.72 | valid ppl   830.98 | bpc    9.699\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |    50/  414 batches | lr 0.0000 | ms/batch 135.00 | loss  7.72 | ppl  2259.61 | bpc   11.142\n",
      "| epoch   9 |   100/  414 batches | lr 0.0000 | ms/batch 133.07 | loss  7.58 | ppl  1965.07 | bpc   10.940\n",
      "| epoch   9 |   150/  414 batches | lr 0.0000 | ms/batch 132.98 | loss  7.47 | ppl  1754.39 | bpc   10.777\n",
      "| epoch   9 |   200/  414 batches | lr 0.0000 | ms/batch 132.76 | loss  7.42 | ppl  1663.25 | bpc   10.700\n",
      "| epoch   9 |   250/  414 batches | lr 0.0000 | ms/batch 132.61 | loss  7.34 | ppl  1542.56 | bpc   10.591\n",
      "| epoch   9 |   300/  414 batches | lr 0.0000 | ms/batch 133.10 | loss  7.24 | ppl  1398.19 | bpc   10.449\n",
      "| epoch   9 |   350/  414 batches | lr 0.0000 | ms/batch 132.29 | loss  7.19 | ppl  1329.77 | bpc   10.377\n",
      "| epoch   9 |   400/  414 batches | lr 0.0000 | ms/batch 133.01 | loss  7.12 | ppl  1241.02 | bpc   10.277\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 57.41s | valid loss  7.00 | valid ppl  1091.73 | bpc   10.092\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |    50/  414 batches | lr 0.0000 | ms/batch 134.97 | loss  7.98 | ppl  2909.06 | bpc   11.506\n",
      "| epoch  10 |   100/  414 batches | lr 0.0000 | ms/batch 132.85 | loss  7.84 | ppl  2534.01 | bpc   11.307\n",
      "| epoch  10 |   150/  414 batches | lr 0.0000 | ms/batch 132.76 | loss  7.75 | ppl  2323.90 | bpc   11.182\n",
      "| epoch  10 |   200/  414 batches | lr 0.0000 | ms/batch 133.35 | loss  7.76 | ppl  2346.59 | bpc   11.196\n",
      "| epoch  10 |   250/  414 batches | lr 0.0000 | ms/batch 132.83 | loss  7.71 | ppl  2237.15 | bpc   11.127\n",
      "| epoch  10 |   300/  414 batches | lr 0.0000 | ms/batch 132.53 | loss  7.68 | ppl  2157.90 | bpc   11.075\n",
      "| epoch  10 |   350/  414 batches | lr 0.0000 | ms/batch 132.87 | loss  7.64 | ppl  2082.60 | bpc   11.024\n",
      "| epoch  10 |   400/  414 batches | lr 0.0000 | ms/batch 132.84 | loss  7.61 | ppl  2020.05 | bpc   10.980\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 57.43s | valid loss  7.47 | valid ppl  1759.97 | bpc   10.781\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |    50/  414 batches | lr 0.0000 | ms/batch 135.70 | loss  8.47 | ppl  4781.33 | bpc   12.223\n",
      "| epoch  11 |   100/  414 batches | lr 0.0000 | ms/batch 133.24 | loss  8.31 | ppl  4050.53 | bpc   11.984\n",
      "| epoch  11 |   150/  414 batches | lr 0.0000 | ms/batch 132.94 | loss  8.32 | ppl  4118.72 | bpc   12.008\n",
      "| epoch  11 |   200/  414 batches | lr 0.0000 | ms/batch 133.44 | loss  8.31 | ppl  4071.61 | bpc   11.991\n",
      "| epoch  11 |   250/  414 batches | lr 0.0000 | ms/batch 132.58 | loss  8.33 | ppl  4159.01 | bpc   12.022\n",
      "| epoch  11 |   300/  414 batches | lr 0.0000 | ms/batch 132.92 | loss  8.33 | ppl  4136.23 | bpc   12.014\n",
      "| epoch  11 |   350/  414 batches | lr 0.0000 | ms/batch 132.92 | loss  8.31 | ppl  4068.13 | bpc   11.990\n",
      "| epoch  11 |   400/  414 batches | lr 0.0000 | ms/batch 133.14 | loss  8.31 | ppl  4049.40 | bpc   11.983\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 57.50s | valid loss  8.20 | valid ppl  3624.29 | bpc   11.823\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |    50/  414 batches | lr 0.0000 | ms/batch 135.36 | loss  8.59 | ppl  5368.18 | bpc   12.390\n",
      "| epoch  12 |   100/  414 batches | lr 0.0000 | ms/batch 132.95 | loss  8.43 | ppl  4592.77 | bpc   12.165\n",
      "| epoch  12 |   150/  414 batches | lr 0.0000 | ms/batch 133.09 | loss  8.43 | ppl  4582.03 | bpc   12.162\n",
      "| epoch  12 |   200/  414 batches | lr 0.0000 | ms/batch 133.03 | loss  8.45 | ppl  4682.91 | bpc   12.193\n",
      "| epoch  12 |   250/  414 batches | lr 0.0000 | ms/batch 132.39 | loss  8.44 | ppl  4639.73 | bpc   12.180\n",
      "| epoch  12 |   300/  414 batches | lr 0.0000 | ms/batch 132.76 | loss  8.44 | ppl  4609.55 | bpc   12.170\n",
      "| epoch  12 |   350/  414 batches | lr 0.0000 | ms/batch 133.03 | loss  8.44 | ppl  4637.88 | bpc   12.179\n",
      "| epoch  12 |   400/  414 batches | lr 0.0000 | ms/batch 132.75 | loss  8.43 | ppl  4599.65 | bpc   12.167\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 57.43s | valid loss  8.36 | valid ppl  4272.48 | bpc   12.061\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |    50/  414 batches | lr 0.0000 | ms/batch 135.46 | loss  8.75 | ppl  6328.25 | bpc   12.628\n",
      "| epoch  13 |   100/  414 batches | lr 0.0000 | ms/batch 133.53 | loss  8.59 | ppl  5393.03 | bpc   12.397\n",
      "| epoch  13 |   150/  414 batches | lr 0.0000 | ms/batch 132.76 | loss  8.58 | ppl  5331.61 | bpc   12.380\n",
      "| epoch  13 |   200/  414 batches | lr 0.0000 | ms/batch 133.14 | loss  8.59 | ppl  5359.34 | bpc   12.388\n",
      "| epoch  13 |   250/  414 batches | lr 0.0000 | ms/batch 132.38 | loss  8.59 | ppl  5403.33 | bpc   12.400\n",
      "| epoch  13 |   300/  414 batches | lr 0.0000 | ms/batch 133.17 | loss  8.59 | ppl  5386.58 | bpc   12.395\n",
      "| epoch  13 |   350/  414 batches | lr 0.0000 | ms/batch 133.16 | loss  8.58 | ppl  5305.69 | bpc   12.373\n",
      "| epoch  13 |   400/  414 batches | lr 0.0000 | ms/batch 132.91 | loss  8.58 | ppl  5338.35 | bpc   12.382\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 57.50s | valid loss  8.51 | valid ppl  4947.50 | bpc   12.272\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |    50/  414 batches | lr 0.0000 | ms/batch 135.24 | loss  8.81 | ppl  6702.72 | bpc   12.711\n",
      "| epoch  14 |   100/  414 batches | lr 0.0000 | ms/batch 133.02 | loss  8.66 | ppl  5781.25 | bpc   12.497\n",
      "| epoch  14 |   150/  414 batches | lr 0.0000 | ms/batch 133.27 | loss  8.65 | ppl  5735.82 | bpc   12.486\n",
      "| epoch  14 |   200/  414 batches | lr 0.0000 | ms/batch 132.90 | loss  8.65 | ppl  5735.62 | bpc   12.486\n",
      "| epoch  14 |   250/  414 batches | lr 0.0000 | ms/batch 132.94 | loss  8.67 | ppl  5803.61 | bpc   12.503\n",
      "| epoch  14 |   300/  414 batches | lr 0.0000 | ms/batch 132.76 | loss  8.65 | ppl  5702.28 | bpc   12.477\n",
      "| epoch  14 |   350/  414 batches | lr 0.0000 | ms/batch 132.87 | loss  8.65 | ppl  5730.26 | bpc   12.484\n",
      "| epoch  14 |   400/  414 batches | lr 0.0000 | ms/batch 132.82 | loss  8.65 | ppl  5716.19 | bpc   12.481\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 57.48s | valid loss  8.57 | valid ppl  5289.92 | bpc   12.369\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |    50/  414 batches | lr 0.0000 | ms/batch 135.41 | loss  8.93 | ppl  7576.26 | bpc   12.887\n",
      "| epoch  15 |   100/  414 batches | lr 0.0000 | ms/batch 132.97 | loss  8.77 | ppl  6427.41 | bpc   12.650\n",
      "| epoch  15 |   150/  414 batches | lr 0.0000 | ms/batch 133.13 | loss  8.77 | ppl  6411.90 | bpc   12.647\n",
      "| epoch  15 |   200/  414 batches | lr 0.0000 | ms/batch 133.19 | loss  8.76 | ppl  6387.66 | bpc   12.641\n",
      "| epoch  15 |   250/  414 batches | lr 0.0000 | ms/batch 132.86 | loss  8.78 | ppl  6482.47 | bpc   12.662\n",
      "| epoch  15 |   300/  414 batches | lr 0.0000 | ms/batch 132.96 | loss  8.77 | ppl  6414.05 | bpc   12.647\n",
      "| epoch  15 |   350/  414 batches | lr 0.0000 | ms/batch 132.66 | loss  8.77 | ppl  6423.03 | bpc   12.649\n",
      "| epoch  15 |   400/  414 batches | lr 0.0000 | ms/batch 133.13 | loss  8.77 | ppl  6437.00 | bpc   12.652\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 57.49s | valid loss  8.68 | valid ppl  5909.31 | bpc   12.529\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |    50/  414 batches | lr 0.0000 | ms/batch 135.31 | loss  8.95 | ppl  7717.92 | bpc   12.914\n",
      "| epoch  16 |   100/  414 batches | lr 0.0000 | ms/batch 133.16 | loss  8.78 | ppl  6499.04 | bpc   12.666\n",
      "| epoch  16 |   150/  414 batches | lr 0.0000 | ms/batch 132.90 | loss  8.77 | ppl  6434.48 | bpc   12.652\n",
      "| epoch  16 |   200/  414 batches | lr 0.0000 | ms/batch 132.90 | loss  8.78 | ppl  6496.36 | bpc   12.665\n",
      "| epoch  16 |   250/  414 batches | lr 0.0000 | ms/batch 133.13 | loss  8.78 | ppl  6513.61 | bpc   12.669\n",
      "| epoch  16 |   300/  414 batches | lr 0.0000 | ms/batch 132.64 | loss  8.78 | ppl  6476.97 | bpc   12.661\n",
      "| epoch  16 |   350/  414 batches | lr 0.0000 | ms/batch 132.90 | loss  8.79 | ppl  6549.62 | bpc   12.677\n",
      "| epoch  16 |   400/  414 batches | lr 0.0000 | ms/batch 132.75 | loss  8.78 | ppl  6490.87 | bpc   12.664\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 57.44s | valid loss  8.69 | valid ppl  5939.56 | bpc   12.536\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |    50/  414 batches | lr 0.0000 | ms/batch 135.50 | loss  8.99 | ppl  7984.47 | bpc   12.963\n",
      "| epoch  17 |   100/  414 batches | lr 0.0000 | ms/batch 133.14 | loss  8.82 | ppl  6769.81 | bpc   12.725\n",
      "| epoch  17 |   150/  414 batches | lr 0.0000 | ms/batch 132.39 | loss  8.81 | ppl  6668.00 | bpc   12.703\n",
      "| epoch  17 |   200/  414 batches | lr 0.0000 | ms/batch 133.23 | loss  8.81 | ppl  6679.22 | bpc   12.705\n",
      "| epoch  17 |   250/  414 batches | lr 0.0000 | ms/batch 132.87 | loss  8.81 | ppl  6718.24 | bpc   12.714\n",
      "| epoch  17 |   300/  414 batches | lr 0.0000 | ms/batch 133.06 | loss  8.81 | ppl  6711.21 | bpc   12.712\n",
      "| epoch  17 |   350/  414 batches | lr 0.0000 | ms/batch 132.68 | loss  8.81 | ppl  6694.90 | bpc   12.709\n",
      "| epoch  17 |   400/  414 batches | lr 0.0000 | ms/batch 132.96 | loss  8.81 | ppl  6707.64 | bpc   12.712\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 57.48s | valid loss  8.73 | valid ppl  6195.91 | bpc   12.597\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |    50/  414 batches | lr 0.0000 | ms/batch 135.47 | loss  9.04 | ppl  8446.24 | bpc   13.044\n",
      "| epoch  18 |   100/  414 batches | lr 0.0000 | ms/batch 132.39 | loss  8.87 | ppl  7123.04 | bpc   12.798\n",
      "| epoch  18 |   150/  414 batches | lr 0.0000 | ms/batch 132.89 | loss  8.86 | ppl  7050.09 | bpc   12.783\n",
      "| epoch  18 |   200/  414 batches | lr 0.0000 | ms/batch 133.29 | loss  8.87 | ppl  7131.89 | bpc   12.800\n",
      "| epoch  18 |   250/  414 batches | lr 0.0000 | ms/batch 132.69 | loss  8.87 | ppl  7102.13 | bpc   12.794\n",
      "| epoch  18 |   300/  414 batches | lr 0.0000 | ms/batch 133.20 | loss  8.87 | ppl  7144.38 | bpc   12.803\n",
      "| epoch  18 |   350/  414 batches | lr 0.0000 | ms/batch 132.33 | loss  8.87 | ppl  7128.05 | bpc   12.799\n",
      "| epoch  18 |   400/  414 batches | lr 0.0000 | ms/batch 132.55 | loss  8.87 | ppl  7084.26 | bpc   12.790\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 57.40s | valid loss  8.79 | valid ppl  6582.09 | bpc   12.684\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |    50/  414 batches | lr 0.0000 | ms/batch 134.91 | loss  9.06 | ppl  8633.11 | bpc   13.076\n",
      "| epoch  19 |   100/  414 batches | lr 0.0000 | ms/batch 133.03 | loss  8.89 | ppl  7262.32 | bpc   12.826\n",
      "| epoch  19 |   150/  414 batches | lr 0.0000 | ms/batch 133.06 | loss  8.89 | ppl  7280.53 | bpc   12.830\n",
      "| epoch  19 |   200/  414 batches | lr 0.0000 | ms/batch 133.26 | loss  8.90 | ppl  7304.78 | bpc   12.835\n",
      "| epoch  19 |   250/  414 batches | lr 0.0000 | ms/batch 133.14 | loss  8.90 | ppl  7299.00 | bpc   12.833\n",
      "| epoch  19 |   300/  414 batches | lr 0.0000 | ms/batch 133.03 | loss  8.89 | ppl  7288.84 | bpc   12.831\n",
      "| epoch  19 |   350/  414 batches | lr 0.0000 | ms/batch 133.17 | loss  8.90 | ppl  7308.15 | bpc   12.835\n",
      "| epoch  19 |   400/  414 batches | lr 0.0000 | ms/batch 132.97 | loss  8.90 | ppl  7302.70 | bpc   12.834\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 57.49s | valid loss  8.81 | valid ppl  6721.16 | bpc   12.714\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |    50/  414 batches | lr 0.0000 | ms/batch 135.33 | loss  9.08 | ppl  8798.06 | bpc   13.103\n",
      "| epoch  20 |   100/  414 batches | lr 0.0000 | ms/batch 132.70 | loss  8.90 | ppl  7351.18 | bpc   12.844\n",
      "| epoch  20 |   150/  414 batches | lr 0.0000 | ms/batch 132.64 | loss  8.90 | ppl  7351.01 | bpc   12.844\n",
      "| epoch  20 |   200/  414 batches | lr 0.0000 | ms/batch 132.67 | loss  8.91 | ppl  7390.77 | bpc   12.852\n",
      "| epoch  20 |   250/  414 batches | lr 0.0000 | ms/batch 133.07 | loss  8.91 | ppl  7398.61 | bpc   12.853\n",
      "| epoch  20 |   300/  414 batches | lr 0.0000 | ms/batch 132.65 | loss  8.90 | ppl  7354.51 | bpc   12.844\n",
      "| epoch  20 |   350/  414 batches | lr 0.0000 | ms/batch 133.44 | loss  8.91 | ppl  7397.92 | bpc   12.853\n",
      "| epoch  20 |   400/  414 batches | lr 0.0000 | ms/batch 132.87 | loss  8.90 | ppl  7349.93 | bpc   12.844\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 57.45s | valid loss  8.83 | valid ppl  6804.12 | bpc   12.732\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  21 |    50/  414 batches | lr 0.0000 | ms/batch 135.48 | loss  9.10 | ppl  8940.12 | bpc   13.126\n",
      "| epoch  21 |   100/  414 batches | lr 0.0000 | ms/batch 132.99 | loss  8.92 | ppl  7443.36 | bpc   12.862\n",
      "| epoch  21 |   150/  414 batches | lr 0.0000 | ms/batch 132.92 | loss  8.91 | ppl  7427.86 | bpc   12.859\n",
      "| epoch  21 |   200/  414 batches | lr 0.0000 | ms/batch 133.16 | loss  8.92 | ppl  7472.20 | bpc   12.867\n",
      "| epoch  21 |   250/  414 batches | lr 0.0000 | ms/batch 132.75 | loss  8.92 | ppl  7476.39 | bpc   12.868\n",
      "| epoch  21 |   300/  414 batches | lr 0.0000 | ms/batch 133.20 | loss  8.92 | ppl  7476.59 | bpc   12.868\n",
      "| epoch  21 |   350/  414 batches | lr 0.0000 | ms/batch 132.88 | loss  8.92 | ppl  7477.52 | bpc   12.868\n",
      "| epoch  21 |   400/  414 batches | lr 0.0000 | ms/batch 132.62 | loss  8.92 | ppl  7449.20 | bpc   12.863\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 57.48s | valid loss  8.84 | valid ppl  6877.12 | bpc   12.748\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |    50/  414 batches | lr 0.0000 | ms/batch 135.13 | loss  9.08 | ppl  8781.98 | bpc   13.100\n",
      "| epoch  22 |   100/  414 batches | lr 0.0000 | ms/batch 132.76 | loss  8.92 | ppl  7461.59 | bpc   12.865\n",
      "| epoch  22 |   150/  414 batches | lr 0.0000 | ms/batch 132.64 | loss  8.91 | ppl  7369.77 | bpc   12.847\n",
      "| epoch  22 |   200/  414 batches | lr 0.0000 | ms/batch 132.44 | loss  8.92 | ppl  7463.61 | bpc   12.866\n",
      "| epoch  22 |   250/  414 batches | lr 0.0000 | ms/batch 132.82 | loss  8.92 | ppl  7456.12 | bpc   12.864\n",
      "| epoch  22 |   300/  414 batches | lr 0.0000 | ms/batch 132.61 | loss  8.91 | ppl  7438.40 | bpc   12.861\n",
      "| epoch  22 |   350/  414 batches | lr 0.0000 | ms/batch 132.79 | loss  8.91 | ppl  7408.41 | bpc   12.855\n",
      "| epoch  22 |   400/  414 batches | lr 0.0000 | ms/batch 132.85 | loss  8.91 | ppl  7386.09 | bpc   12.851\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 57.38s | valid loss  8.83 | valid ppl  6825.62 | bpc   12.737\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |    50/  414 batches | lr 0.0000 | ms/batch 135.46 | loss  9.11 | ppl  9085.80 | bpc   13.149\n",
      "| epoch  23 |   100/  414 batches | lr 0.0000 | ms/batch 133.25 | loss  8.93 | ppl  7562.54 | bpc   12.885\n",
      "| epoch  23 |   150/  414 batches | lr 0.0000 | ms/batch 132.83 | loss  8.93 | ppl  7575.06 | bpc   12.887\n",
      "| epoch  23 |   200/  414 batches | lr 0.0000 | ms/batch 132.82 | loss  8.94 | ppl  7628.92 | bpc   12.897\n",
      "| epoch  23 |   250/  414 batches | lr 0.0000 | ms/batch 133.06 | loss  8.94 | ppl  7602.68 | bpc   12.892\n",
      "| epoch  23 |   300/  414 batches | lr 0.0000 | ms/batch 133.13 | loss  8.93 | ppl  7589.99 | bpc   12.890\n",
      "| epoch  23 |   350/  414 batches | lr 0.0000 | ms/batch 132.72 | loss  8.93 | ppl  7576.70 | bpc   12.887\n",
      "| epoch  23 |   400/  414 batches | lr 0.0000 | ms/batch 132.90 | loss  8.94 | ppl  7633.65 | bpc   12.898\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 57.48s | valid loss  8.86 | valid ppl  7024.35 | bpc   12.778\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |    50/  414 batches | lr 0.0000 | ms/batch 135.32 | loss  9.11 | ppl  9052.40 | bpc   13.144\n",
      "| epoch  24 |   100/  414 batches | lr 0.0000 | ms/batch 133.28 | loss  8.93 | ppl  7546.55 | bpc   12.882\n",
      "| epoch  24 |   150/  414 batches | lr 0.0000 | ms/batch 132.79 | loss  8.93 | ppl  7539.94 | bpc   12.880\n",
      "| epoch  24 |   200/  414 batches | lr 0.0000 | ms/batch 133.04 | loss  8.93 | ppl  7588.64 | bpc   12.890\n",
      "| epoch  24 |   250/  414 batches | lr 0.0000 | ms/batch 132.93 | loss  8.93 | ppl  7587.70 | bpc   12.889\n",
      "| epoch  24 |   300/  414 batches | lr 0.0000 | ms/batch 133.02 | loss  8.93 | ppl  7589.87 | bpc   12.890\n",
      "| epoch  24 |   350/  414 batches | lr 0.0000 | ms/batch 132.86 | loss  8.93 | ppl  7575.54 | bpc   12.887\n",
      "| epoch  24 |   400/  414 batches | lr 0.0000 | ms/batch 132.83 | loss  8.93 | ppl  7532.02 | bpc   12.879\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 57.48s | valid loss  8.86 | valid ppl  7025.67 | bpc   12.778\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |    50/  414 batches | lr 0.0000 | ms/batch 135.83 | loss  9.12 | ppl  9095.94 | bpc   13.151\n",
      "| epoch  25 |   100/  414 batches | lr 0.0000 | ms/batch 132.86 | loss  8.94 | ppl  7598.38 | bpc   12.891\n",
      "| epoch  25 |   150/  414 batches | lr 0.0000 | ms/batch 133.11 | loss  8.94 | ppl  7598.22 | bpc   12.891\n",
      "| epoch  25 |   200/  414 batches | lr 0.0000 | ms/batch 132.74 | loss  8.94 | ppl  7619.70 | bpc   12.896\n",
      "| epoch  25 |   250/  414 batches | lr 0.0000 | ms/batch 132.71 | loss  8.94 | ppl  7614.92 | bpc   12.895\n",
      "| epoch  25 |   300/  414 batches | lr 0.0000 | ms/batch 133.08 | loss  8.95 | ppl  7672.47 | bpc   12.905\n",
      "| epoch  25 |   350/  414 batches | lr 0.0000 | ms/batch 133.04 | loss  8.94 | ppl  7607.20 | bpc   12.893\n",
      "| epoch  25 |   400/  414 batches | lr 0.0000 | ms/batch 132.85 | loss  8.94 | ppl  7615.91 | bpc   12.895\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 57.48s | valid loss  8.86 | valid ppl  7047.22 | bpc   12.783\n",
      "-----------------------------------------------------------------------------------------\n",
      "=========================================================================================\n",
      "| End of training | test loss  6.63 | test ppl   761.17 | bpc    9.572\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import vector_to_parameters, parameters_to_vector\n",
    "lr = lr\n",
    "best_val_loss = None\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.99)\n",
    "opts = 'SGD'\n",
    "epochs = 25\n",
    "# if opt == 'Adam':\n",
    "#     opt = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
    "#     lr = 0.001\n",
    "# if args.opt == 'Momentum':\n",
    "#     opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.8)\n",
    "# if args.opt == 'RMSprop':\n",
    "#     opt = torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9)\n",
    "#     lr = 0.001\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.to(device)\n",
    "\n",
    "        param_vector = parameters_to_vector(model.rnn.parameters())\n",
    "        param_vector.to(device)\n",
    "        n_params = len(param_vector)\n",
    "        noise = torch.distributions.Normal(loc=torch.tensor(0.), scale=torch.tensor(0.075)).sample_n(n_params)\n",
    "        param_vector.add_(noise.to(device))\n",
    "        \n",
    "        vector_to_parameters(param_vector, model.rnn.parameters())\n",
    "        model.to(device)\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f} | bpc {:8.3f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                           val_loss, math.exp(val_loss), val_loss / math.log(2)))\n",
    "        print('-' * 89)\n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            with open(save, 'wb') as f:\n",
    "                torch.save(model, f)\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            if opts == 'SGD' or opts == 'Momentum':\n",
    "                lr /= 4.0\n",
    "                for group in opt.param_groups:\n",
    "                    group['lr'] = lr\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f} | bpc {:8.3f}'.format(\n",
    "    test_loss, math.exp(test_loss), test_loss / math.log(2)))\n",
    "print('=' * 89)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PennTreebankExperiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
